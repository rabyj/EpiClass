{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205540cf-84f1-475b-a22c-a8bf67a5d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Notebook to analyze the values in an HDF5 file.\"\"\"\n",
    "\n",
    "# %pip list | grep \"ka\"\n",
    "# pylint: disable=redefined-outer-name, expression-not-assigned, import-error, not-callable, pointless-statement, no-value-for-parameter, undefined-variable, unused-argument, use-dict-literal, too-many-lines, too-many-branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdbeea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49ad09",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521d1af-84f2-46e7-9219-985d8a01a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "import json\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from typing import IO, Dict, Iterable, List, Tuple\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "\n",
    "from epiclass.core.data_source import EpiDataSource  # pylint: disable=unused-import\n",
    "from epiclass.core.epiatlas_treatment import (  # pylint: disable=unused-import\n",
    "    ACCEPTED_TRACKS,\n",
    ")\n",
    "from epiclass.core.hdf5_loader import Hdf5Loader\n",
    "from epiclass.core.metadata import Metadata\n",
    "from epiclass.utils.bed_utils import bed_to_bins, bins_to_bed_ranges\n",
    "\n",
    "ASSAY = \"assay_epiclass\"\n",
    "TRACK_TYPE = \"track_type\"\n",
    "CELL_TYPE = \"harmonized_sample_ontology_intermediate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96127d0d-e528-4524-8a84-12792434cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47618fb8-c3e1-40a5-8390-b01b59431ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = Path(\"/lustre06/project/6007017/rabyj/epilap/input/\")\n",
    "base = Path.home() / \"Projects/epiclass\"\n",
    "input_base = base / \"input\"\n",
    "output_base = base / \"output\"\n",
    "\n",
    "chromsize_path = input_base / \"chromsizes\" / \"hg38.noy.chrom.sizes\"\n",
    "metadata_path = (\n",
    "    input_base\n",
    "    / \"metadata/dfreeze-v2/hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    ")\n",
    "\n",
    "base_logdir = output_base / \"logs\"\n",
    "logdir = base_logdir / \"epiatlas-dfreeze-v2.1/hdf5_stats\"\n",
    "\n",
    "if not logdir.exists():\n",
    "    logdir.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dir = output_base / \"paper\"\n",
    "table_dir = paper_dir / \"tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsizes: List[Tuple[str, int]] = EpiDataSource.load_external_chrom_file(chromsize_path)\n",
    "\n",
    "chroms: List[str] = sorted([chrom for chrom, _ in chromsizes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = Metadata(metadata_path)\n",
    "metadata_df = metadata.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5d20e",
   "metadata": {},
   "source": [
    "## Global bin metrics analysis\n",
    "\n",
    "e.g. mean/stddev, median/IRQ in raw hdf5 values, or other data like ChromScore or CNV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e275a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf5_list_path = input_base / \"hdf5_list\" / \"100kb_all_none_10samples.list\"\n",
    "# hdf5_list_path = (\n",
    "#     input_base\n",
    "#     / \"hdf5_list\"\n",
    "#     / \"hg38_2023-01-epiatlas-freeze\"\n",
    "#     / \"100kb_all_none_0blklst.list\"\n",
    "# )\n",
    "\n",
    "# datasource = EpiDataSource(hdf5_list_path, chromsize_path, metadata_path)\n",
    "# my_meta = Metadata(datasource.metadata_file)\n",
    "# my_meta.display_labels(\"track_type\")\n",
    "\n",
    "# my_meta.select_category_subsets(\"track_type\", ACCEPTED_TRACKS)\n",
    "# my_meta.display_labels(\"track_type\")\n",
    "\n",
    "# paths = Hdf5Loader.read_list(hdf5_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5_sizes(hdf5_path: Path | str, chroms: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"Read the HDF5 file and return the data.\"\"\"\n",
    "    with h5py.File(hdf5_path, \"r\") as file:\n",
    "        header = list(file.keys())[0]\n",
    "        hdf5_data = file[header]\n",
    "        chrom_lengths = {chrom: len(hdf5_data[chrom][...]) for chrom in chroms}  # type: ignore\n",
    "    return chrom_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130dccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_important_features(global_task_features_path) -> Dict[str, List[int]]:\n",
    "    \"\"\"Read the important features from the global task features file.\"\"\"\n",
    "    with open(global_task_features_path, \"r\", encoding=\"utf8\") as file:\n",
    "        important_features = json.load(file)\n",
    "    return important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cancer_important_bins() -> Dict[str, List[int]]:\n",
    "    \"\"\"Read the cancer important bins.\"\"\"\n",
    "    dir_path = Path.home() / \"scratch/epiclass/join_important_features/global_info/cancer\"\n",
    "    index_dict = {}\n",
    "\n",
    "    filepath = (\n",
    "        dir_path / \"cancer_intersection_merge_samplings_bed-details_blood_subset.tsv\"\n",
    "    )\n",
    "    df = pd.read_csv(filepath, names=[\"chr\", \"start\", \"end\", \"bin\", \"details\"], sep=\"\\t\")\n",
    "    index_dict[\"cancer_intersection_merge_sampling_blood_subset\"] = list(df[\"bin\"])\n",
    "\n",
    "    filepath = dir_path / \"cancer_intersection_merge_samplings_bed-details_2.tsv\"\n",
    "    df = pd.read_csv(filepath, names=[\"chr\", \"start\", \"end\", \"bin\", \"details\"], sep=\"\\t\")\n",
    "    index_dict[\"cancer_intersection_merge_sampling\"] = list(df[\"bin\"])\n",
    "\n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d22201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features_metrics(\n",
    "    important_features: Dict[str, List[int]],\n",
    "    npz_file_path: Path,\n",
    "    logdir: Path | None = None,\n",
    "    include_categories: Iterable[str] | None = None,\n",
    ") -> Dict[str, Tuple[int, float, float]]:\n",
    "    \"\"\"Using the important features positions, plot (violin) the mean values according to the given npz file.\n",
    "\n",
    "    Adds a violin for a random feature set of the same size, and one for the global distribution.\n",
    "\n",
    "    Compute the KS test for the random features and the global distribution, and add the p-value to the plot.\n",
    "\n",
    "    Args:\n",
    "    - important_features: A dictionary with category names as keys, and lists of feature positions as values.\n",
    "    - npz_file_path: The path to the npz file containing the bin metrics.\n",
    "    - logdir: The directory where to save the plots.\n",
    "    - include_categories: The categories to include in the plot.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with category names as keys, and tuples of sample size and p-values as values.\n",
    "    \"\"\"\n",
    "    with np.load(npz_file_path) as data:\n",
    "        bin_metrics = {metric: data[metric] for metric in data.keys()}\n",
    "\n",
    "    means = np.array(bin_metrics[\"mean\"], dtype=np.float64)\n",
    "\n",
    "    pvals = {}\n",
    "    for category_name, features_pos in important_features.items():\n",
    "        if include_categories and category_name not in include_categories:\n",
    "            continue\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        selected_features = np.array(\n",
    "            [means[pos] for pos in features_pos], dtype=np.float64\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=selected_features,\n",
    "                name=f\"{category_name} features (N={len(features_pos)})\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"all\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Random features comparison\n",
    "        N = len(features_pos)\n",
    "        np.random.seed(42)\n",
    "        random_features = np.random.choice(means, size=N, replace=False)\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=random_features,\n",
    "                name=f\"Random features (N={N})\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"all\",\n",
    "            )\n",
    "        )\n",
    "        _, pval_random = stats.ks_2samp(selected_features, random_features)\n",
    "        if pval_random < 0.0001:\n",
    "            annot_random = \" << 0.001\"\n",
    "        else:\n",
    "            annot_random = f\" = {pval_random:.3f}\"\n",
    "\n",
    "        # Global distribution comparison\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=means,\n",
    "                name=f\"All features N={len(means)}\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"all\",\n",
    "            )\n",
    "        )\n",
    "        _, pval_global = stats.ks_2samp(selected_features, means)\n",
    "        if pval_global < 0.0001:\n",
    "            annot_global = \" << 0.001\"\n",
    "        else:\n",
    "            annot_global = f\" = {pval_global:.3f}\"\n",
    "\n",
    "        # Annotations for p-values\n",
    "        fig.add_annotation(\n",
    "            x=1,\n",
    "            y=max(random_features) + 0.02,\n",
    "            text=f\"p-val {annot_random} (Selected vs. Random)\",\n",
    "            showarrow=False,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            x=2,\n",
    "            y=max(means) + 0.02,\n",
    "            text=f\"p-val {annot_global} (Selected vs. Global)\",\n",
    "            showarrow=False,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "        )\n",
    "\n",
    "        # Small points\n",
    "        fig.update_traces(marker=dict(size=2))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Mean values for {category_name} features\",\n",
    "            xaxis_title=\"Feature set\",\n",
    "            yaxis_title=\"Mean values\",\n",
    "            violinmode=\"group\",\n",
    "            width=1200,\n",
    "            height=800,\n",
    "        )\n",
    "\n",
    "        # sanity check, pval random vs global\n",
    "        _, pval_random_vs_global = stats.ks_2samp(random_features, means)\n",
    "        if pval_random_vs_global < 0.05:\n",
    "            print(f\"WARNING: pval_random_vs_global: {pval_random_vs_global}\")\n",
    "\n",
    "        pvals[category_name] = (N, pval_random, pval_global, pval_random_vs_global)\n",
    "\n",
    "        if logdir:\n",
    "            fig.write_html(logdir / f\"{npz_file_path.stem}_{category_name}_violin.html\")\n",
    "            fig.write_image(logdir / f\"{npz_file_path.stem}_{category_name}_violin.png\")\n",
    "            fig.write_image(logdir / f\"{npz_file_path.stem}_{category_name}_violin.svg\")\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    return pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa01b8",
   "metadata": {},
   "source": [
    "## SHAP values: important regions vs genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b726b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_regions_general_dir = table_dir / \"dfreeze_v2/100kb_all_none/SHAP-MLP\"\n",
    "if not shap_regions_general_dir.exists():\n",
    "    raise FileNotFoundError(f\"Directory {shap_regions_general_dir} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gff_intersect_cols = [\n",
    "    \"chromosome\",\n",
    "    \"start_100kb\",\n",
    "    \"end_100kb\",\n",
    "    \"seqname\",\n",
    "    \"source\",\n",
    "    \"feature\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"score\",\n",
    "    \"strand\",\n",
    "    \"frame\",\n",
    "    \"attribute\",\n",
    "    \"overlap (bp)\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BED_COLS = [\"chromosome\", \"start_100kb\", \"end_100kb\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7553f",
   "metadata": {},
   "source": [
    "### BIOSPECIMENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a3324",
   "metadata": {},
   "source": [
    "#### Read important bins values, and find possible classes for each unique bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc553d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = shap_regions_general_dir / \"cell_type\"\n",
    "features_file = features_dir / \"select_beds_top303.tar.gz\"\n",
    "\n",
    "ct_important_bins: Dict[str, List[int]] = {}\n",
    "with tarfile.open(features_file, \"r:gz\") as tar:\n",
    "    for member in tar.getmembers():\n",
    "        filename = member.name\n",
    "        if \"merge_samplings\" in filename and filename.endswith(\"bed\"):\n",
    "            file_obj: IO[bytes] = tar.extractfile(member)  # type: ignore\n",
    "\n",
    "            cell_type = (\n",
    "                filename.split(\"/\")[1]\n",
    "                .replace(\"merge_samplings_\", \"\")\n",
    "                .replace(\"_features.bed\", \"\")\n",
    "                .lower()\n",
    "            )\n",
    "            ct_important_bins[cell_type] = bed_to_bins(\n",
    "                file_obj, chroms=chromsizes, resolution=100 * 1000\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bins = set()\n",
    "for bins in ct_important_bins.values():\n",
    "    all_bins.update(bins)\n",
    "\n",
    "all_bins = sorted(all_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d79380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find relevant cell types for each bin, optimized for pandas future vectorization\n",
    "relevant_pairs_list = []\n",
    "for cell_type, bins_list in ct_important_bins.items():\n",
    "    for bin_idx in bins_list:\n",
    "        relevant_pairs_list.append({\"bin_index\": bin_idx, CELL_TYPE: cell_type})\n",
    "\n",
    "bin_to_relevant_ct_df = pd.DataFrame(relevant_pairs_list)\n",
    "bin_to_relevant_ct_df[\"bin_index\"] = bin_to_relevant_ct_df[\"bin_index\"].astype(int)\n",
    "\n",
    "assert bin_to_relevant_ct_df.shape[0] > len(ct_important_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68986bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bin_to_relevant_ct_df.shape)\n",
    "print(bin_to_relevant_ct_df[\"bin_index\"].nunique())\n",
    "print(bin_to_relevant_ct_df[CELL_TYPE].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_cell_types = set(bin_to_relevant_ct_df[CELL_TYPE].unique())\n",
    "assert len(classifier_cell_types) == 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca06d6e",
   "metadata": {},
   "source": [
    "##### Creating a new table with associated genes + cell types for each region.\n",
    "\n",
    "The final desired format is  \n",
    "chr, start, end, cell_types, genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e31d2f",
   "metadata": {},
   "source": [
    "Reformat bin / cell type association to have full bed value and aggregated cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_ranges = bins_to_bed_ranges(all_bins, chromsizes, resolution=100 * 1000)\n",
    "bin_to_bed_dict = dict(zip(all_bins, bed_ranges))\n",
    "assert (\n",
    "    len(bin_to_bed_dict) == len(all_bins) == bin_to_relevant_ct_df[\"bin_index\"].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5bec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(bin_to_bed_dict) == bin_to_relevant_ct_df[\"bin_index\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc49ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_to_relevant_ct_df[\"bed_range\"] = bin_to_relevant_ct_df[\"bin_index\"].map(bin_to_bed_dict)  # type: ignore\n",
    "\n",
    "bin_to_relevant_ct_df[[\"chr\", \"start\", \"end\"]] = bin_to_relevant_ct_df[\"bed_range\"].apply(\n",
    "    pd.Series\n",
    ")\n",
    "bin_to_relevant_ct_df[\"region\"] = (\n",
    "    bin_to_relevant_ct_df[\"chr\"].astype(str)\n",
    "    + \":\"\n",
    "    + bin_to_relevant_ct_df[\"start\"].astype(str)\n",
    "    + \"-\"\n",
    "    + bin_to_relevant_ct_df[\"end\"].astype(str)\n",
    ")\n",
    "\n",
    "bin_to_relevant_ct_df.drop(columns=[\"bed_range\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_cols = [\n",
    "    \"bin_index\",\n",
    "    \"chr\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"region\",\n",
    "]  # redundant but want to keep\n",
    "\n",
    "grouped_ct_df = (\n",
    "    bin_to_relevant_ct_df.groupby(groupby_cols)[CELL_TYPE]\n",
    "    .agg(lambda x: \";\".join(map(str, sorted(set(x)))))\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\n",
    "            CELL_TYPE: \"SHAP-MLP_associated_biospecimens\",\n",
    "            \"bin_index\": \"bin_index_100kb\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert grouped_ct_df.shape[0] == grouped_ct_df[\"bin_index_100kb\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee58d5eb",
   "metadata": {},
   "source": [
    "Reformat gff intersection file\n",
    "\n",
    "We will make a version with minimal info, aggregated gene_id + feature_type,  \n",
    "and another version that keeps details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_filepath = features_dir / \"global_union_features_intersect_gff.tsv\"\n",
    "gene_intersect_df = pd.read_csv(\n",
    "    gene_intersect_filepath,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=gff_intersect_cols,\n",
    "    index_col=False,\n",
    ")\n",
    "\n",
    "# Redundant (seqname) or empty (score,frame)\n",
    "gene_intersect_df = gene_intersect_df.drop(columns=[\"seqname\", \"score\", \"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nb of genes: {gene_intersect_df.shape[0]}\")\n",
    "print(f\"Nb of 100kb regions: {grouped_ct_df['bin_index_100kb'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277a9272",
   "metadata": {},
   "source": [
    "Full details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gff = pd.merge(\n",
    "    gene_intersect_df,\n",
    "    grouped_ct_df,\n",
    "    how=\"right\",\n",
    "    left_on=[\"chromosome\", \"start_100kb\", \"end_100kb\"],\n",
    "    right_on=[\"chr\", \"start\", \"end\"],\n",
    "    suffixes=(\"_gff_feature\", \"_ct_df\"),\n",
    ")\n",
    "\n",
    "# Replace missing coordinates with grouped ct coordinates\n",
    "merged_gff[[\"chromosome\", \"start_100kb\", \"end_100kb\"]] = merged_gff[\n",
    "    [\"chr\", \"start_ct_df\", \"end_ct_df\"]\n",
    "]\n",
    "merged_gff.drop(columns=[\"chr\", \"start_ct_df\", \"end_ct_df\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gff[\"feature_length\"] = (\n",
    "    merged_gff[\"end_gff_feature\"] - merged_gff[\"start_gff_feature\"] + 1\n",
    ")\n",
    "merged_gff[\"overlap (fraction)\"] = (\n",
    "    merged_gff[\"overlap (bp)\"] / merged_gff[\"feature_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a066562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some columns\n",
    "merged_gff.rename(\n",
    "    columns={\"source\": \"gene_DB_source\", \"feature\": \"gene_type\"}, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\n",
    "    \"bin_index_100kb\",\n",
    "    \"chromosome\",\n",
    "    \"start_100kb\",\n",
    "    \"end_100kb\",\n",
    "    \"region\",\n",
    "    \"gene_DB_source\",\n",
    "    \"gene_type\",\n",
    "    \"start_gff_feature\",\n",
    "    \"end_gff_feature\",\n",
    "    \"feature_length\",\n",
    "    \"overlap (bp)\",\n",
    "    \"overlap (fraction)\",\n",
    "    \"SHAP-MLP_associated_biospecimens\",\n",
    "    \"attribute\",\n",
    "]\n",
    "merged_gff = merged_gff[col_order]\n",
    "\n",
    "# Int32 is nullable, not int32\n",
    "merged_gff = merged_gff.astype(\n",
    "    {\n",
    "        \"start_100kb\": \"Int32\",\n",
    "        \"end_100kb\": \"Int32\",\n",
    "        \"bin_index_100kb\": \"Int32\",\n",
    "        \"start_gff_feature\": \"Int32\",\n",
    "        \"end_gff_feature\": \"Int32\",\n",
    "        \"feature_length\": \"Int32\",\n",
    "        \"overlap (bp)\": \"Int32\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80683e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gff.to_csv(\n",
    "    features_dir / \"global_union_features_intersect_gff_with_ct.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd40b85",
   "metadata": {},
   "source": [
    "Minimal details, aggregated gene info.\n",
    "\n",
    "Start by reformating gff intersection file to have one line per region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_df.rename(columns={\"feature\": \"gene_type\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep only relevant columns\n",
    "gene_intersect_df = gene_intersect_df[\n",
    "    [\"chromosome\", \"start_100kb\", \"end_100kb\", \"gene_type\", \"attribute\"]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63049aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_df[\"attribute\"] = gene_intersect_df[\"attribute\"].str.split(\n",
    "    \";\", expand=True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a977053",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_df[\"gene_IDs\"] = gene_intersect_df[\"attribute\"].str.split(\n",
    "    \"ID=gene:\", expand=True\n",
    ")[1]\n",
    "gene_intersect_df.drop(columns=[\"attribute\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_cols = [\"chromosome\", \"start_100kb\", \"end_100kb\"]\n",
    "grouped_gene_df = (\n",
    "    gene_intersect_df.groupby(dup_cols)[[\"gene_IDs\", \"gene_type\"]]\n",
    "    .agg(lambda x: \";\".join(map(str, list(x))))\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a46795",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gene_df = grouped_gene_df.merge(\n",
    "    grouped_ct_df,\n",
    "    how=\"right\",\n",
    "    left_on=[\"chromosome\", \"start_100kb\", \"end_100kb\"],\n",
    "    right_on=[\"chr\", \"start\", \"end\"],\n",
    "    suffixes=(\"_gene_df\", \"_ct_df\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gene_df.drop(columns=[\"chromosome\", \"start_100kb\", \"end_100kb\"], inplace=True)\n",
    "grouped_gene_df.rename(columns={\"start\": \"start_100kb\", \"end\": \"end_100kb\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\n",
    "    \"bin_index_100kb\",\n",
    "    \"chr\",\n",
    "    \"start_100kb\",\n",
    "    \"end_100kb\",\n",
    "    \"region\",\n",
    "    \"SHAP-MLP_associated_biospecimens\",\n",
    "    \"gene_IDs\",\n",
    "    \"gene_type\",\n",
    "]\n",
    "grouped_gene_df = grouped_gene_df[col_order]\n",
    "grouped_gene_df.to_csv(\n",
    "    features_dir / \"global_union_features_intersect_gff_aggregated_with_ct.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54803ed8",
   "metadata": {},
   "source": [
    "### SEX/CANCER TOP SHAP intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf344f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gff_intersect_aggregate(\n",
    "    gff_intersect_df: pd.DataFrame, regions_df: pd.DataFrame, verbose: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Aggregate gff intersect data to merge genes for each region (each region comes up only one time)\"\"\"\n",
    "    intersect_df = gff_intersect_df.copy()\n",
    "    regions_df = regions_df.copy()\n",
    "\n",
    "    intersect_df = intersect_df.drop(\n",
    "        columns=[\"seqname\", \"score\", \"frame\", \"overlap (bp)\", \"strand\", \"source\"]\n",
    "    )\n",
    "    intersect_df[\"attribute\"] = intersect_df[\"attribute\"].str.split(\";\", expand=True)[0]\n",
    "    intersect_df[\"gene_IDs\"] = intersect_df[\"attribute\"].str.split(\n",
    "        \"ID=gene:\", expand=True\n",
    "    )[1]\n",
    "    intersect_df.drop(columns=[\"attribute\"], inplace=True)\n",
    "\n",
    "    intersect_df.rename(\n",
    "        columns={\"start\": \"feature_start\", \"end\": \"feature_end\", \"feature\": \"gene_type\"},\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Regions: {regions_df.shape[0]}\")\n",
    "        print(f\"Intersect: {intersect_df.shape[0]}\")\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        regions_df,\n",
    "        intersect_df,\n",
    "        how=\"left\",\n",
    "        on=[\"chromosome\", \"start_100kb\", \"end_100kb\"],\n",
    "    )\n",
    "\n",
    "    groupby_cols = [\"bin_index_100kb\", \"chromosome\", \"start_100kb\", \"end_100kb\"]\n",
    "    merged_df = (\n",
    "        merged_df.groupby(groupby_cols)[[\"gene_IDs\", \"gene_type\"]]\n",
    "        .agg(lambda x: \";\".join(map(str, list(x))))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    merged_df[\"region\"] = (\n",
    "        merged_df[\"chromosome\"].astype(str)\n",
    "        + \":\"\n",
    "        + merged_df[\"start_100kb\"].astype(str)\n",
    "        + \"-\"\n",
    "        + merged_df[\"end_100kb\"].astype(str)\n",
    "    )\n",
    "\n",
    "    # order\n",
    "    merged_df = merged_df[\n",
    "        [\n",
    "            \"bin_index_100kb\",\n",
    "            \"chromosome\",\n",
    "            \"start_100kb\",\n",
    "            \"end_100kb\",\n",
    "            \"region\",\n",
    "            \"gene_IDs\",\n",
    "            \"gene_type\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# miaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dir = shap_regions_general_dir / \"sex\"\n",
    "cancer_dir = shap_regions_general_dir / \"cancer\"\n",
    "\n",
    "sex_intersect_path = sex_dir / \"sex_intersection_merge_samplings_intersect_gff.tsv\"\n",
    "sex_regions_path = sex_dir / \"sex_intersection_merge_samplings.bed\"\n",
    "sex_idx = bed_to_bins(sex_regions_path, chroms=chromsizes, resolution=100 * 1000)\n",
    "\n",
    "cancer_intersect_path = (\n",
    "    cancer_dir / \"cancer_intersection_merge_samplings_intersect_gff.tsv\"\n",
    ")\n",
    "cancer_regions_path = cancer_dir / \"cancer_intersection_merge_samplings.bed\"\n",
    "cancer_idx = bed_to_bins(cancer_regions_path, chroms=chromsizes, resolution=100 * 1000)\n",
    "\n",
    "sex_intersect_df = pd.read_csv(\n",
    "    sex_intersect_path, sep=\"\\t\", header=None, index_col=False, names=gff_intersect_cols\n",
    ")\n",
    "sex_regions_df = pd.read_csv(\n",
    "    sex_regions_path, sep=\"\\t\", header=None, index_col=False, names=BED_COLS\n",
    ")\n",
    "sex_regions_df[\"bin_index_100kb\"] = sex_idx\n",
    "\n",
    "cancer_intersect_df = pd.read_csv(\n",
    "    cancer_intersect_path,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    index_col=False,\n",
    "    names=gff_intersect_cols,\n",
    ")\n",
    "cancer_regions_df = pd.read_csv(\n",
    "    cancer_regions_path, sep=\"\\t\", header=None, index_col=False, names=BED_COLS\n",
    ")\n",
    "cancer_regions_df[\"bin_index_100kb\"] = cancer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_intersect, df_regions, name in zip(\n",
    "    [sex_intersect_df, cancer_intersect_df],\n",
    "    [sex_regions_df, cancer_regions_df],\n",
    "    [\"sex\", \"cancer\"],\n",
    "):\n",
    "    merged_df = gff_intersect_aggregate(df_intersect, df_regions)\n",
    "\n",
    "    merged_df.to_csv(\n",
    "        shap_regions_general_dir / name / f\"{name}_intersect_gff_aggregated.tsv\",\n",
    "        sep=\"\\t\",\n",
    "        index=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a08d2",
   "metadata": {},
   "source": [
    "## ChromScore hdf5 values\n",
    "\n",
    "For each cell type important feature, find the average ChromScore value throughout associated cell types.  \n",
    "If bin is present in multiple classes, just use files for all those classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b05c1e",
   "metadata": {},
   "source": [
    "### Read ChromScore values, and map files to their cell type.\n",
    "\n",
    "Using hdf5 output from `bigwig_metrics.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscore_dir = paper_dir / \"data\" / \"ChromScore\"\n",
    "chromscore_file = chromscore_dir / \"max_metrics_clean.h5\"\n",
    "\n",
    "to_clean = False\n",
    "if not chromscore_file.exists():\n",
    "    print(f\"{chromscore_file} does not exist\")\n",
    "    chromscore_file = chromscore_dir / \"max_metrics.h5\"\n",
    "    to_clean = True\n",
    "\n",
    "if not chromscore_file.exists():\n",
    "    raise FileNotFoundError(f\"{chromscore_file} does not exist\")\n",
    "\n",
    "print(f\"Loading {chromscore_file}\")\n",
    "chromscores_df: pd.DataFrame = pd.read_hdf(chromscore_file)  # type: ignore\n",
    "print(\"Chromscores shape\", chromscores_df.shape)\n",
    "display(chromscores_df.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f28a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_chromscore_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean up values in .h5 inplace.\n",
    "\n",
    "    - If values in .h5 were stored a lists (with one value), get val\n",
    "    - fillna as 0\n",
    "    \"\"\"\n",
    "    # check for nans\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum():\n",
    "            print(col, df[col].isna().sum())\n",
    "\n",
    "    # check if values are lists\n",
    "    if isinstance(df.iloc[0, 0], list):\n",
    "        df = df.map(lambda x: x[0])\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc494c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_clean:\n",
    "    print(\"Chromscores shape\", chromscores_df.shape)\n",
    "    chromscores_df = transform_chromscore_df(chromscores_df)\n",
    "    print(\"Chromscores shape\", chromscores_df.shape)\n",
    "\n",
    "    chromscore_file = chromscore_dir / \"max_metrics_clean.h5\"\n",
    "    chromscores_df.to_hdf(\n",
    "        chromscore_file,\n",
    "        key=\"df\",\n",
    "        mode=\"w\",\n",
    "        format=\"fixed\",\n",
    "        complevel=9,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscores_df[\"epirr\"] = chromscores_df.index.str.split(\".\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from epirr_id_without_version to cell_type\n",
    "epirr_to_cell_type = dict(\n",
    "    metadata_df.loc[:, [\"epirr_id_without_version\", CELL_TYPE]].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7caed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscores_df[CELL_TYPE] = (\n",
    "    chromscores_df[\"epirr\"].map(epirr_to_cell_type).str.replace(\" \", \"_\").str.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58394020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep files from classifier 16ct\n",
    "chromscores_df = chromscores_df[chromscores_df[CELL_TYPE].isin(classifier_cell_types)]\n",
    "print(\"Chromscores shape\", chromscores_df.shape)\n",
    "display(chromscores_df.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c41507",
   "metadata": {},
   "source": [
    "### Find mean chromScore for each bin (for their relevant files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce905e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting global chromscores for future operation, now all values are in one column\n",
    "# Assuming all columns starting with chr are bins, and all 100kb bins are present\n",
    "region_cols_mapper = {\n",
    "    col: idx\n",
    "    for idx, col in enumerate(chromscores_df.columns)\n",
    "    if isinstance(col, str) and col.startswith(\"chr\")\n",
    "}\n",
    "assert len(region_cols_mapper) == 30321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73330f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscores_df.rename(columns=region_cols_mapper, inplace=True)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_chromscores = chromscores_df.reset_index().rename(columns={\"index\": \"filename\"})\n",
    "melted_chromscores = melted_chromscores.melt(\n",
    "    id_vars=[\"epirr\", CELL_TYPE],\n",
    "    value_vars=list(region_cols_mapper.values()),\n",
    "    var_name=\"bin_index\",\n",
    "    value_name=\"chromscore_value\",\n",
    ")\n",
    "melted_chromscores[\"bin_index\"] = melted_chromscores[\"bin_index\"].astype(int)\n",
    "print(melted_chromscores.shape)\n",
    "print(melted_chromscores[\"bin_index\"].nunique())\n",
    "print(melted_chromscores[\"epirr\"].nunique())\n",
    "display(melted_chromscores.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54395752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge melted chromscores with bin_to_relevant_ct_df, efficient for pandas\n",
    "# Filters out all irrelevant bins\n",
    "merged_df = pd.merge(\n",
    "    melted_chromscores, bin_to_relevant_ct_df, on=[\"bin_index\", CELL_TYPE], how=\"inner\"\n",
    ")\n",
    "print(merged_df.shape)\n",
    "print(merged_df[\"bin_index\"].nunique())\n",
    "print(merged_df[\"epirr\"].nunique())\n",
    "display(merged_df.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns of interest for plotting\n",
    "merged_df = merged_df[[\"epirr\", CELL_TYPE, \"bin_index\", \"chromscore_value\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75059fc",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = paper_dir / \"figures\" / \"chromscore\"\n",
    "if not logdir.exists():\n",
    "    logdir.mkdir(parents=True)\n",
    "\n",
    "# plot_important_features_chromscore_global(\n",
    "#     avg_selected=avg,\n",
    "#     all_avg=all_avg,\n",
    "#     logdir=logdir,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_distribution(\n",
    "    x: List[float], y: List[float], verbose: bool = True\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Test for distribution difference. x is used as reference for the number of samples.\n",
    "\n",
    "    Welch's t-test and Brunner-Munzel test are computed.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: p-value for each test\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"Number of samples in x: {len(x)}\")\n",
    "        print(f\"Number of samples in y: {len(y)}\")\n",
    "\n",
    "    Welch_pval = stats.ttest_ind(\n",
    "        a=x,\n",
    "        b=y,\n",
    "        equal_var=False,\n",
    "        alternative=\"two-sided\",\n",
    "        nan_policy=\"raise\",\n",
    "    ).pvalue  # type: ignore\n",
    "\n",
    "    # def statistic(x, y, axis):\n",
    "    #     return np.mean(x, axis=axis) - np.mean(y, axis=axis)\n",
    "\n",
    "    # perm_pval = stats.permutation_test(\n",
    "    #     data=(x, y),\n",
    "    #     statistic=statistic,\n",
    "    #     permutation_type=\"independent\",\n",
    "    #     alternative=\"two-sided\",\n",
    "    #     n_resamples=9999,  # type: ignore\n",
    "    #     random_state=42,\n",
    "    # ).pvalue\n",
    "\n",
    "    BM_pval = stats.brunnermunzel(\n",
    "        x,\n",
    "        y,\n",
    "        alternative=\"two-sided\",\n",
    "        nan_policy=\"raise\",\n",
    "        distribution=\"t\",\n",
    "    ).pvalue\n",
    "\n",
    "    return Welch_pval, BM_pval\n",
    "\n",
    "\n",
    "def define_pval_label(pval: float) -> str:\n",
    "    \"\"\"Define p-value label.\"\"\"\n",
    "    pval_symbol = \"\"\n",
    "    if pval < 0.001:\n",
    "        pval_symbol = \"<0.001***\"\n",
    "    elif pval < 0.01:\n",
    "        pval_symbol = \"<0.01**\"\n",
    "    elif pval < 0.05:\n",
    "        pval_symbol = \"<0.05*\"\n",
    "    elif pval >= 0.05:\n",
    "        pval_symbol = \">0.05 NS\"\n",
    "\n",
    "    return pval_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_chromscore_per_biospecimen_data(\n",
    "    selected_bins_df: pd.DataFrame,\n",
    "    all_chromscores_df: pd.DataFrame,\n",
    ") -> Dict[str, Dict[str, List[float] | int]]:\n",
    "    \"\"\"\n",
    "    Prepare plot data for chromscore per biospecimen plot.\n",
    "\n",
    "    Each biospecimen need values for:\n",
    "    - important features\n",
    "    - random features\n",
    "    - global distribution\n",
    "\n",
    "    This is done with independent file subsets.\n",
    "    \"\"\"\n",
    "    total_bins = all_chromscores_df[\"bin_index\"].nunique()\n",
    "\n",
    "    grouped_means = {}\n",
    "\n",
    "    for biospecimen, df in selected_bins_df.groupby(by=CELL_TYPE):\n",
    "        print(f\"Processing {biospecimen}\")\n",
    "\n",
    "        all_chromscores_group = all_chromscores_df.loc[\n",
    "            all_chromscores_df[CELL_TYPE] == biospecimen, :\n",
    "        ]\n",
    "        if not all_chromscores_group[\"chromscore_value\"].isna().sum() == 0:\n",
    "            raise ValueError(f\"Missing values in chromscore_value for {biospecimen}\")\n",
    "        nb_files = df[\"epirr\"].nunique()\n",
    "\n",
    "        # Important features\n",
    "        avg_per_bin = df.groupby(\"bin_index\")[\"chromscore_value\"].mean()\n",
    "        nb_features = len(avg_per_bin)\n",
    "\n",
    "        # Random features\n",
    "        np.random.seed(42)\n",
    "        random_features_idx = np.random.choice(\n",
    "            range(total_bins), size=nb_features, replace=False\n",
    "        )\n",
    "\n",
    "        random_df = all_chromscores_group.loc[\n",
    "            all_chromscores_group[\"bin_index\"].isin(random_features_idx)\n",
    "        ]\n",
    "        random_features_means = random_df.groupby(\"bin_index\")[\"chromscore_value\"].mean()\n",
    "\n",
    "        # Global distribution\n",
    "        all_means_file_subset = all_chromscores_group.groupby(\"bin_index\")[\n",
    "            \"chromscore_value\"\n",
    "        ].mean()\n",
    "\n",
    "        grouped_means[biospecimen] = {\n",
    "            \"avg_per_bin\": avg_per_bin,\n",
    "            \"random_features_means\": random_features_means,\n",
    "            \"all_means_file_subset\": all_means_file_subset,\n",
    "            \"nb_files\": nb_files,\n",
    "        }\n",
    "\n",
    "    grouped_means[\"all_files\"] = all_chromscores_df.groupby(\"bin_index\")[\n",
    "        \"chromscore_value\"\n",
    "    ].mean()\n",
    "\n",
    "    return grouped_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24442c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check, missing values\n",
    "groupby = merged_df.groupby(CELL_TYPE)[\"chromscore_value\"].apply(lambda x: x.isna().sum())\n",
    "if not groupby.sum() == 0:\n",
    "    display(groupby)\n",
    "    raise ValueError(\"Missing values in chromscore_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a7d93",
   "metadata": {},
   "source": [
    "This next cell can take more than 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba62aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = prepare_chromscore_per_biospecimen_data(\n",
    "    selected_bins_df=merged_df, all_chromscores_df=melted_chromscores\n",
    ")\n",
    "\n",
    "del merged_df, melted_chromscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be9f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features_chromscore_global(\n",
    "    avg_selected: pd.DataFrame,\n",
    "    all_avg: pd.DataFrame,\n",
    "    logdir: Path | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot violin for important features and random features.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Important features\n",
    "    print(\"Tracing important features\")\n",
    "    N = len(avg_selected)\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=avg_selected,\n",
    "            name=f\"Important features per biospecimen (N={N})\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            points=False,\n",
    "            spanmode=\"hard\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Random features comparison\n",
    "    print(\"Computing random features\")\n",
    "    np.random.seed(42)\n",
    "    random_features_means = np.random.choice(all_avg, size=N, replace=False)\n",
    "\n",
    "    print(\"Tracing random features\")\n",
    "    N = len(random_features_means)\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            y=random_features_means,\n",
    "            name=f\"Random features, value on all files (N={N})\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            points=False,\n",
    "            spanmode=\"hard\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Global distribution comparison\n",
    "    print(\"Tracing all features\")\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            y=all_avg,\n",
    "            name=f\"All features, all files (N={len(all_avg)})\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            points=False,\n",
    "            spanmode=\"hard\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Important cell type features chromScore\",\n",
    "        xaxis_title=\"Feature set\",\n",
    "        yaxis_title=\"Average max value in selected regions of 100kb\",\n",
    "        violinmode=\"group\",\n",
    "        width=800,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if logdir is not None:\n",
    "        print(\"Saving figure.\")\n",
    "        name = \"important_features_16ct_max_chromscore_100kb\"\n",
    "        fig.write_image(logdir / f\"{name}.svg\")\n",
    "        fig.write_image(logdir / f\"{name}.png\")\n",
    "        fig.write_html(logdir / f\"{name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37501d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chromscore_global_violin(\n",
    "    graph_data: Dict[str, Dict[str, List[float] | int]],\n",
    "    cell_types: List[str] | None = None,\n",
    "    logdir: Path | None = None,\n",
    "    filename: str = \"chromscore_global_violin\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot boxplots for important features with their cell type files subset\n",
    "    vs all features for all files.\n",
    "\n",
    "    Args:\n",
    "        graph_data: Dict[str, Dict[str, List[float] | int]]. From prepare_chromscore_per_biospecimen_data.\n",
    "        cell_types: List[str]|None. List of cell types to plot.\n",
    "\n",
    "    \"\"\"\n",
    "    data = copy.deepcopy(graph_data)\n",
    "    if not cell_types:\n",
    "        cell_types = list(data.keys())\n",
    "        cell_types.remove(\"all_files\")\n",
    "\n",
    "    colors = px.colors.qualitative.Dark24[0:2]\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Filter\n",
    "    try:\n",
    "        data = {biospecimen: graph_data[biospecimen] for biospecimen in cell_types}\n",
    "    except KeyError as err:\n",
    "        raise KeyError(\n",
    "            f\"A cell type is missing from the graph_data.\\ncell types: {graph_data.keys()}.\\nDesired: {cell_types}.\"\n",
    "        ) from err\n",
    "\n",
    "    important_features_vals = []\n",
    "    for _, data in enumerate(data.values()):\n",
    "        avg_per_bin: List[float] = data[\"avg_per_bin\"]  # type: ignore\n",
    "        important_features_vals.extend(avg_per_bin)\n",
    "    N_subsets = len(important_features_vals)\n",
    "\n",
    "    # Important features\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            name=\"trace\",\n",
    "            legendgroup=\"Important features (SHAP)\",\n",
    "            side=\"negative\",\n",
    "            y=important_features_vals,\n",
    "            fillcolor=colors[0],\n",
    "            line=dict(color=\"black\", width=1.5),\n",
    "            showlegend=False,\n",
    "            meanline_visible=True,\n",
    "            points=False,\n",
    "            spanmode=\"hard\",\n",
    "            box=dict(\n",
    "                visible=True,\n",
    "                fillcolor=colors[0],\n",
    "                width=0.4,\n",
    "                line_width=1,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Global distribution comparison\n",
    "    big_N = len(graph_data[\"all_files\"])\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            name=\"trace\",\n",
    "            legendgroup=\"All features\",\n",
    "            side=\"positive\",\n",
    "            y=graph_data[\"all_files\"],\n",
    "            fillcolor=colors[1],\n",
    "            line=dict(color=\"black\", width=1.5),\n",
    "            showlegend=False,\n",
    "            meanline_visible=True,\n",
    "            points=False,\n",
    "            spanmode=\"hard\",\n",
    "            box=dict(\n",
    "                visible=True,\n",
    "                fillcolor=colors[1],\n",
    "                width=0.4,\n",
    "                line_width=1,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    pval = stats.ttest_ind(\n",
    "        a=important_features_vals,\n",
    "        b=graph_data[\"all_files\"],\n",
    "        equal_var=False,\n",
    "        alternative=\"two-sided\",\n",
    "        nan_policy=\"raise\",\n",
    "    ).pvalue\n",
    "    print(f\"pval Welch's T-test:{pval:.4f}\")\n",
    "\n",
    "    # Legend with dummy points\n",
    "    for i, name in enumerate(\n",
    "        [f\"Important SHAP features ({N_subsets})\", f\"All features ({big_N})\"]\n",
    "    ):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode=\"markers\",\n",
    "                name=name,\n",
    "                legendgroup=name.split(\"(\")[0].strip(),\n",
    "                showlegend=True,\n",
    "                marker=dict(color=colors[i], symbol=\"square\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "    fig.update_layout(\n",
    "        yaxis_title=\"Average of max value in selected regions of 100kb (over files)\",\n",
    "        width=700,\n",
    "        height=700,\n",
    "    )\n",
    "\n",
    "    # fig.update_layout(violingap=0, violinmode='overlay')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if logdir is not None:\n",
    "        print(\"Saving figure.\")\n",
    "        fig.write_image(logdir / f\"{filename}.svg\")\n",
    "        fig.write_image(logdir / f\"{filename}.png\", scale=1.5)\n",
    "        fig.write_html(logdir / f\"{filename}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd33e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chromscore_per_biospecimen_box(\n",
    "    graph_data: Dict[str, Dict[str, List[float] | int]],\n",
    "    logdir: Path | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot boxplots for important features and random features,\n",
    "    using regions and files per biospecimen independently.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    colors = px.colors.qualitative.Dark24_r[0:3]\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=4,\n",
    "        cols=4,\n",
    "        shared_yaxes=True,\n",
    "        vertical_spacing=0.1,\n",
    "        y_title=\"Average max value in selected regions of 100kb\",\n",
    "    )\n",
    "\n",
    "    for idx, (biospecimen, data) in enumerate(graph_data.items()):\n",
    "        try:\n",
    "            avg_per_bin: List[float] = data[\"avg_per_bin\"]  # type: ignore\n",
    "            random_features_means: List[float] = data[\"random_features_means\"]  # type: ignore\n",
    "            all_means_file_subset: List[float] = data[\"all_means_file_subset\"]  # type: ignore\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "        nb_files = data[\"nb_files\"]\n",
    "        nb_features = len(avg_per_bin)\n",
    "\n",
    "        # Important features\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=avg_per_bin,\n",
    "                x=[0] * len(avg_per_bin),\n",
    "                line_color=colors[0],\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "        )\n",
    "\n",
    "        # Random features comparison\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=random_features_means,\n",
    "                x=[1] * len(random_features_means),\n",
    "                line_color=colors[1],\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "        )\n",
    "\n",
    "        # Global distribution comparison\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=all_means_file_subset,\n",
    "                x=[2] * len(all_means_file_subset),\n",
    "                boxpoints=False,\n",
    "                line_color=colors[2],\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "        )\n",
    "\n",
    "        pvals = test_distribution(\n",
    "            x=avg_per_bin,\n",
    "            y=all_means_file_subset,\n",
    "        )\n",
    "        print(f\"{biospecimen}, {nb_features} features, {nb_files} files\")\n",
    "        print(f\"pvals [Welch, Permutation, BM]: {pvals}\\n\")\n",
    "\n",
    "        pval = float(np.max(pvals))\n",
    "        pval_symbol = define_pval_label(pval)\n",
    "\n",
    "        group_name = f\"{biospecimen}<br>({nb_features} features, {nb_files} files)<br>pval{pval_symbol}\"\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            showticklabels=False,\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "            title=group_name,\n",
    "        )\n",
    "\n",
    "    # Legend with dummy points\n",
    "    for i, name in zip(\n",
    "        range(3),\n",
    "        [\"Important SHAP features\", \"Random features\", \"All features (whiskers=max/min)\"],\n",
    "    ):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode=\"markers\",\n",
    "                name=name,\n",
    "                legendgroup=name,\n",
    "                showlegend=True,\n",
    "                marker=dict(color=colors[i], symbol=\"square\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"ChromScore per biospecimen file subset\",\n",
    "        width=1200,\n",
    "        height=1200,\n",
    "        legend=dict(\n",
    "            itemsizing=\"constant\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if logdir is not None:\n",
    "        print(\"Saving figure.\")\n",
    "        name = \"important_features_16ct_max_chromscore_100kb_per_biospecimen_boxplot\"\n",
    "        fig.write_image(logdir / f\"{name}.svg\")\n",
    "        fig.write_image(logdir / f\"{name}.png\")\n",
    "        fig.write_html(logdir / f\"{name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_chromscore_per_biospecimen_box(\n",
    "#     graph_data=graph_data,\n",
    "#     logdir=logdir,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chromscore_per_biospecimen_violin(\n",
    "    graph_data: Dict[str, Dict[str, List[float] | int]],\n",
    "    cell_types: List[str] | None = None,\n",
    "    logdir: Path | None = None,\n",
    "    do_subplots: bool = True,\n",
    "    filename: str = \"important_features_16ct_max_chromscore_100kb_per_biospecimen_2violin\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Plot boxplots for important features and random features,\n",
    "    using regions and files per biospecimen independently.\n",
    "\n",
    "    Args:\n",
    "        graph_data: Dict[str, Dict[str, List[float] | int]]. From prepare_chromscore_per_biospecimen_data.\n",
    "        cell_types: List[str]|None. List of cell types to plot.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame. Dataframe with pvals.\n",
    "    \"\"\"\n",
    "    data = copy.deepcopy(graph_data)\n",
    "    if not cell_types:\n",
    "        cell_types = list(data.keys())\n",
    "        cell_types.remove(\"all_files\")\n",
    "\n",
    "    colors = px.colors.qualitative.Dark24[0:2]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    if do_subplots:\n",
    "        fig = make_subplots(\n",
    "            rows=4,\n",
    "            cols=4,\n",
    "            shared_yaxes=True,\n",
    "            vertical_spacing=0.1,\n",
    "            y_title=\"Average of max value in selected regions of 100kb (over files)\",\n",
    "        )\n",
    "\n",
    "    # Filter\n",
    "    try:\n",
    "        data = {biospecimen: graph_data[biospecimen] for biospecimen in cell_types}\n",
    "    except KeyError as err:\n",
    "        raise KeyError(\n",
    "            f\"A cell type is missing from the graph_data.\\ncell types: {graph_data.keys()}.\\nDesired: {cell_types}.\"\n",
    "        ) from err\n",
    "\n",
    "    all_pvals = []\n",
    "    trace_names = []\n",
    "    for idx, (biospecimen, data) in enumerate(data.items()):\n",
    "        if biospecimen not in cell_types:\n",
    "            continue\n",
    "\n",
    "        avg_per_bin: List[float] = data[\"avg_per_bin\"]  # type: ignore\n",
    "        all_means_file_subset: List[float] = data[\"all_means_file_subset\"]  # type: ignore\n",
    "\n",
    "        nb_files = data[\"nb_files\"]\n",
    "        nb_features = len(avg_per_bin)\n",
    "\n",
    "        if do_subplots:\n",
    "            placement_dict = {\n",
    "                \"row\": idx // 4 + 1,\n",
    "                \"col\": idx % 4 + 1,\n",
    "            }\n",
    "        else:\n",
    "            placement_dict = {}\n",
    "\n",
    "        # Important features\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                side=\"negative\",\n",
    "                name=f\"trace{idx}\",\n",
    "                y=avg_per_bin,\n",
    "                fillcolor=colors[0],\n",
    "                line=dict(color=\"black\", width=1.5 if do_subplots else 0),\n",
    "                showlegend=False,\n",
    "                meanline_visible=True,\n",
    "                points=False,\n",
    "                spanmode=\"hard\",\n",
    "                legendgroup=\"All features\",\n",
    "                box=dict(\n",
    "                    visible=True,\n",
    "                    fillcolor=colors[0] if do_subplots else \"black\",\n",
    "                    width=0.4,\n",
    "                    line_width=0.5 if do_subplots else 0,\n",
    "                ),\n",
    "                scalemode=\"width\",  # occupy all possible space for subplots\n",
    "                scalegroup=f\"trace{idx}\",\n",
    "            ),\n",
    "            **placement_dict,  # type: ignore\n",
    "        )\n",
    "\n",
    "        # Global distribution comparison\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                side=\"positive\",\n",
    "                name=f\"trace{idx}\",\n",
    "                y=all_means_file_subset,\n",
    "                fillcolor=colors[1],\n",
    "                line=dict(color=\"black\", width=1.5 if do_subplots else 0),\n",
    "                showlegend=False,\n",
    "                meanline_visible=True,\n",
    "                points=False,\n",
    "                spanmode=\"hard\",\n",
    "                legendgroup=\"All features\",\n",
    "                box=dict(\n",
    "                    visible=True,\n",
    "                    fillcolor=colors[1] if do_subplots else \"black\",\n",
    "                    width=0.4,\n",
    "                    line_width=0.5 if do_subplots else 0,\n",
    "                ),\n",
    "                scalemode=\"width\",\n",
    "                scalegroup=f\"trace{idx}\",\n",
    "            ),\n",
    "            **placement_dict,  # type: ignore\n",
    "        )\n",
    "\n",
    "        pvals = test_distribution(\n",
    "            x=avg_per_bin,\n",
    "            y=all_means_file_subset,\n",
    "            verbose=False,\n",
    "        )\n",
    "        print(f\"{biospecimen}, {nb_features} features, {nb_files} files\")\n",
    "        print(f\"pvals [Welch, BM]: {pvals}\\n\\n\")\n",
    "\n",
    "        all_pvals.append(\n",
    "            [biospecimen, nb_files, nb_features, len(all_means_file_subset), *pvals]\n",
    "        )\n",
    "\n",
    "        pval = float(np.max(pvals))\n",
    "        pval_symbol = define_pval_label(pval)\n",
    "\n",
    "        if do_subplots:\n",
    "            group_name = f\"{biospecimen}<br>({nb_files} files, {nb_features} features)<br>p{pval_symbol}\"\n",
    "            fig.update_xaxes(\n",
    "                showticklabels=False,\n",
    "                row=idx // 4 + 1,\n",
    "                col=idx % 4 + 1,\n",
    "                title=group_name,\n",
    "            )\n",
    "        else:\n",
    "            group_name = f\"{biospecimen} ({nb_files} files, {nb_features} features), p{pval_symbol}\"\n",
    "            trace_names.append(group_name)\n",
    "\n",
    "    # Manually set names for traces\n",
    "    if not do_subplots:\n",
    "        newnames = {f\"trace{idx}\": name for idx, name in enumerate(trace_names)}\n",
    "        fig.for_each_trace(lambda t: t.update(name=newnames[t.name]))\n",
    "\n",
    "    # Legend with dummy points\n",
    "    for i, name in enumerate([\"Important SHAP features\", \"All features\"]):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode=\"markers\",\n",
    "                name=name,\n",
    "                legendgroup=name,\n",
    "                showlegend=True,\n",
    "                marker=dict(color=colors[i], symbol=\"square\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"ChromScore per biospecimen file subset\",\n",
    "        width=1200,\n",
    "        height=1200,\n",
    "        legend=dict(\n",
    "            itemsizing=\"constant\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # fig.update_layout(violingap=0, violinmode='overlay')\n",
    "\n",
    "    if not do_subplots:\n",
    "        fig.update_layout(\n",
    "            yaxis_title=\"Average of max value in selected regions of 100kb (over files)\",\n",
    "            xaxis_title=\"Biospecimen\",\n",
    "            width=700,\n",
    "            height=700,\n",
    "        )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if logdir is not None:\n",
    "        print(\"Saving figure.\")\n",
    "        fig.write_image(logdir / f\"{filename}.svg\")\n",
    "        fig.write_image(logdir / f\"{filename}.png\", scale=1.5)\n",
    "        fig.write_html(logdir / f\"{filename}.html\")\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        all_pvals,\n",
    "        columns=[\n",
    "            \"biospecimen\",\n",
    "            \"nb_files\",\n",
    "            \"Nb features (N_1)\",\n",
    "            \"Nb features global (N_2)\",\n",
    "            \"pval_Welch\",\n",
    "            \"pval_BM\",\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_types = [\"t_cell\", \"neutrophil\", \"lymphocyte_of_b_lineage\", \"brain\", \"hepatocyte\"]\n",
    "\n",
    "# plot_chromscore_per_biospecimen_violin(\n",
    "#     graph_data=graph_data,\n",
    "#     do_subplots=False,\n",
    "#     cell_types=cell_types,\n",
    "#     # filename=\"v2_important_features_16ct_max_chromscore_100kb_per_biospecimen_2violin\",\n",
    "#     # logdir=logdir,\n",
    "# )\n",
    "\n",
    "\n",
    "pvals_df = plot_chromscore_per_biospecimen_violin(\n",
    "    graph_data=graph_data,\n",
    "    do_subplots=True,\n",
    "    # cell_types=cell_types,\n",
    "    filename=\"v4_important_features_16ct_max_chromscore_100kb_per_biospecimen_2violin\",\n",
    "    logdir=logdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c08a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals_df.set_index(\"biospecimen\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc23404",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals_df[\"corrected_pval_Welch\"] = pvals_df[\"pval_Welch\"].apply(\n",
    "    lambda x: min(1, x * len(pvals_df))\n",
    ")\n",
    "pvals_df[\"corrected_pval_BM\"] = pvals_df[\"pval_BM\"].apply(\n",
    "    lambda x: min(1, x * len(pvals_df))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50355448",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = (\n",
    "    logdir\n",
    "    / \"v4_important_features_16ct_max_chromscore_100kb_per_biospecimen_2violin_pvals.csv\"\n",
    ")\n",
    "pvals_df.to_csv(filepath, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df21429",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_chromscore_global_violin(\n",
    "    graph_data=graph_data,\n",
    "    logdir=logdir,\n",
    "    filename=\"chromscore_16ct_global_2violin_v3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c786ae",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_md5s_path = input_base / \"hdf5_list\" / \"md5_shap_assay_explain.list\"\n",
    "# with open(shap_md5s_path, \"r\", encoding=\"utf8\") as f:\n",
    "#     shap_md5s = set(f.read().splitlines())\n",
    "\n",
    "\n",
    "def analyze_feature_vals(\n",
    "    regions_dict: Dict[int, Tuple],\n",
    "    md5s: List[str],\n",
    "    hdf5_list: Path,\n",
    "    logdir: Path,\n",
    "    name: str,\n",
    "    shap_md5s: List[str],\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate and save a violin plot of provided feature values for the provided md5s, with some md5s highlighted.\n",
    "\n",
    "    This function takes as input a list of md5s and a dictionary of regions, and generates a violin plot\n",
    "    of the feature values for these md5s. It also highlights specific md5s by adding lines+markers for them.\n",
    "    The function saves the plot as an HTML file and a PNG file in the provided log directory.\n",
    "\n",
    "    Args:\n",
    "        regions_dict (Dict[int, Tuple]): A dictionary mapping region indices to their respective genomic coordinates.\n",
    "        md5s (List[str]): A list of md5s to analyze.\n",
    "        hdf5_list (Path): Path to the list of hdf5 files to be used.\n",
    "        logdir (Path): Directory where the resulting plot should be saved.\n",
    "        name (str): Name used to save the resulting plot (will be part of the filename).\n",
    "    \"\"\"\n",
    "    hdf5_loader = Hdf5Loader(chrom_file=chromsize_path, normalization=True)\n",
    "    hdf5_loader.load_hdf5s(hdf5_list, md5s, strict=True)\n",
    "    N = len(hdf5_loader.signals)\n",
    "\n",
    "    nb_highlight = 3\n",
    "    highlight_md5s = list(set(md5s) & set(shap_md5s))[0:nb_highlight]\n",
    "\n",
    "    traces = []\n",
    "    highlight_values = {highlight_md5: [] for highlight_md5 in highlight_md5s}\n",
    "    for region, region_bed in regions_dict.items():\n",
    "        values = [signal[region] for signal in hdf5_loader.signals.values()]\n",
    "        region_str = f\"{region_bed[0]}:{region_bed[1]}-{region_bed[2]}\"\n",
    "\n",
    "        trace = go.Violin(\n",
    "            y=values,\n",
    "            name=region_str,\n",
    "            points=\"all\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "        for highlight_md5 in highlight_md5s:\n",
    "            highlight_value = hdf5_loader.signals[highlight_md5][region]\n",
    "            highlight_values[highlight_md5].append((region_str, highlight_value))\n",
    "\n",
    "    for (highlight_md5, highlight_value), marker_format in zip(\n",
    "        highlight_values.items(),\n",
    "        [[\"cross\", \"black\"], [\"circle\", \"blue\"], [\"diamond\", \"red\"]],\n",
    "    ):\n",
    "        x, y = zip(*highlight_value)\n",
    "        symbol, color = marker_format\n",
    "        highlight_trace = go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"lines+markers\",\n",
    "            name=f\"{highlight_md5}\",\n",
    "            marker={\"size\": 6, \"symbol\": symbol, \"color\": color},\n",
    "        )\n",
    "        traces.append(highlight_trace)\n",
    "\n",
    "    # Create the layout\n",
    "    layout = go.Layout(\n",
    "        title=f\"Feature values distributions for {N} {name} samples (0blklst)\",\n",
    "        yaxis={\"title\": \"z-score\"},\n",
    "        xaxis={\"title\": \"Region\"},\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Create the figure with the data and layout\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    fig.write_html(logdir / f\"feature_values_{name}.html\")\n",
    "\n",
    "    width = 1200\n",
    "    fig.write_image(\n",
    "        logdir / f\"feature_values_{name}.png\", width=width, height=width * 3 / 4\n",
    "    )\n",
    "    # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_file(hdf5_list_path, md5, zscore: bool = True):\n",
    "    \"\"\"Produce a violin plot (save to html) of all feature values for a single sample.\"\"\"\n",
    "    if zscore:\n",
    "        mode = \"z-scores\"\n",
    "    else:\n",
    "        mode = \"raw values\"\n",
    "\n",
    "    hdf5_loader = Hdf5Loader(chrom_file=chromsize_path, normalization=zscore)\n",
    "    signals = hdf5_loader.load_hdf5s(hdf5_list_path, [md5], strict=True).signals\n",
    "\n",
    "    fig = px.violin(\n",
    "        data_frame=list(signals.values())[0],\n",
    "        box=True,\n",
    "        points=\"all\",\n",
    "        title=f\"Violin plot for {md5} {mode}\",\n",
    "    )\n",
    "    fig.write_html(f\"{md5}-{mode}.html\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_casting_error(filepath: Path | str, dataset_name: str):\n",
    "    \"\"\"Evaluate the casting error for a specific dataset in an HDF5 file.\"\"\"\n",
    "    with h5py.File(filepath, \"r\") as f:\n",
    "        dataset: h5py.Dataset = f[dataset_name]  # type: ignore\n",
    "        values: np.ndarray = dataset[:]  # type: ignore\n",
    "\n",
    "        # Cast to float32 and compare max diff\n",
    "        casted_dataset = dataset.astype(np.float32)[:]\n",
    "        diff = np.abs(casted_dataset - values)\n",
    "        max_diff = np.max(diff)\n",
    "        print(f\"Max diff when casting: {max_diff}\")\n",
    "        if max_diff > 1e-4:\n",
    "            print(\"Induced casting error\")\n",
    "            print(f\"Max value: {np.max(values)}\")\n",
    "            print(f\"Filepath: {filepath}\")\n",
    "            print(f\"Dataset name: {dataset_name}\")\n",
    "\n",
    "\n",
    "# traces = []\n",
    "# for filepath in paths:\n",
    "#     with h5py.File(filepath, \"r+\") as f:\n",
    "#         for _, group in f.items():\n",
    "#             for dataset_name, dataset in list(group.items()):\n",
    "#                 # Extract the values from the dataset\n",
    "#                 values = dataset[:]\n",
    "\n",
    "#                 # Create a violin trace\n",
    "#                 trace = go.Violin(y=values, name=dataset_name)\n",
    "\n",
    "#                 # Add the trace to the data list\n",
    "#                 traces.append(trace)\n",
    "\n",
    "#                 evaluate_casting_error(filepath, dataset_name)\n",
    "\n",
    "#     # Create the layout\n",
    "#     layout = go.Layout(title=\"Violin Plots\", yaxis={\"title\": \"Values\"})\n",
    "\n",
    "#     # Create the figure with the data and layout\n",
    "#     fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "#     # Show the violin plot\n",
    "#     fig.show()\n",
    "#     traces = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f67fa-023c-45a8-b454-99c15d0470b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_descriptive_stats(\n",
    "    df: pd.DataFrame, metadata_df: pd.DataFrame, metadata: Metadata, logdir: Path\n",
    "):\n",
    "    \"\"\"Evaluate the descriptive statistics for a DataFrame.\"\"\"\n",
    "    percentiles = [0.01] + list(np.arange(0.05, 1, 0.05)) + [0.99] + [0.999]\n",
    "    stats_df = df.apply(pd.DataFrame.describe, percentiles=percentiles, axis=1)  # type: ignore\n",
    "    metrics = set(stats_df.columns.values)\n",
    "    stats_df = stats_df.join(metadata_df)  # type: ignore\n",
    "\n",
    "    # Create violin plots, one plot for each metric, and a violin for each assay (per plot)\n",
    "    allowed_metrics = metrics - set([\"count\", \"mean\", \"std\"])\n",
    "    category_orders = {ASSAY: sorted(metadata.label_counter(ASSAY, verbose=False).keys())}\n",
    "    for column in stats_df:\n",
    "        if column not in allowed_metrics:\n",
    "            continue\n",
    "        fig = px.violin(\n",
    "            data_frame=stats_df,\n",
    "            x=column,\n",
    "            y=ASSAY,\n",
    "            box=True,\n",
    "            points=\"all\",\n",
    "            title=f\"Violin plot for {column}\",\n",
    "            color=ASSAY,\n",
    "            category_orders=category_orders,\n",
    "            height=800,\n",
    "            hover_data={\"md5sum\": (df.index)},\n",
    "        )\n",
    "        fig.write_image(logdir / f\"100kb_all_none_hdf5_{column}.png\")\n",
    "        fig.write_html(logdir / f\"100kb_all_none_hdf5_{column}.html\")\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have a list of arrays\n",
    "# hdf5_loader = Hdf5Loader(chrom_file=chromsize_path, normalization=True)\n",
    "# signals = hdf5_loader.load_hdf5s(hdf5_list_path, md5s, strict=True).signals\n",
    "# df = pd.DataFrame.from_dict(signals, orient=\"index\")\n",
    "# # df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
