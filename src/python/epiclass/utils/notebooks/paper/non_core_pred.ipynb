{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Analyze non-core predictions from 9n-nc classifier, all within epiatlas\n",
    "\"\"\"\n",
    "\n",
    "# pylint: disable=import-error, redefined-outer-name, use-dict-literal, too-many-lines, unused-import, unused-argument, too-many-branches, duplicate-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import confusion_matrix as sk_cm\n",
    "\n",
    "from epiclass.core.confusion_matrix import ConfusionMatrixWriter\n",
    "from epiclass.utils.notebooks.paper.paper_utilities import (\n",
    "    ASSAY,\n",
    "    IHECColorMap,\n",
    "    MetadataHandler,\n",
    "    SplitResultsHandler,\n",
    "    add_second_highest_prediction,\n",
    "    display_perc,\n",
    ")\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "base_data_dir = base_dir / \"data\"\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "if not base_fig_dir.exists():\n",
    "    raise FileNotFoundError(f\"Directory {base_fig_dir} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IHECColorMap = IHECColorMap(base_fig_dir)\n",
    "assay_colors = IHECColorMap.assay_color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results_handler = SplitResultsHandler()\n",
    "metadata_handler = MetadataHandler(paper_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_v2_df = metadata_handler.load_metadata_df(\"v2-encode\", merge_assays=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assay epiclass 9c-nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create informative dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = (\n",
    "    base_data_dir / \"training_results/dfreeze_v2/hg38_100kb_all_none_w_encode_noncore\"\n",
    ")\n",
    "results_dir = results_dir / f\"{ASSAY}_1l_3000n\" / \"9c-nc\" / \"10fold-oversampling\"\n",
    "if not results_dir.exists():\n",
    "    raise FileNotFoundError(f\"Directory {results_dir} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = split_results_handler.read_split_results(results_dir)\n",
    "concat_results = split_results_handler.concatenate_split_results(\n",
    "    {\"9c-nc\": results}, concat_first_level=True\n",
    ")[\"9c-nc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = [col for col in concat_results.columns if \"class\" not in col]\n",
    "# pred_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_results = split_results_handler.add_max_pred(concat_results)\n",
    "augmented_results = add_second_highest_prediction(augmented_results, pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_results[\"md5sum\"] = augmented_results.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze non-core pred that are \"mislabels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pred = 0.6\n",
    "pred_mask = augmented_results[\"Max pred\"] >= min_pred\n",
    "nb_pred = pred_mask.sum()\n",
    "print(\n",
    "    f\"Nb pred (pred score >= {min_pred:.02f}): {nb_pred/len(augmented_results) * 100:.02f}% ({nb_pred}/{len(augmented_results)})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save a confusion matrix\n",
    "# df = augmented_results[pred_mask]\n",
    "# cm = sk_cm(df[\"True class\"], df[\"Predicted class\"])\n",
    "# cm_writer = ConfusionMatrixWriter(labels=pred_cols, confusion_matrix=cm)\n",
    "\n",
    "# name = f\"full-10fold-validation_prediction-confusion-matrix-threshold-{min_pred:.02f}\"\n",
    "# cm_writer.to_all_formats(logdir=results_dir, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(augmented_results[\"True class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_pred_df = augmented_results[\n",
    "    (augmented_results[\"Predicted class\"] == \"non-core\")\n",
    "    & (augmented_results[\"Predicted class\"] != augmented_results[\"True class\"])\n",
    "]\n",
    "print(nc_pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_pred_ok_mask = nc_pred_df[\"True class\"] == nc_pred_df[\"2nd pred class\"]\n",
    "print(\n",
    "    f\"Number of non-core predictions mislabels where the second highest prediction is correct: {second_pred_ok_mask.sum()}/{nc_pred_df.shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pred_cols = [col for col in augmented_results.columns if col not in pred_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=consider-using-f-string\n",
    "with pd.option_context(\"display.float_format\", \"{:.3f}\".format):\n",
    "    display(nc_pred_df[~second_pred_ok_mask][non_pred_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "- Nb pred (pred score >= 0.60): 99.17% (20682/20855)\n",
    "- Number of non-core predictions mislabels where the second highest prediction is correct: 24/29\n",
    "- Incorrect 2nd_pred + min_pred >= 0.6: 2/5 (both ctcf)\n",
    "\n",
    "If we also ask for a 1st/2nd prob diff > 0.3, in non-core mislabels, only one CTCF -> h3k4me3 remains. Could be worth to examine this specific file for mislabeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze non-core files predicted as other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_metadata_dir = base_data_dir / \"metadata/encode\"\n",
    "non_core_categories_path = encode_metadata_dir / \"non-core_encode_assay_counts_v1.tsv\"\n",
    "if not non_core_categories_path.exists():\n",
    "    raise FileNotFoundError(f\"File {non_core_categories_path} does not exist.\")\n",
    "\n",
    "non_core_categories_df = pd.read_csv(non_core_categories_path, sep=\"\\t\")\n",
    "print(non_core_categories_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_v2_df.loc[:, \"Assay\"] = metadata_v2_df[\"Assay\"].str.lower().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_pred_df = concat_results[\n",
    "    (concat_results[\"Predicted class\"] != \"non-core\")\n",
    "    & (augmented_results[\"True class\"] == \"non-core\")\n",
    "]\n",
    "for col in [\"True class\", \"Predicted class\"]:\n",
    "    nc_pred_df.loc[:, col] = nc_pred_df[col].str.lower().copy()\n",
    "\n",
    "# print(nc_pred_df.shape)\n",
    "nc_pred_df = nc_pred_df.merge(metadata_v2_df, left_index=True, right_on=\"md5sum\")\n",
    "# print(nc_pred_df.shape)\n",
    "nc_pred_df = nc_pred_df.merge(\n",
    "    non_core_categories_df[[\"assay\", \"assay_category\"]],\n",
    "    left_on=\"Assay\",\n",
    "    right_on=\"assay\",\n",
    "    how=\"left\",\n",
    ")\n",
    "# print(nc_pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(nc_pred_df[\"Predicted class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for predicted_class, group in nc_pred_df.groupby(\"Predicted class\"):\n",
    "    print(f\"\\nPredicted class: {predicted_class}\")\n",
    "    print(group[\"Assay\"].value_counts())\n",
    "\n",
    "    category_counts = group[\"assay_category\"].value_counts(dropna=False)\n",
    "    print(\"\\nAssay categories:\")\n",
    "    print(category_counts)\n",
    "    display_perc((category_counts / category_counts.sum()).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in sorted(nc_pred_df[nc_pred_df[\"assay_category\"] == \"not_looked\"][\"assay\"]):\n",
    "    print(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
