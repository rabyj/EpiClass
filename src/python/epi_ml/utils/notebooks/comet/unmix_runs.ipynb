{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some results from two different groups_second_level_name runs were mixed up, so I need to unmix them.\"\"\"\n",
    "# pylint: disable=import-error,redefined-outer-name,consider-using-f-string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "from comet_ml.api import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_smallest_md5_files(root_dir: str | Path) -> List[Dict[str, int | str | Path]]:\n",
    "    \"\"\"\n",
    "    Traverse the directory structure and identify the smallest .md5 files for each split and set pair.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str | Path): The root directory to start the search.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, int|str|Path]]: A list containing dictionaries with the smallest files for each split and set pair.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    smallest_files = [\n",
    "        {\"split\": i, \"training\": (float(\"inf\"), None), \"validation\": (float(\"inf\"), None)}\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    for file_path in root_path.rglob(\"*.md5\"):\n",
    "        filename = file_path.name\n",
    "        # Extracting split and set information from the filename\n",
    "        if filename.startswith(\"split\") and (\n",
    "            \"_training_\" in filename or \"_validation_\" in filename\n",
    "        ):\n",
    "            split, set_type = filename.split(\"_\")[:2]\n",
    "            split_index = int(split[-1])  # spliti string\n",
    "            file_size = file_path.stat().st_size\n",
    "            if file_size < smallest_files[split_index][set_type][0]:\n",
    "                smallest_files[split_index][set_type] = (file_size, file_path)\n",
    "    return smallest_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recent_md5_files(root_dir: str | Path) -> List[Dict[str, int | str | Path]]:\n",
    "    \"\"\"\n",
    "    Traverse the directory structure and identify the most recent .md5 files for each split and set pair.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str | Path): The root directory to start the search.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, int|str|Path]]: A list containing dictionaries with the recent files for each split and set pair.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    recent_files = [\n",
    "        {\"split\": i, \"training\": (0, None), \"validation\": (0, None)} for i in range(10)\n",
    "    ]\n",
    "    for file_path in root_path.rglob(\"*.md5\"):\n",
    "        filename = file_path.name\n",
    "        # Extracting split and set information from the filename\n",
    "        if filename.startswith(\"split\") and (\n",
    "            \"_training_\" in filename or \"_validation_\" in filename\n",
    "        ):\n",
    "            split, set_type = filename.split(\"_\")[:2]\n",
    "            split_index = int(split[-1])  # spliti string\n",
    "            file_time = int(file_path.stat().st_mtime)\n",
    "            if file_time > recent_files[split_index][set_type][0]:\n",
    "                recent_files[split_index][set_type] = (file_time, file_path)\n",
    "    return recent_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = (\n",
    "    Path.home()\n",
    "    / \"mounts/narval-mount/project-rabyj/epilap/output/logs/epiatlas-dfreeze-v2.1/hg38_100kb_all_none/assay_epiclass_1l_3000n/10fold\"\n",
    ")\n",
    "destination_root_directory = (\n",
    "    Path(root_directory).parents[2]\n",
    "    / \"hg38_100kb_all_none_w_encode_noncore\"\n",
    "    / \"assay_epiclass_1l_3000n\"\n",
    "    / \"10fold\"\n",
    ")\n",
    "print(destination_root_directory, destination_root_directory.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smallest_md5_files = find_smallest_md5_files(root_directory)\n",
    "# print(smallest_md5_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_md5_files = find_recent_md5_files(root_directory)\n",
    "# print(recent_md5_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print all paths\n",
    "# for file_dict in recent_md5_files:\n",
    "#     print(file_dict[\"training\"][1])  # type: ignore\n",
    "#     print(file_dict[\"validation\"][1])  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_files(\n",
    "    files: List[Dict[str, int | str | Path]],\n",
    "    destination_root: str | Path,\n",
    "    delete_original: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Transfer md5 .md5 files to a new directory structure, preserving the original structure.\n",
    "\n",
    "    Args:\n",
    "        smallest_files (List[Dict[str, int|str|Path]]): A list containing dictionaries with the smallest files for each split and set pair.\n",
    "        destination_root (str | Path): The root directory where the files will be transferred to.\n",
    "    \"\"\"\n",
    "    for file_info in files:\n",
    "        split = \"split\" + str(file_info[\"split\"])\n",
    "        for set_type in [\"training\", \"validation\"]:\n",
    "            _, file_path = file_info[set_type]  # type: ignore\n",
    "            if file_path:  # Check if the file path is not None\n",
    "                destination_path: Path = Path(destination_root) / split / file_path.name\n",
    "                os.makedirs(destination_path.parent, exist_ok=True)\n",
    "\n",
    "                shutil.copy2(file_path, destination_path)\n",
    "                if delete_original:\n",
    "                    os.unlink(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transer_results(root: Path, new_root: Path, delete_original: bool = False):\n",
    "    \"\"\"Transfer png, csv and tsv and list files to a new directory structure, preserving the original structure.\"\"\"\n",
    "    for file_path in root.rglob(\"*\"):\n",
    "        if file_path.is_file():\n",
    "            if file_path.suffix in [\".png\", \".csv\", \".tsv\", \".list\"]:\n",
    "                destination_path: Path = Path(new_root) / file_path.relative_to(root)\n",
    "                os.makedirs(destination_path.parent, exist_ok=True)\n",
    "                shutil.copy2(file_path, destination_path)\n",
    "                if delete_original:\n",
    "                    os.unlink(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_files(recent_md5_files, destination_root_directory, delete_original=True)\n",
    "transer_results(root_directory, destination_root_directory, delete_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_to_move = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files_with_strings(\n",
    "    root_dir: str | Path, destination_root: str | Path, strings_list: list\n",
    "):\n",
    "    \"\"\"\n",
    "    Traverse the directory structure and print commands to move files containing any of the specified strings\n",
    "    to a mirrored directory structure.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): The root directory to start the search.\n",
    "        destination_root (str): The root directory where the files will be copied to.\n",
    "        strings_list (list): List of strings to look for in the file paths.\n",
    "    \"\"\"\n",
    "    root_path = Path(root_dir)\n",
    "    for file_path in root_path.rglob(\"*\"):\n",
    "        if (\n",
    "            file_path.is_dir()\n",
    "            and any(s in str(file_path) for s in strings_list)\n",
    "            and len(file_path.name) == 32\n",
    "        ):\n",
    "            relative_path = file_path.relative_to(root_path)\n",
    "            destination_path = Path(destination_root) / relative_path\n",
    "\n",
    "            os.makedirs(destination_path.parent, exist_ok=True)\n",
    "\n",
    "            print(r\"\\mv {} {}\".format(file_path, destination_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just change the base of the paths for the non-mounted one and it will all be good.\n",
    "copy_files_with_strings(root_directory, destination_root_directory, experiments_to_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the cometML API to retrieve saved result files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = API()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in api.get(\"rabyj/epilap\"):\n",
    "    help(experiment)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future, use \"SLURM_JOB_ID\" to select experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_list = []\n",
    "for experiment in api.get(\"rabyj/epilap\"):\n",
    "    if \"assay_epiclass\" not in experiment.get_tags():\n",
    "        continue\n",
    "    meta = experiment.get_metadata()\n",
    "    time = int(meta[\"startTimeMillis\"]) / 1000\n",
    "    time = datetime.utcfromtimestamp(time)\n",
    "    if (\n",
    "        not datetime.fromisoformat(\"2023-08-20\")\n",
    "        < time\n",
    "        < datetime.fromisoformat(\"2023-08-25\")\n",
    "    ):\n",
    "        continue\n",
    "    if (\n",
    "        \"hg38_100kb_all_none-assay_epiclass_1l_3000n-10fold-split\"\n",
    "        in meta[\"experimentName\"]\n",
    "    ):\n",
    "        correct_list.append(experiment.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in [api.get(f\"rabyj/epilap/{key}\") for key in correct_list]:\n",
    "    for info in experiment.get_others_summary():\n",
    "        if \"SLURM_JOB_ID\" == info[\"name\"]:\n",
    "            print(info[\"valueCurrent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in [api.get(f\"rabyj/epilap/{key}\") for key in correct_list]:\n",
    "    exp_name = experiment.get_name()\n",
    "    split_name = exp_name.split(\"-\")[-1]\n",
    "    for asset_dict in experiment.get_asset_list(asset_type=\"all\"):\n",
    "        filename = asset_dict[\"fileName\"]\n",
    "        if (\n",
    "            filename.endswith(\".csv\")\n",
    "            or filename.endswith(\".png\")\n",
    "            or filename.endswith(\".tsv\")\n",
    "        ):\n",
    "            url = asset_dict[\"link\"]\n",
    "            local_filename, _ = urllib.request.urlretrieve(url, filename)\n",
    "            new_path = destination_root_directory / split_name / filename\n",
    "            print(local_filename, new_path)\n",
    "            shutil.move(local_filename, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in [api.get(f\"rabyj/epilap/{key}\") for key in correct_list]:\n",
    "    # print(experiment.get_metadata())\n",
    "    # print(experiment.get_others_summary())\n",
    "    wanted_experiment = True\n",
    "    for param_dict in experiment.get_parameters_summary():\n",
    "        print(param_dict)\n",
    "        break\n",
    "    #     if \"mixed.mixed\" in param_dict.values() and \"mapping\" in param_dict[\"name\"]:\n",
    "    #         wanted_experiment = False\n",
    "\n",
    "    # if wanted_experiment:\n",
    "    #     exp_name = experiment.get_name()\n",
    "    #     split_name = exp_name.split(\"-\")[-1]\n",
    "    #     for asset_dict in experiment.get_asset_list(asset_type=\"all\"):\n",
    "    #         filename = asset_dict[\"fileName\"]\n",
    "    #         if (\n",
    "    #             filename.endswith(\".csv\")\n",
    "    #             or filename.endswith(\".png\")\n",
    "    #             or filename.endswith(\".tsv\")\n",
    "    #         ):\n",
    "    #             url = asset_dict[\"link\"]\n",
    "    #             local_filename, _ = urllib.request.urlretrieve(url, filename)\n",
    "    #             new_path = destination_root_directory / split_name / filename\n",
    "    #             # shutil.move(local_filename, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging last epoch not showing up in dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = API()\n",
    "\n",
    "last_epochs = set()\n",
    "correct_list = []\n",
    "for experiment in api.get(\"rabyj/epilap\"):\n",
    "    last_epoch = experiment.get_metrics(\"Last epoch\")\n",
    "    if last_epoch:\n",
    "        last_epochs.add(last_epoch[0][\"metricValue\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
