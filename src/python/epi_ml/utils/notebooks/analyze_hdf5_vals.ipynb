{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205540cf-84f1-475b-a22c-a8bf67a5d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Notebook to analyze the values in an HDF5 file.\"\"\"\n",
    "# %pip list | grep \"ka\"\n",
    "# pylint: disable=redefined-outer-name, expression-not-assigned, import-error, not-callable, pointless-statement, no-value-for-parameter, undefined-variable, unused-argument, use-dict-literal, too-many-lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49ad09",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521d1af-84f2-46e7-9219-985d8a01a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import tarfile\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import IO, Dict, Iterable, List, Sequence, Tuple\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px  # type: ignore\n",
    "import plotly.graph_objects as go  # type: ignore\n",
    "from plotly.subplots import make_subplots  # type: ignore\n",
    "from scipy import stats\n",
    "\n",
    "from epi_ml.core.data_source import EpiDataSource  # pylint: disable=unused-import\n",
    "from epi_ml.core.epiatlas_treatment import (  # pylint: disable=unused-import\n",
    "    ACCEPTED_TRACKS,\n",
    ")\n",
    "from epi_ml.core.hdf5_loader import Hdf5Loader\n",
    "from epi_ml.core.metadata import Metadata\n",
    "from epi_ml.utils.bed_utils import bed_to_bins, bins_to_bed_ranges\n",
    "\n",
    "ASSAY = \"assay_epiclass\"\n",
    "TRACK_TYPE = \"track_type\"\n",
    "CELL_TYPE = \"harmonized_sample_ontology_intermediate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96127d0d-e528-4524-8a84-12792434cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47618fb8-c3e1-40a5-8390-b01b59431ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = Path(\"/lustre06/project/6007017/rabyj/epilap/input/\")\n",
    "base = Path.home() / \"Projects/epiclass\"\n",
    "input_base = base / \"input\"\n",
    "output_base = base / \"output\"\n",
    "\n",
    "chromsize_path = input_base / \"chromsizes\" / \"hg38.noy.chrom.sizes\"\n",
    "metadata_path = (\n",
    "    input_base\n",
    "    / \"metadata/dfreeze-v2/hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    ")\n",
    "\n",
    "base_logdir = output_base / \"logs\"\n",
    "logdir = base_logdir / \"epiatlas-dfreeze-v2.1/hdf5_stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dir = output_base / \"paper\"\n",
    "table_dir = paper_dir / \"tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsizes: List[Tuple[str, int]] = EpiDataSource.load_external_chrom_file(chromsize_path)\n",
    "\n",
    "chroms: List[str] = sorted([chrom for chrom, _ in chromsizes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = Metadata(metadata_path)\n",
    "metadata_df = metadata.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5d20e",
   "metadata": {},
   "source": [
    "## Global bin metrics analysis\n",
    "\n",
    "e.g. mean/stddev, median/IRQ in raw hdf5 values, or other data like ChromScore or CNV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e275a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_list_path = input_base / \"hdf5_list\" / \"100kb_all_none_10samples.list\"\n",
    "# hdf5_list_path = (\n",
    "#     input_base\n",
    "#     / \"hdf5_list\"\n",
    "#     / \"hg38_2023-01-epiatlas-freeze\"\n",
    "#     / \"100kb_all_none_0blklst.list\"\n",
    "# )\n",
    "\n",
    "# datasource = EpiDataSource(hdf5_list_path, chromsize_path, metadata_path)\n",
    "# my_meta = Metadata(datasource.metadata_file)\n",
    "# my_meta.display_labels(\"track_type\")\n",
    "\n",
    "# my_meta.select_category_subsets(\"track_type\", ACCEPTED_TRACKS)\n",
    "# my_meta.display_labels(\"track_type\")\n",
    "\n",
    "paths = Hdf5Loader.read_list(hdf5_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5_sizes(hdf5_path: Path | str, chroms: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"Read the HDF5 file and return the data.\"\"\"\n",
    "    with h5py.File(hdf5_path, \"r\") as file:\n",
    "        header = list(file.keys())[0]\n",
    "        hdf5_data = file[header]\n",
    "        chrom_lengths = {chrom: len(hdf5_data[chrom][...]) for chrom in chroms}  # type: ignore\n",
    "    return chrom_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = list(paths.values())[0]\n",
    "chr_bin_sizes = read_hdf5_sizes(a_file, chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chr_bin_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_positions(\n",
    "    feature_dict: Dict[str, Sequence[int]],\n",
    "    chr_bin_sizes: Dict[str, int],\n",
    "    output_name: str,\n",
    "    logdir: Path,\n",
    "):\n",
    "    \"\"\"Plot the features into a global genome position plot.\n",
    "\n",
    "    feature_dict: Dict[str, Iterable[int]]: A dictionary of feature names and positions.\n",
    "    chr_bin_sizes: Dict[str, int]: The chromosome sizes. Needs to be matching the feature_dict resolution.\n",
    "    output_name: str: The name of the output file.\n",
    "    logdir: Path: The directory to save the output file.\n",
    "    \"\"\"\n",
    "    layout = go.Layout(autosize=False, width=1500, height=500)\n",
    "    fig = go.Figure(layout=layout)\n",
    "\n",
    "    # Add the features\n",
    "    # Sort features by set size\n",
    "    sorted_features = sorted(\n",
    "        feature_dict.items(), key=lambda item: len(item[1]), reverse=False\n",
    "    )\n",
    "    for i, (feature_name, feature_positions) in enumerate(sorted_features):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=feature_positions,\n",
    "                y=i * np.ones(len(feature_positions)),\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=\"red\", size=2),\n",
    "                name=f\"{feature_name} ({len(feature_positions)})\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Add vertical line for each chrom end\n",
    "    line_position = 0\n",
    "    for i, chrom in enumerate(list(chr_bin_sizes)):\n",
    "        line_position += chr_bin_sizes[chrom]\n",
    "\n",
    "        # Add vertical line for each chromosome, except last one\n",
    "        if i != len(chr_bin_sizes) - 1:\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                xref=\"x\",  # Use the x-axis for positioning\n",
    "                yref=\"paper\",  # Use the figure's relative height for y positioning\n",
    "                x0=line_position,\n",
    "                x1=line_position,\n",
    "                y0=0,  # Start from bottom of the plot area\n",
    "                y1=1,  # Extend to the top of the plot area\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    dash=\"dashdot\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        fig.add_annotation(\n",
    "            x=line_position - 800,  # Position the label at the chromosome boundary\n",
    "            y=1\n",
    "            + 0.05\n",
    "            * (\n",
    "                i % 2\n",
    "            ),  # Adjust the y position to be near the top of the figure; use a relative value within 'paper' coordinate\n",
    "            text=chrom,  # Chromosome label\n",
    "            showarrow=False,  # Do not show an arrow pointing to the annotation\n",
    "            xref=\"x\",  # Use the x-axis for positioning\n",
    "            yref=\"paper\",  # Use the figure's relative height for y positioning\n",
    "            xanchor=\"left\",  # Anchor the text to the left of the x position\n",
    "            yanchor=\"bottom\",  # Anchor the text to the bottom of the y position\n",
    "            font=dict(family=\"Arial\", size=10, color=\"RoyalBlue\"),\n",
    "        )\n",
    "\n",
    "    # Update the layout\n",
    "    fig.update_layout(\n",
    "        title=\"Important feature positions\",\n",
    "        showlegend=False,\n",
    "        xaxis_title=\"Genomic position\",\n",
    "        xaxis=dict(range=[0 - 10, sum(chr_bin_sizes.values()) + 10]),\n",
    "        yaxis_title=\"Set of features\",\n",
    "        yaxis=dict(\n",
    "            tickmode=\"array\",\n",
    "            tickvals=list(range(len(feature_dict))),\n",
    "            ticktext=[\n",
    "                f\"{name} (n={len(features)})\" for name, features in sorted_features\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fig.write_html(logdir / f\"{output_name}.html\")\n",
    "    fig.write_image(logdir / f\"{output_name}.png\")\n",
    "    fig.write_image(logdir / f\"{output_name}.svg\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_important_features_dir = (\n",
    "    Path.home() / \"Projects/epiclass/output/models/SHAP/global_task_features/global_info\"\n",
    ")\n",
    "global_important_features_path = (\n",
    "    global_important_features_dir / \"global_task_features.json\"\n",
    ")\n",
    "with open(global_important_features_path, \"r\", encoding=\"utf8\") as f:\n",
    "    global_important_features = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9121daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_positions(\n",
    "    global_important_features,\n",
    "    chr_bin_sizes,\n",
    "    \"important_features_on_genome\",\n",
    "    logdir=global_important_features_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8dcf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enrichment_per_chrom(\n",
    "    chr_bin_sizes: Dict[str, int], bed_dir: Path\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Compute the enrichment per chromosome of each feature set.\n",
    "\n",
    "    Args:\n",
    "        chr_bin_sizes (Dict[str, int]): The chromosome sizes (number of bins).\n",
    "        bed_dir (Path): The directory containing the bed files of the same resolution.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the relative enrichment values for each feature set across chromosomes.\n",
    "        pd.DataFrame: A DataFrame containing the chromosome bin count for each feature set.\n",
    "    \"\"\"\n",
    "    # Read the bed files\n",
    "    bed_files = list(bed_dir.glob(\"*.bed\"))\n",
    "    chr_count = {}\n",
    "    relative_chr_count = {}\n",
    "    for bed_file in bed_files:\n",
    "        with open(bed_file, \"r\", encoding=\"utf8\") as f:\n",
    "            lines = f.readlines()\n",
    "        set_chr_count = Counter([line.split(\"\\t\")[0] for line in lines])\n",
    "        set_relative_chr_count = {\n",
    "            chrom: count / len(lines) for chrom, count in set_chr_count.items()\n",
    "        }\n",
    "\n",
    "        set_name = str(bed_file.stem).rsplit(\"_\", 1)[0]\n",
    "        chr_count[set_name] = set_chr_count\n",
    "        relative_chr_count[set_name] = set_relative_chr_count\n",
    "\n",
    "    # Chrom relative sizes\n",
    "    relative_chromsize = {\n",
    "        chrom: size / sum(chr_bin_sizes.values()) for chrom, size in chr_bin_sizes.items()\n",
    "    }\n",
    "\n",
    "    # Compute the enrichement\n",
    "    relative_enrichement = {}\n",
    "    for set_name, set_counter in relative_chr_count.items():\n",
    "        relative_enrichement[set_name] = {\n",
    "            chrom: count / relative_chromsize[chrom]\n",
    "            for chrom, count in set_counter.items()\n",
    "        }\n",
    "\n",
    "    relative_enrichement = pd.DataFrame(\n",
    "        data=relative_enrichement, index=list(chr_bin_sizes.keys())\n",
    "    ).transpose()\n",
    "    chr_count = pd.DataFrame(data=chr_count, index=list(chr_bin_sizes.keys())).transpose()\n",
    "    return relative_enrichement, chr_count  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d273d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_dir = global_important_features_dir / \"global_task_features_beds\"\n",
    "enrichment, chr_count = compute_enrichment_per_chrom(chr_bin_sizes, bed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd5d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment.to_csv(global_important_features_dir / \"chromosome_feature_enrichment.csv\")\n",
    "chr_count.to_csv(global_important_features_dir / \"chromosome_feature_count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bin_metrics(npz_file: Path, output_name: str, chr_bin_sizes: Dict[str, int]):\n",
    "    \"\"\"Plot the bin metrics from a numpy file.\"\"\"\n",
    "    with np.load(npz_file) as data:\n",
    "        bin_metrics = {k: data[k] for k in data.files}\n",
    "\n",
    "    means = bin_metrics[\"mean\"]\n",
    "    std_devs = bin_metrics[\"std\"]\n",
    "    medians = bin_metrics[\"median\"]\n",
    "    iqrs = bin_metrics[\"iqr\"]\n",
    "\n",
    "    # subsample values\n",
    "    # means = means\n",
    "    # std_devs = std_devs\n",
    "    # medians = medians\n",
    "    # iqrs = iqrs\n",
    "\n",
    "    # Indices for x-axis, assuming each point's x-coordinate is its index\n",
    "    indices = np.arange(len(means))\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "\n",
    "    # Add scatter plot for means with standard deviation as error bars to the first subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=indices,\n",
    "            y=means,\n",
    "            mode=\"markers\",\n",
    "            name=\"Mean with Std Dev\",\n",
    "            marker=dict(size=1),  # Smaller marker size\n",
    "            error_y=dict(\n",
    "                type=\"data\",\n",
    "                array=std_devs,\n",
    "                visible=True,\n",
    "                thickness=1,  # Thinner error bars\n",
    "                width=2,  # Narrower end caps on error bars\n",
    "            ),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,  # Position of the trace in the subplot grid\n",
    "    )\n",
    "\n",
    "    # Add scatter plot for medians with IQR as error bars to the second subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=indices,\n",
    "            y=medians,\n",
    "            mode=\"markers\",\n",
    "            name=\"Median with IQR\",\n",
    "            marker=dict(size=1),  # Smaller marker size\n",
    "            error_y=dict(\n",
    "                type=\"data\",\n",
    "                array=iqrs / 2,  # Approximation\n",
    "                visible=True,\n",
    "                thickness=1,  # Thinner error bars\n",
    "                width=2,  # Narrower end caps on error bars\n",
    "            ),\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1,  # Position of the trace in the subplot grid\n",
    "    )\n",
    "\n",
    "    # Update layout for clarity\n",
    "    fig.update_layout(\n",
    "        title=\"Separate Metrics with Error Bars\",\n",
    "        xaxis_title=\"Bin position\",\n",
    "        yaxis_title=\"Mean Values\",\n",
    "        legend_title=\"Metric Type\",\n",
    "    )\n",
    "\n",
    "    # Specific labels for the second subplot\n",
    "    fig.update_yaxes(title_text=\"Median Values\", row=2, col=1)\n",
    "\n",
    "    # Add vertical line for each chrom end to both subplots\n",
    "    for row in [1, 2]:\n",
    "        line_position = 0\n",
    "        for chrom in chr_bin_sizes:\n",
    "            line_position += chr_bin_sizes[chrom]\n",
    "            # Add vertical line to the first subplot\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                x0=line_position,\n",
    "                x1=line_position,\n",
    "                y0=0,  # Start from bottom of the plot area\n",
    "                y1=1,  # Extend to the top of the plot area\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    dash=\"dashdot\",\n",
    "                ),\n",
    "                xref=\"x\",  # Reference to the x-axis of the subplot\n",
    "                yref=\"y2 domain\",\n",
    "                row=row,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "            fig.add_annotation(\n",
    "                x=line_position - 1000,  # Position the label at the chromosome boundary\n",
    "                y=0.95,  # Adjust the y position to be near the top of the figure; use a relative value within 'paper' coordinate\n",
    "                text=chrom,  # Chromosome label\n",
    "                showarrow=False,  # Do not show an arrow pointing to the annotation\n",
    "                xref=\"x\",  # Use the x-axis for positioning\n",
    "                yref=\"y2 domain\",  # Use the figure's paper for y positioning\n",
    "                xanchor=\"left\",  # Anchor the text to the left of the x position\n",
    "                yanchor=\"bottom\",  # Anchor the text to the bottom of the y position\n",
    "                font=dict(family=\"Arial\", size=10, color=\"RoyalBlue\"),\n",
    "                row=row,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "    # Show plot\n",
    "    fig.write_html(logdir / f\"{output_name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130dccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_important_features(global_task_features_path) -> Dict[str, List[int]]:\n",
    "    \"\"\"Read the important features from the global task features file.\"\"\"\n",
    "    with open(global_task_features_path, \"r\", encoding=\"utf8\") as file:\n",
    "        important_features = json.load(file)\n",
    "    return important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cancer_important_bins() -> Dict[str, List[int]]:\n",
    "    \"\"\"Read the cancer important bins.\"\"\"\n",
    "    dir_path = Path.home() / \"scratch/epiclass/join_important_features/global_info/cancer\"\n",
    "    index_dict = {}\n",
    "\n",
    "    filepath = (\n",
    "        dir_path / \"cancer_intersection_merge_samplings_bed-details_blood_subset.tsv\"\n",
    "    )\n",
    "    df = pd.read_csv(filepath, names=[\"chr\", \"start\", \"end\", \"bin\", \"details\"], sep=\"\\t\")\n",
    "    index_dict[\"cancer_intersection_merge_sampling_blood_subset\"] = list(df[\"bin\"])\n",
    "\n",
    "    filepath = dir_path / \"cancer_intersection_merge_samplings_bed-details_2.tsv\"\n",
    "    df = pd.read_csv(filepath, names=[\"chr\", \"start\", \"end\", \"bin\", \"details\"], sep=\"\\t\")\n",
    "    index_dict[\"cancer_intersection_merge_sampling\"] = list(df[\"bin\"])\n",
    "\n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d22201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features_metrics(\n",
    "    important_features: Dict[str, List[int]],\n",
    "    npz_file_path: Path,\n",
    "    logdir: Path | None = None,\n",
    "    include_categories: Iterable[str] | None = None,\n",
    ") -> Dict[str, Tuple[int, float, float]]:\n",
    "    \"\"\"Using the important features positions, plot (violin) the mean values according to the given npz file.\n",
    "\n",
    "    Adds a violin for a random feature set of the same size, and one for the global distribution.\n",
    "\n",
    "    Compute the KS test for the random features and the global distribution, and add the p-value to the plot.\n",
    "\n",
    "    Args:\n",
    "    - important_features: A dictionary with category names as keys, and lists of feature positions as values.\n",
    "    - npz_file_path: The path to the npz file containing the bin metrics.\n",
    "    - logdir: The directory where to save the plots.\n",
    "    - include_categories: The categories to include in the plot.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with category names as keys, and tuples of sample size and p-values as values.\n",
    "    \"\"\"\n",
    "    with np.load(npz_file_path) as data:\n",
    "        bin_metrics = {metric: data[metric] for metric in data.keys()}\n",
    "\n",
    "    means = np.array(bin_metrics[\"mean\"], dtype=np.float64)\n",
    "\n",
    "    pvals = {}\n",
    "    for category_name, features_pos in important_features.items():\n",
    "        if include_categories and category_name not in include_categories:\n",
    "            continue\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        selected_features = np.array(\n",
    "            [means[pos] for pos in features_pos], dtype=np.float64\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=selected_features,\n",
    "                name=f\"{category_name} features (N={len(features_pos)})\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"all\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Random features comparison\n",
    "        N = len(features_pos)\n",
    "        np.random.seed(42)\n",
    "        random_features = np.random.choice(means, size=N, replace=False)\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=random_features,\n",
    "                name=f\"Random features (N={N})\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"all\",\n",
    "            )\n",
    "        )\n",
    "        _, pval_random = stats.ks_2samp(selected_features, random_features)\n",
    "        if pval_random < 0.0001:\n",
    "            annot_random = \" << 0.001\"\n",
    "        else:\n",
    "            annot_random = f\" = {pval_random:.3f}\"\n",
    "\n",
    "        # Global distribution comparison\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=means,\n",
    "                name=f\"All features N={len(means)}\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"all\",\n",
    "            )\n",
    "        )\n",
    "        _, pval_global = stats.ks_2samp(selected_features, means)\n",
    "        if pval_global < 0.0001:\n",
    "            annot_global = \" << 0.001\"\n",
    "        else:\n",
    "            annot_global = f\" = {pval_global:.3f}\"\n",
    "\n",
    "        # Annotations for p-values\n",
    "        fig.add_annotation(\n",
    "            x=1,\n",
    "            y=max(random_features) + 0.02,\n",
    "            text=f\"p-val {annot_random} (Selected vs. Random)\",\n",
    "            showarrow=False,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            x=2,\n",
    "            y=max(means) + 0.02,\n",
    "            text=f\"p-val {annot_global} (Selected vs. Global)\",\n",
    "            showarrow=False,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "        )\n",
    "\n",
    "        # Small points\n",
    "        fig.update_traces(marker=dict(size=2))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Mean values for {category_name} features\",\n",
    "            xaxis_title=\"Feature set\",\n",
    "            yaxis_title=\"Mean values\",\n",
    "            violinmode=\"group\",\n",
    "            width=1200,\n",
    "            height=800,\n",
    "        )\n",
    "\n",
    "        # sanity check, pval random vs global\n",
    "        _, pval_random_vs_global = stats.ks_2samp(random_features, means)\n",
    "        if pval_random_vs_global < 0.05:\n",
    "            print(f\"WARNING: pval_random_vs_global: {pval_random_vs_global}\")\n",
    "\n",
    "        pvals[category_name] = (N, pval_random, pval_global, pval_random_vs_global)\n",
    "\n",
    "        if logdir:\n",
    "            fig.write_html(logdir / f\"{npz_file_path.stem}_{category_name}_violin.html\")\n",
    "            fig.write_image(logdir / f\"{npz_file_path.stem}_{category_name}_violin.png\")\n",
    "            fig.write_image(logdir / f\"{npz_file_path.stem}_{category_name}_violin.svg\")\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    return pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa01b8",
   "metadata": {},
   "source": [
    "## SHAP values: important biospecimen regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a3324",
   "metadata": {},
   "source": [
    "### Read important bins values, and find possible classes for each unique bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc553d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = table_dir / \"dfreeze_v2/100kb_all_none/SHAP-MLP/cell_type\"\n",
    "features_file = features_dir / \"select_beds_top303.tar.gz\"\n",
    "\n",
    "ct_important_bins: Dict[str, List[int]] = {}\n",
    "with tarfile.open(features_file, \"r:gz\") as tar:\n",
    "    for member in tar.getmembers():\n",
    "        filename = member.name\n",
    "        if \"merge_samplings\" in filename and filename.endswith(\"bed\"):\n",
    "            file_obj: IO[bytes] = tar.extractfile(member)  # type: ignore\n",
    "\n",
    "            cell_type = (\n",
    "                filename.split(\"/\")[1]\n",
    "                .replace(\"merge_samplings_\", \"\")\n",
    "                .replace(\"_features.bed\", \"\")\n",
    "                .lower()\n",
    "            )\n",
    "            ct_important_bins[cell_type] = bed_to_bins(\n",
    "                file_obj, chroms=chromsizes, resolution=100 * 1000\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bins = set()\n",
    "for bins in ct_important_bins.values():\n",
    "    all_bins.update(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d79380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find relevant cell types for each bin, optimized for pandas future vectorization\n",
    "relevant_pairs_list = []\n",
    "for cell_type, bins_list in ct_important_bins.items():\n",
    "    for bin_idx in bins_list:\n",
    "        relevant_pairs_list.append({\"bin_index\": bin_idx, CELL_TYPE: cell_type})\n",
    "\n",
    "bin_to_relevant_ct_df = pd.DataFrame(relevant_pairs_list)\n",
    "bin_to_relevant_ct_df[\"bin_index\"] = bin_to_relevant_ct_df[\"bin_index\"].astype(int)\n",
    "\n",
    "assert bin_to_relevant_ct_df.shape[0] > len(ct_important_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68986bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bin_to_relevant_ct_df.shape)\n",
    "print(bin_to_relevant_ct_df[\"bin_index\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_cell_types = set(bin_to_relevant_ct_df[CELL_TYPE].unique())\n",
    "assert len(classifier_cell_types) == 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca06d6e",
   "metadata": {},
   "source": [
    "#### Creating a new table with associated genes + cell types for each region.\n",
    "\n",
    "The final desired format is  \n",
    "chr, start, end, cell_types, genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e31d2f",
   "metadata": {},
   "source": [
    "Reformat bin / cell type association to have full bed value and aggregated cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a29d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_ranges = bins_to_bed_ranges(all_bins, chromsizes, resolution=100 * 1000)\n",
    "bin_to_bed_dict = dict(zip(all_bins, bed_ranges))\n",
    "assert (\n",
    "    len(bin_to_bed_dict) == len(all_bins) == bin_to_relevant_ct_df[\"bin_index\"].nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc49ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_to_relevant_ct_df[\"bed_range\"] = bin_to_relevant_ct_df[\"bin_index\"].map(bin_to_bed_dict)  # type: ignore\n",
    "\n",
    "bin_to_relevant_ct_df[[\"chr\", \"start\", \"end\"]] = bin_to_relevant_ct_df[\"bed_range\"].apply(\n",
    "    pd.Series\n",
    ")\n",
    "bin_to_relevant_ct_df.drop(columns=[\"bed_range\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bin_to_relevant_ct_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_ct_df = (\n",
    "    bin_to_relevant_ct_df.groupby([\"bin_index\", \"chr\", \"start\", \"end\"])[CELL_TYPE]\n",
    "    .agg(lambda x: \";\".join(map(str, sorted(set(x)))))\n",
    "    .reset_index()\n",
    "    .rename(\n",
    "        columns={\n",
    "            CELL_TYPE: \"SHAP-MLP_associated_biospecimens\",\n",
    "            \"bin_index\": \"bin_index_100kb\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert grouped_ct_df.shape[0] == grouped_ct_df[\"bin_index_100kb\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee58d5eb",
   "metadata": {},
   "source": [
    "Reformat gff intersection file\n",
    "\n",
    "We will make a version with minimal info, aggregated gene_id + feature_type,  \n",
    "and another version that keeps details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_filepath = features_dir / \"global_union_features_intersect_gff.tsv\"\n",
    "columns = [\n",
    "    \"chromosome\",\n",
    "    \"start_100kb\",\n",
    "    \"end_100kb\",\n",
    "    \"seqname\",\n",
    "    \"source\",\n",
    "    \"feature\",\n",
    "    \"start\",\n",
    "    \"end\",\n",
    "    \"score\",\n",
    "    \"strand\",\n",
    "    \"frame\",\n",
    "    \"attribute\",\n",
    "    \"overlap (bp)\",\n",
    "]\n",
    "gene_intersect_df = pd.read_csv(\n",
    "    gene_intersect_filepath, sep=\"\\t\", header=None, names=columns, index_col=False\n",
    ")\n",
    "\n",
    "# Redundant (seqname) or empty (score,frame)\n",
    "gene_intersect_df = gene_intersect_df.drop(columns=[\"seqname\", \"score\", \"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nb of genes: {gene_intersect_df.shape[0]}\")\n",
    "print(f\"Nb of 100kb regions: {grouped_ct_df['bin_index_100kb'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277a9272",
   "metadata": {},
   "source": [
    "Full details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gff = gene_intersect_df.merge(\n",
    "    grouped_ct_df,\n",
    "    how=\"right\",\n",
    "    left_on=[\"chromosome\", \"start_100kb\", \"end_100kb\"],\n",
    "    right_on=[\"chr\", \"start\", \"end\"],\n",
    "    suffixes=(\"_gff_feature\", \"_ct_df\"),\n",
    ")\n",
    "merged_gff = merged_gff.drop(columns=[\"chr\", \"start_ct_df\", \"end_ct_df\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gff[\"feature_length\"] = (\n",
    "    merged_gff[\"end_gff_feature\"] - merged_gff[\"start_gff_feature\"] + 1\n",
    ")\n",
    "merged_gff[\"overlap (fraction)\"] = (\n",
    "    merged_gff[\"overlap (bp)\"] / merged_gff[\"feature_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a066562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some columns\n",
    "merged_gff.rename(\n",
    "    columns={\"source\": \"gene_DB_source\", \"feature\": \"gene_type\"}, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\n",
    "    \"chromosome\",\n",
    "    \"start_100kb\",\n",
    "    \"end_100kb\",\n",
    "    \"bin_index_100kb\",\n",
    "    \"gene_DB_source\",\n",
    "    \"gene_type\",\n",
    "    \"start_gff_feature\",\n",
    "    \"end_gff_feature\",\n",
    "    \"feature_length\",\n",
    "    \"overlap (bp)\",\n",
    "    \"overlap (fraction)\",\n",
    "    \"SHAP-MLP_associated_biospecimens\",\n",
    "    \"attribute\",\n",
    "]\n",
    "merged_gff = merged_gff[col_order]\n",
    "\n",
    "# Int32 is nullable, not int32\n",
    "merged_gff = merged_gff.astype(\n",
    "    {\n",
    "        \"start_100kb\": \"Int32\",\n",
    "        \"end_100kb\": \"Int32\",\n",
    "        \"bin_index_100kb\": \"Int32\",\n",
    "        \"start_gff_feature\": \"Int32\",\n",
    "        \"end_gff_feature\": \"Int32\",\n",
    "        \"feature_length\": \"Int32\",\n",
    "        \"overlap (bp)\": \"Int32\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80683e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gff.to_csv(\n",
    "    features_dir / \"global_union_features_intersect_gff_with_ct.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd40b85",
   "metadata": {},
   "source": [
    "Minimal details, aggregated gene info.\n",
    "\n",
    "Start by reformating gff intersection file to have one line per region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_df.rename(columns={\"feature\": \"gene_type\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep only relevant columns\n",
    "gene_intersect_df = gene_intersect_df[\n",
    "    [\"chromosome\", \"start_100kb\", \"end_100kb\", \"gene_type\", \"attribute\"]\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63049aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_df[\"attribute\"] = gene_intersect_df[\"attribute\"].str.split(\n",
    "    \";\", expand=True\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a977053",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_intersect_df[\"gene_IDs\"] = gene_intersect_df[\"attribute\"].str.split(\n",
    "    \"ID=gene:\", expand=True\n",
    ")[1]\n",
    "gene_intersect_df.drop(columns=[\"attribute\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_cols = [\"chromosome\", \"start_100kb\", \"end_100kb\"]\n",
    "grouped_gene_df = (\n",
    "    gene_intersect_df.groupby(dup_cols)[[\"gene_IDs\", \"gene_type\"]]\n",
    "    .agg(lambda x: \";\".join(map(str, sorted(set(x)))))\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a46795",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gene_df = grouped_gene_df.merge(\n",
    "    grouped_ct_df,\n",
    "    how=\"right\",\n",
    "    left_on=[\"chromosome\", \"start_100kb\", \"end_100kb\"],\n",
    "    right_on=[\"chr\", \"start\", \"end\"],\n",
    "    suffixes=(\"_gene_df\", \"_ct_df\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_gene_df.drop(columns=[\"chromosome\", \"start_100kb\", \"end_100kb\"], inplace=True)\n",
    "grouped_gene_df.rename(columns={\"start\": \"start_100kb\", \"end\": \"end_100kb\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\n",
    "    \"chr\",\n",
    "    \"start_100kb\",\n",
    "    \"end_100kb\",\n",
    "    \"bin_index_100kb\",\n",
    "    \"SHAP-MLP_associated_biospecimens\",\n",
    "    \"gene_IDs\",\n",
    "    \"gene_type\",\n",
    "]\n",
    "grouped_gene_df = grouped_gene_df[col_order]\n",
    "grouped_gene_df.to_csv(\n",
    "    features_dir / \"global_union_features_intersect_gff_aggregated_with_ct.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a08d2",
   "metadata": {},
   "source": [
    "## ChromScore hdf5 values\n",
    "\n",
    "For each cell type important feature, find the average ChromScore value throughout associated cell types.  \n",
    "If bin is present in multiple classes, just use files for all those classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b05c1e",
   "metadata": {},
   "source": [
    "### Read ChromScore values, and map files to their cell type.\n",
    "\n",
    "Using hdf5 output from `bigwig_metrics.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscore_dir = paper_dir / \"data\" / \"ChromScore\"\n",
    "chromscore_file = chromscore_dir / \"max_metrics.h5\"\n",
    "if not chromscore_file.exists():\n",
    "    print(f\"{chromscore_file} does not exist\")\n",
    "\n",
    "chromscores_df = pd.read_hdf(chromscore_file)\n",
    "print(\"Chromscores shape\", chromscores_df.shape)\n",
    "display(chromscores_df.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742613ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in chromscores_df.columns:\n",
    "    if chromscores_df[col].isna().sum():\n",
    "        print(col, chromscores_df[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2391087",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscores_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae79b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscores_df[\"epirr\"] = chromscores_df.index.str.split(\".\").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from epirr_id_without_version to cell_type\n",
    "epirr_to_cell_type = dict(\n",
    "    metadata_df.loc[:, [\"epirr_id_without_version\", CELL_TYPE]].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7caed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscores_df[CELL_TYPE] = (\n",
    "    chromscores_df[\"epirr\"].map(epirr_to_cell_type).str.replace(\" \", \"_\").str.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58394020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep files from classifier 16ct\n",
    "chromscores_df = chromscores_df[chromscores_df[CELL_TYPE].isin(classifier_cell_types)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62956bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chromscores_df[\"epirr\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c41507",
   "metadata": {},
   "source": [
    "### Find mean chromScore for each bin (for their relevant files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce905e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting global chromscores for future operation, now all values are in one column\n",
    "# Assuming all columns starting with chr are bins, and all 100kb bins are present\n",
    "region_cols_mapper = {\n",
    "    col: idx\n",
    "    for idx, col in enumerate(chromscores_df.columns)\n",
    "    if isinstance(col, str) and col.startswith(\"chr\")\n",
    "}\n",
    "assert len(region_cols_mapper) == 30321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73330f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscores_df.rename(columns=region_cols_mapper, inplace=True)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef4fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_chromscores = chromscores_df.reset_index().rename(columns={\"index\": \"filename\"})\n",
    "melted_chromscores = melted_chromscores.melt(\n",
    "    id_vars=[\"epirr\", CELL_TYPE],\n",
    "    value_vars=list(region_cols_mapper.values()),\n",
    "    var_name=\"bin_index\",\n",
    "    value_name=\"chromscore_value\",\n",
    ")\n",
    "melted_chromscores[\"bin_index\"] = melted_chromscores[\"bin_index\"].astype(int)\n",
    "print(melted_chromscores.shape)\n",
    "print(melted_chromscores[\"bin_index\"].nunique())\n",
    "print(melted_chromscores[\"epirr\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54395752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge melted chromscores with bin_to_relevant_ct_df, efficient for pandas\n",
    "# Filters out all irrelevant bins\n",
    "merged_df = pd.merge(\n",
    "    melted_chromscores, bin_to_relevant_ct_df, on=[\"bin_index\", CELL_TYPE], how=\"inner\"\n",
    ")\n",
    "print(merged_df.shape)\n",
    "print(merged_df[\"bin_index\"].nunique())\n",
    "print(merged_df[\"epirr\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only columns of interest for plotting\n",
    "merged_df = merged_df[[\"epirr\", CELL_TYPE, \"bin_index\", \"chromscore_value\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75059fc",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features_chromscore_global(\n",
    "    avg_selected: pd.DataFrame,\n",
    "    all_avg: pd.DataFrame,\n",
    "    logdir: Path | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot violin for important features and random features.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Important features\n",
    "    print(\"Tracing important features\")\n",
    "    N = len(avg_selected)\n",
    "    fig.add_trace(\n",
    "        go.Box(\n",
    "            y=avg_selected,\n",
    "            name=f\"Important features per biospecimen (N={N})\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            points=False,\n",
    "            spanmode=\"hard\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Random features comparison\n",
    "    print(\"Computing random features\")\n",
    "    np.random.seed(42)\n",
    "    random_features_means = np.random.choice(all_avg, size=N, replace=False)\n",
    "\n",
    "    print(\"Tracing random features\")\n",
    "    N = len(random_features_means)\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            y=random_features_means,\n",
    "            name=f\"Random features, value on all files (N={N})\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            points=False,\n",
    "            spanmode=\"hard\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Global distribution comparison\n",
    "    print(\"Tracing all features\")\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            y=all_avg,\n",
    "            name=f\"All features, all files (N={len(all_avg)})\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            points=False,\n",
    "            spanmode=\"hard\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Important cell type features chromScore\",\n",
    "        xaxis_title=\"Feature set\",\n",
    "        yaxis_title=\"Average max value in selected regions of 100kb\",\n",
    "        violinmode=\"group\",\n",
    "        width=800,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if logdir is not None:\n",
    "        print(\"Saving figure.\")\n",
    "        name = \"important_features_16ct_max_chromscore_100kb\"\n",
    "        fig.write_image(logdir / f\"{name}.svg\")\n",
    "        fig.write_image(logdir / f\"{name}.png\")\n",
    "        fig.write_html(logdir / f\"{name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418aab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg = merged_df.groupby(\"bin_index\")[\"chromscore_value\"].mean()\n",
    "# all_avg = melted_chromscores.groupby(\"bin_index\")[\"chromscore_value\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = paper_dir / \"figures\" / \"chromscore\"\n",
    "if not logdir.exists():\n",
    "    logdir.mkdir(parents=True)\n",
    "\n",
    "# plot_important_features_chromscore_global(\n",
    "#     avg_selected=avg,\n",
    "#     all_avg=all_avg,\n",
    "#     logdir=logdir,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_chromscore_per_biospecimen_data(\n",
    "    selected_bins_df: pd.DataFrame,\n",
    "    all_chromscores_df: pd.DataFrame,\n",
    ") -> Dict[str, Dict[str, List[float] | int]]:\n",
    "    \"\"\"\n",
    "    Prepare plot data for chromscore per biospecimen plot.\n",
    "\n",
    "    Each biospecimen need values for:\n",
    "    - important features\n",
    "    - random features\n",
    "    - global distribution\n",
    "\n",
    "    This is done with independant file subsets.\n",
    "    \"\"\"\n",
    "    total_bins = all_chromscores_df[\"bin_index\"].nunique()\n",
    "\n",
    "    grouped_means = {}\n",
    "\n",
    "    for biospecimen, df in selected_bins_df.groupby(by=CELL_TYPE):\n",
    "        print(f\"Processing {biospecimen}\")\n",
    "\n",
    "        all_chromscores_group = all_chromscores_df.loc[\n",
    "            all_chromscores_df[CELL_TYPE] == biospecimen, :\n",
    "        ]\n",
    "        assert all_chromscores_group[\"chromscore_value\"].isna().sum() == 0\n",
    "        nb_files = df[\"epirr\"].nunique()\n",
    "\n",
    "        # Important features\n",
    "        avg_per_bin = df.groupby(\"bin_index\")[\"chromscore_value\"].mean()\n",
    "        nb_features = len(avg_per_bin)\n",
    "\n",
    "        # Random features\n",
    "        np.random.seed(42)\n",
    "        random_features_idx = np.random.choice(\n",
    "            range(total_bins), size=nb_features, replace=False\n",
    "        )\n",
    "\n",
    "        random_df = all_chromscores_group.loc[\n",
    "            all_chromscores_group[\"bin_index\"].isin(random_features_idx)\n",
    "        ]\n",
    "        random_features_means = random_df.groupby(\"bin_index\")[\"chromscore_value\"].mean()\n",
    "\n",
    "        # Global distribution\n",
    "        all_means_file_subset = all_chromscores_group.groupby(\"bin_index\")[\n",
    "            \"chromscore_value\"\n",
    "        ].mean()\n",
    "\n",
    "        grouped_means[biospecimen] = {\n",
    "            \"avg_per_bin\": avg_per_bin.to_list(),\n",
    "            \"random_features_means\": random_features_means.to_list(),\n",
    "            \"all_means_file_subset\": all_means_file_subset.to_list(),\n",
    "            \"nb_files\": nb_files,\n",
    "        }\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return grouped_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba62aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = prepare_chromscore_per_biospecimen_data(\n",
    "    selected_bins_df=merged_df, all_chromscores_df=melted_chromscores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edd0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chromscore_per_biospecimen(\n",
    "    graph_data: Dict[str, Dict[str, List[float] | int]],\n",
    "    logdir: Path | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot violin for important features and random features,\n",
    "    using regions and files per biospecimen independently.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    colors = px.colors.qualitative.Dark24_r[0:3]\n",
    "\n",
    "    for biospecimen, data in graph_data.items():\n",
    "        avg_per_bin = data[\"avg_per_bin\"]\n",
    "        random_features_means = data[\"random_features_means\"]\n",
    "        all_means_file_subset = data[\"all_means_file_subset\"]\n",
    "\n",
    "        nb_files = data[\"nb_files\"]\n",
    "        nb_features = len(avg_per_bin)\n",
    "\n",
    "        # Important features\n",
    "        group_name = f\"{biospecimen} ({nb_features} features, {nb_files} files)\"\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=avg_per_bin,\n",
    "                name=group_name,\n",
    "                legendgroup=\"SHAP features\",\n",
    "                legendgrouptitle_text=\"SHAP features\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=False,\n",
    "                spanmode=\"hard\",\n",
    "                line_color=colors[0],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Random features comparison\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=random_features_means,\n",
    "                name=group_name,\n",
    "                legendgroup=\"Random features\",\n",
    "                legendgrouptitle_text=\"Random features\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=False,\n",
    "                spanmode=\"hard\",\n",
    "                line_color=colors[1],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Global distribution comparison\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=all_means_file_subset,\n",
    "                name=group_name,\n",
    "                legendgroup=\"All features\",\n",
    "                legendgrouptitle_text=\"All features\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=False,\n",
    "                spanmode=\"hard\",\n",
    "                line_color=colors[2],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"ChromScore per biospecimen file subset\",\n",
    "        xaxis_title=\"Biospecimen\",\n",
    "        yaxis_title=\"Average max value in selected regions of 100kb\",\n",
    "        violinmode=\"group\",\n",
    "        width=1200,\n",
    "        height=1200,\n",
    "        legend_groupclick=\"toggleitem\",\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if logdir is not None:\n",
    "        print(\"Saving figure.\")\n",
    "        name = \"important_features_16ct_max_chromscore_100kb\"\n",
    "        fig.write_image(logdir / f\"{name}.svg\")\n",
    "        fig.write_image(logdir / f\"{name}.png\")\n",
    "        fig.write_html(logdir / f\"{name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_chromscore_per_biospecimen(\n",
    "#     graph_data=graph_data,\n",
    "#     # logdir=logdir,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd33e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chromscore_per_biospecimen_box(\n",
    "    graph_data: Dict[str, Dict[str, List[float] | int]],\n",
    "    logdir: Path | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot boxplots for important features and random features,\n",
    "    using regions and files per biospecimen independently.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    colors = px.colors.qualitative.Dark24_r[0:3]\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=4,\n",
    "        cols=4,\n",
    "        shared_yaxes=True,\n",
    "        vertical_spacing=0.1,\n",
    "        y_title=\"Average max value in selected regions of 100kb\",\n",
    "    )\n",
    "\n",
    "    for idx, (biospecimen, data) in enumerate(graph_data.items()):\n",
    "        avg_per_bin = data[\"avg_per_bin\"]\n",
    "        random_features_means = data[\"random_features_means\"]\n",
    "        all_means_file_subset = data[\"all_means_file_subset\"]\n",
    "\n",
    "        nb_files = data[\"nb_files\"]\n",
    "        nb_features = len(avg_per_bin)\n",
    "\n",
    "        # Important features\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=avg_per_bin,\n",
    "                x=[0] * len(avg_per_bin),\n",
    "                line_color=colors[0],\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "        )\n",
    "\n",
    "        # Random features comparison\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=random_features_means,\n",
    "                x=[1] * len(random_features_means),\n",
    "                line_color=colors[1],\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "        )\n",
    "\n",
    "        # Global distribution comparison\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=all_means_file_subset,\n",
    "                x=[2] * len(all_means_file_subset),\n",
    "                boxpoints=False,\n",
    "                line_color=colors[2],\n",
    "                showlegend=False,\n",
    "            ),\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "        )\n",
    "\n",
    "        pval = stats.ttest_ind(\n",
    "            a=avg_per_bin,\n",
    "            b=all_means_file_subset,\n",
    "            equal_var=False,\n",
    "            alternative=\"greater\",\n",
    "            nan_policy=\"raise\",\n",
    "        ).pvalue\n",
    "\n",
    "        pval_symbol = \"\"\n",
    "        if pval < 0.001:\n",
    "            pval_symbol = \"<0.001***\"\n",
    "        elif pval < 0.01:\n",
    "            pval_symbol = \"<0.01**\"\n",
    "        elif pval < 0.05:\n",
    "            pval_symbol = \"<0.05*\"\n",
    "        elif pval >= 0.05:\n",
    "            pval_symbol = \">0.05 NS\"\n",
    "            print(f\"Warning: pval={pval:.3f} for {biospecimen}\")\n",
    "\n",
    "        group_name = f\"{biospecimen}<br>({nb_features} features, {nb_files} files)<br>pval{pval_symbol}\"\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            showticklabels=False,\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "            title=group_name,\n",
    "        )\n",
    "\n",
    "    # Legend with dummy points\n",
    "    for i, name in zip(\n",
    "        range(3),\n",
    "        [\"Important SHAP features\", \"Random features\", \"All features (whiskers=max/min)\"],\n",
    "    ):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode=\"markers\",\n",
    "                name=name,\n",
    "                legendgroup=name,\n",
    "                showlegend=True,\n",
    "                marker=dict(color=colors[i], symbol=\"square\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"ChromScore per biospecimen file subset\",\n",
    "        width=1200,\n",
    "        height=1200,\n",
    "        legend=dict(\n",
    "            itemsizing=\"constant\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if logdir is not None:\n",
    "        print(\"Saving figure.\")\n",
    "        name = \"important_features_16ct_max_chromscore_100kb_per_biospecimen_boxplot\"\n",
    "        fig.write_image(logdir / f\"{name}.svg\")\n",
    "        fig.write_image(logdir / f\"{name}.png\")\n",
    "        fig.write_html(logdir / f\"{name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc6091",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_chromscore_per_biospecimen_box(\n",
    "    graph_data=graph_data,\n",
    "    logdir=logdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chromscore_per_biospecimen_violin(\n",
    "    graph_data: Dict[str, Dict[str, List[float] | int]],\n",
    "    logdir: Path | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot boxplots for important features and random features,\n",
    "    using regions and files per biospecimen independently.\n",
    "    \"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    colors = px.colors.qualitative.Dark24[0:2]\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=4,\n",
    "        cols=4,\n",
    "        shared_yaxes=True,\n",
    "        vertical_spacing=0.1,\n",
    "        y_title=\"Average max value in selected regions of 100kb\",\n",
    "    )\n",
    "\n",
    "    for idx, (biospecimen, data) in enumerate(graph_data.items()):\n",
    "        avg_per_bin = data[\"avg_per_bin\"]\n",
    "        all_means_file_subset = data[\"all_means_file_subset\"]\n",
    "\n",
    "        nb_files = data[\"nb_files\"]\n",
    "        nb_features = len(avg_per_bin)\n",
    "\n",
    "        # Important features\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                name=\"miaw\",\n",
    "                y=avg_per_bin,\n",
    "                line_color=colors[0],\n",
    "                showlegend=False,\n",
    "                meanline_visible=True,\n",
    "                points=False,\n",
    "                spanmode=\"hard\",\n",
    "                side=\"negative\",\n",
    "            ),\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "        )\n",
    "\n",
    "        # Global distribution comparison\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                name=\"miaw\",\n",
    "                y=all_means_file_subset,\n",
    "                line_color=colors[1],\n",
    "                showlegend=False,\n",
    "                meanline_visible=True,\n",
    "                points=False,\n",
    "                spanmode=\"hard\",\n",
    "                side=\"positive\",\n",
    "            ),\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "        )\n",
    "\n",
    "        pval = stats.ttest_ind(\n",
    "            a=avg_per_bin,\n",
    "            b=all_means_file_subset,\n",
    "            equal_var=False,\n",
    "            alternative=\"greater\",\n",
    "            nan_policy=\"raise\",\n",
    "        ).pvalue\n",
    "\n",
    "        pval_symbol = \"\"\n",
    "        if pval < 0.001:\n",
    "            pval_symbol = \"<0.001***\"\n",
    "        elif pval < 0.01:\n",
    "            pval_symbol = \"<0.01**\"\n",
    "        elif pval < 0.05:\n",
    "            pval_symbol = \"<0.05*\"\n",
    "        elif pval >= 0.05:\n",
    "            pval_symbol = \">0.05 NS\"\n",
    "            print(f\"Warning: pval={pval:.3f} for {biospecimen}\")\n",
    "\n",
    "        group_name = f\"{biospecimen}<br>({nb_features} features, {nb_files} files)<br>pval{pval_symbol}\"\n",
    "\n",
    "        fig.update_xaxes(\n",
    "            showticklabels=False,\n",
    "            row=idx // 4 + 1,\n",
    "            col=idx % 4 + 1,\n",
    "            title=group_name,\n",
    "        )\n",
    "\n",
    "    # Legend with dummy points\n",
    "    for i, name in enumerate([\"Important SHAP features\", \"All features\"]):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode=\"markers\",\n",
    "                name=name,\n",
    "                legendgroup=name,\n",
    "                showlegend=True,\n",
    "                marker=dict(color=colors[i], symbol=\"square\"),\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"ChromScore per biospecimen file subset\",\n",
    "        width=1200,\n",
    "        height=1200,\n",
    "        legend=dict(\n",
    "            itemsizing=\"constant\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if logdir is not None:\n",
    "        print(\"Saving figure.\")\n",
    "        name = \"important_features_16ct_max_chromscore_100kb_per_biospecimen_2violin\"\n",
    "        fig.write_image(logdir / f\"{name}.svg\")\n",
    "        fig.write_image(logdir / f\"{name}.png\")\n",
    "        fig.write_html(logdir / f\"{name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_chromscore_per_biospecimen_violin(\n",
    "    graph_data=graph_data,\n",
    "    logdir=logdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84fde93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features_chromscore_box_matplotlib(\n",
    "    selected_features: pd.DataFrame,\n",
    "    all_features: pd.DataFrame,\n",
    "    logdir: Path | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot boxplot for important features, random features, and all features using Matplotlib.\n",
    "    \"\"\"\n",
    "    # --- Data Preparation ---\n",
    "    print(\"Preparing data\")\n",
    "    # Important features\n",
    "    y_selected = selected_features[\n",
    "        \"chromscore_value\"\n",
    "    ].dropna()  # Important to drop NaNs for boxplot\n",
    "\n",
    "    # Random features comparison\n",
    "    np.random.seed(42)\n",
    "    N_unique_features = selected_features[\"bin_index\"].nunique()\n",
    "    # Ensure we don't try to sample more unique features than available\n",
    "    N_all_unique_features = all_features[\"bin_index\"].nunique()\n",
    "    sample_size = min(N_unique_features, N_all_unique_features)\n",
    "\n",
    "    # Get unique bin_index values from all_features to sample from\n",
    "    all_unique_bin_indices = all_features[\"bin_index\"].unique()\n",
    "    random_bin_indices = np.random.choice(\n",
    "        all_unique_bin_indices, size=sample_size, replace=False\n",
    "    )\n",
    "    y_random = all_features.loc[\n",
    "        all_features[\"bin_index\"].isin(random_bin_indices), \"chromscore_value\"\n",
    "    ].dropna()\n",
    "\n",
    "    # Global distribution comparison\n",
    "    y_all = all_features[\"chromscore_value\"].dropna()\n",
    "\n",
    "    data_to_plot = [y_selected, y_random, y_all]\n",
    "\n",
    "    # --- Labels for the boxes ---\n",
    "    # Using \\n for line breaks in labels to make them more readable if long\n",
    "    labels = [\n",
    "        f\"Important features\\nper biospecimen (N={len(y_selected)})\",\n",
    "        f\"Random features\\n(N={len(y_random)})\",  # Simplified label a bit\n",
    "        f\"All features\\nall files (N={len(y_all)})\",\n",
    "    ]\n",
    "\n",
    "    # --- Plotting ---\n",
    "    print(\"Plotting\")\n",
    "    fig, ax = plt.subplots(\n",
    "        figsize=(10, 7)\n",
    "    )  # Adjust figsize as needed (width, height in inches)\n",
    "\n",
    "    # Create the boxplot\n",
    "    # patch_artist=True allows filling boxes with color if desired later\n",
    "    # showfliers=False mimics boxpoints=False if outliers are not desired\n",
    "    _ = ax.boxplot(data_to_plot, labels=labels, showfliers=False)\n",
    "\n",
    "    # --- Customization ---\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(\"Important cell type features chromScore\", fontsize=16)\n",
    "    ax.set_xlabel(\"Feature set\", fontsize=14)\n",
    "    ax.set_ylabel(\"Average max value in selected regions of 100kb\", fontsize=14)\n",
    "\n",
    "    # Improve layout to prevent labels from overlapping\n",
    "    plt.xticks(fontsize=10)  # Adjust x-tick label font size\n",
    "    plt.yticks(fontsize=10)\n",
    "    fig.tight_layout()  # Adjusts plot to ensure everything fits without overlapping\n",
    "\n",
    "    # --- Display and Save ---\n",
    "    # print(\"Displaying Matplotlib figure\")\n",
    "    # plt.show()\n",
    "\n",
    "    print(\"Saving Matplotlib figure\")\n",
    "    if logdir is not None:\n",
    "        logdir.mkdir(parents=True, exist_ok=True)  # Ensure logdir exists\n",
    "        name = \"important_features_16ct_max_chromscore_100kb_matplotlib\"  # Added suffix\n",
    "        print(f\"Saving Matplotlib figure to {logdir}\")\n",
    "        try:\n",
    "            # fig.savefig(logdir / f\"{name}.svg\", bbox_inches='tight')\n",
    "            fig.savefig(logdir / f\"{name}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        except Exception as e:  # pylint: disable=broad-except\n",
    "            print(f\"Error saving figure: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_important_features_chromscore_box_matplotlib(\n",
    "    selected_features=merged_df, all_features=melted_chromscores, logdir=logdir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c786ae",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_md5s_path = input_base / \"hdf5_list\" / \"md5_shap_assay_explain.list\"\n",
    "# with open(shap_md5s_path, \"r\", encoding=\"utf8\") as f:\n",
    "#     shap_md5s = set(f.read().splitlines())\n",
    "\n",
    "\n",
    "def analyze_feature_vals(\n",
    "    regions_dict: Dict[int, Tuple],\n",
    "    md5s: List[str],\n",
    "    hdf5_list: Path,\n",
    "    logdir: Path,\n",
    "    name: str,\n",
    "    shap_md5s: List[str],\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate and save a violin plot of provided feature values for the provided md5s, with some md5s highlighted.\n",
    "\n",
    "    This function takes as input a list of md5s and a dictionary of regions, and generates a violin plot\n",
    "    of the feature values for these md5s. It also highlights specific md5s by adding lines+markers for them.\n",
    "    The function saves the plot as an HTML file and a PNG file in the provided log directory.\n",
    "\n",
    "    Args:\n",
    "        regions_dict (Dict[int, Tuple]): A dictionary mapping region indices to their respective genomic coordinates.\n",
    "        md5s (List[str]): A list of md5s to analyze.\n",
    "        hdf5_list (Path): Path to the list of hdf5 files to be used.\n",
    "        logdir (Path): Directory where the resulting plot should be saved.\n",
    "        name (str): Name used to save the resulting plot (will be part of the filename).\n",
    "    \"\"\"\n",
    "    hdf5_loader = Hdf5Loader(chrom_file=chromsize_path, normalization=True)\n",
    "    hdf5_loader.load_hdf5s(hdf5_list, md5s, strict=True)\n",
    "    N = len(hdf5_loader.signals)\n",
    "\n",
    "    nb_highlight = 3\n",
    "    highlight_md5s = list(set(md5s) & set(shap_md5s))[0:nb_highlight]\n",
    "\n",
    "    traces = []\n",
    "    highlight_values = {highlight_md5: [] for highlight_md5 in highlight_md5s}\n",
    "    for region, region_bed in regions_dict.items():\n",
    "        values = [signal[region] for signal in hdf5_loader.signals.values()]\n",
    "        region_str = f\"{region_bed[0]}:{region_bed[1]}-{region_bed[2]}\"\n",
    "\n",
    "        trace = go.Violin(\n",
    "            y=values,\n",
    "            name=region_str,\n",
    "            points=\"all\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "        for highlight_md5 in highlight_md5s:\n",
    "            highlight_value = hdf5_loader.signals[highlight_md5][region]\n",
    "            highlight_values[highlight_md5].append((region_str, highlight_value))\n",
    "\n",
    "    for (highlight_md5, highlight_value), marker_format in zip(\n",
    "        highlight_values.items(),\n",
    "        [[\"cross\", \"black\"], [\"circle\", \"blue\"], [\"diamond\", \"red\"]],\n",
    "    ):\n",
    "        x, y = zip(*highlight_value)\n",
    "        symbol, color = marker_format\n",
    "        highlight_trace = go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"lines+markers\",\n",
    "            name=f\"{highlight_md5}\",\n",
    "            marker={\"size\": 6, \"symbol\": symbol, \"color\": color},\n",
    "        )\n",
    "        traces.append(highlight_trace)\n",
    "\n",
    "    # Create the layout\n",
    "    layout = go.Layout(\n",
    "        title=f\"Feature values distributions for {N} {name} samples (0blklst)\",\n",
    "        yaxis={\"title\": \"z-score\"},\n",
    "        xaxis={\"title\": \"Region\"},\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Create the figure with the data and layout\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    fig.write_html(logdir / f\"feature_values_{name}.html\")\n",
    "\n",
    "    width = 1200\n",
    "    fig.write_image(\n",
    "        logdir / f\"feature_values_{name}.png\", width=width, height=width * 3 / 4\n",
    "    )\n",
    "    # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_file(md5, zscore: bool = True):\n",
    "    \"\"\"Produce a violin plot (save to html) of all feature values for a single sample.\"\"\"\n",
    "    if zscore:\n",
    "        mode = \"z-scores\"\n",
    "    else:\n",
    "        mode = \"raw values\"\n",
    "\n",
    "    hdf5_loader = Hdf5Loader(chrom_file=chromsize_path, normalization=zscore)\n",
    "    signals = hdf5_loader.load_hdf5s(hdf5_list_path, [md5], strict=True).signals\n",
    "\n",
    "    fig = px.violin(\n",
    "        data_frame=list(signals.values())[0],\n",
    "        box=True,\n",
    "        points=\"all\",\n",
    "        title=f\"Violin plot for {md5} {mode}\",\n",
    "    )\n",
    "    fig.write_html(f\"{md5}-{mode}.html\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_casting_error(filepath: Path | str, dataset_name: str):\n",
    "    \"\"\"Evaluate the casting error for a specific dataset in an HDF5 file.\"\"\"\n",
    "    with h5py.File(filepath, \"r\") as f:\n",
    "        dataset: h5py.Dataset = f[dataset_name]  # type: ignore\n",
    "        values: np.ndarray = dataset[:]  # type: ignore\n",
    "\n",
    "        # Cast to float32 and compare max diff\n",
    "        casted_dataset = dataset.astype(np.float32)[:]\n",
    "        diff = np.abs(casted_dataset - values)\n",
    "        max_diff = np.max(diff)\n",
    "        print(f\"Max diff when casting: {max_diff}\")\n",
    "        if max_diff > 1e-4:\n",
    "            print(\"Induced casting error\")\n",
    "            print(f\"Max value: {np.max(values)}\")\n",
    "            print(f\"Filepath: {filepath}\")\n",
    "            print(f\"Dataset name: {dataset_name}\")\n",
    "\n",
    "\n",
    "# traces = []\n",
    "# for filepath in paths:\n",
    "#     with h5py.File(filepath, \"r+\") as f:\n",
    "#         for _, group in f.items():\n",
    "#             for dataset_name, dataset in list(group.items()):\n",
    "#                 # Extract the values from the dataset\n",
    "#                 values = dataset[:]\n",
    "\n",
    "#                 # Create a violin trace\n",
    "#                 trace = go.Violin(y=values, name=dataset_name)\n",
    "\n",
    "#                 # Add the trace to the data list\n",
    "#                 traces.append(trace)\n",
    "\n",
    "#                 evaluate_casting_error(filepath, dataset_name)\n",
    "\n",
    "#     # Create the layout\n",
    "#     layout = go.Layout(title=\"Violin Plots\", yaxis={\"title\": \"Values\"})\n",
    "\n",
    "#     # Create the figure with the data and layout\n",
    "#     fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "#     # Show the violin plot\n",
    "#     fig.show()\n",
    "#     traces = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f67fa-023c-45a8-b454-99c15d0470b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_descriptive_stats(\n",
    "    df: pd.DataFrame, metadata_df: pd.DataFrame, metadata: Metadata, logdir: Path\n",
    "):\n",
    "    \"\"\"Evaluate the descriptive statistics for a DataFrame.\"\"\"\n",
    "    percentiles = [0.01] + list(np.arange(0.05, 1, 0.05)) + [0.99] + [0.999]\n",
    "    stats_df = df.apply(pd.DataFrame.describe, percentiles=percentiles, axis=1)  # type: ignore\n",
    "    metrics = set(stats_df.columns.values)\n",
    "    stats_df = stats_df.join(metadata_df)  # type: ignore\n",
    "\n",
    "    # Create violin plots, one plot for each metric, and a violin for each assay (per plot)\n",
    "    allowed_metrics = metrics - set([\"count\", \"mean\", \"std\"])\n",
    "    category_orders = {ASSAY: sorted(metadata.label_counter(ASSAY, verbose=False).keys())}\n",
    "    for column in stats_df:\n",
    "        if column not in allowed_metrics:\n",
    "            continue\n",
    "        fig = px.violin(\n",
    "            data_frame=stats_df,\n",
    "            x=column,\n",
    "            y=ASSAY,\n",
    "            box=True,\n",
    "            points=\"all\",\n",
    "            title=f\"Violin plot for {column}\",\n",
    "            color=ASSAY,\n",
    "            category_orders=category_orders,\n",
    "            height=800,\n",
    "            hover_data={\"md5sum\": (df.index)},\n",
    "        )\n",
    "        fig.write_image(logdir / f\"100kb_all_none_hdf5_{column}.png\")\n",
    "        fig.write_html(logdir / f\"100kb_all_none_hdf5_{column}.html\")\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have a list of arrays\n",
    "# hdf5_loader = Hdf5Loader(chrom_file=chromsize_path, normalization=True)\n",
    "# signals = hdf5_loader.load_hdf5s(hdf5_list_path, md5s, strict=True).signals\n",
    "# df = pd.DataFrame.from_dict(signals, orient=\"index\")\n",
    "# # df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
