{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205540cf-84f1-475b-a22c-a8bf67a5d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Notebook to analyze the values in an HDF5 file.\"\"\"\n",
    "# %pip list | grep \"ka\"\n",
    "# pylint: disable=redefined-outer-name, expression-not-assigned, import-error, not-callable, pointless-statement, no-value-for-parameter, undefined-variable, unused-argument, use-dict-literal, too-many-lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49ad09",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521d1af-84f2-46e7-9219-985d8a01a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import tarfile\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import IO, Dict, Iterable, List, Sequence, Tuple\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px  # type: ignore\n",
    "import plotly.graph_objects as go  # type: ignore\n",
    "from plotly.subplots import make_subplots  # type: ignore\n",
    "from scipy import stats\n",
    "\n",
    "from epi_ml.core.data_source import EpiDataSource  # pylint: disable=unused-import\n",
    "from epi_ml.core.epiatlas_treatment import (  # pylint: disable=unused-import\n",
    "    ACCEPTED_TRACKS,\n",
    ")\n",
    "from epi_ml.core.hdf5_loader import Hdf5Loader\n",
    "from epi_ml.core.metadata import Metadata\n",
    "from epi_ml.utils.bed_utils import bed_to_bins\n",
    "\n",
    "ASSAY = \"assay_epiclass\"\n",
    "TRACK_TYPE = \"track_type\"\n",
    "CELL_TYPE = \"harmonized_sample_ontology_intermediate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96127d0d-e528-4524-8a84-12792434cb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47618fb8-c3e1-40a5-8390-b01b59431ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = Path(\"/lustre06/project/6007017/rabyj/epilap/input/\")\n",
    "base = Path.home() / \"Projects/epiclass\"\n",
    "input_base = base / \"input\"\n",
    "output_base = base / \"output\"\n",
    "\n",
    "chromsize_path = input_base / \"chromsizes\" / \"hg38.noy.chrom.sizes\"\n",
    "metadata_path = (\n",
    "    input_base\n",
    "    / \"metadata/dfreeze-v2/hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    ")\n",
    "\n",
    "base_logdir = output_base / \"logs\"\n",
    "logdir = base_logdir / \"epiatlas-dfreeze-v2.1/hdf5_stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dir = output_base / \"paper\"\n",
    "table_dir = paper_dir / \"tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36f7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsizes = EpiDataSource.load_external_chrom_file(chromsize_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms = Hdf5Loader.load_chroms(chromsize_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = Metadata(metadata_path)\n",
    "metadata_df = metadata.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea5d20e",
   "metadata": {},
   "source": [
    "## Global bin metrics analysis\n",
    "\n",
    "e.g. mean/stddev, median/IRQ in raw hdf5 values, or other data like ChromScore or CNV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e275a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_list_path = input_base / \"hdf5_list\" / \"100kb_all_none_10samples.list\"\n",
    "# hdf5_list_path = (\n",
    "#     input_base\n",
    "#     / \"hdf5_list\"\n",
    "#     / \"hg38_2023-01-epiatlas-freeze\"\n",
    "#     / \"100kb_all_none_0blklst.list\"\n",
    "# )\n",
    "\n",
    "# datasource = EpiDataSource(hdf5_list_path, chromsize_path, metadata_path)\n",
    "# my_meta = Metadata(datasource.metadata_file)\n",
    "# my_meta.display_labels(\"track_type\")\n",
    "\n",
    "# my_meta.select_category_subsets(\"track_type\", ACCEPTED_TRACKS)\n",
    "# my_meta.display_labels(\"track_type\")\n",
    "\n",
    "paths = Hdf5Loader.read_list(hdf5_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hdf5_sizes(hdf5_path: Path | str, chroms: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"Read the HDF5 file and return the data.\"\"\"\n",
    "    with h5py.File(hdf5_path, \"r\") as file:\n",
    "        header = list(file.keys())[0]\n",
    "        hdf5_data = file[header]\n",
    "        chrom_lengths = {chrom: len(hdf5_data[chrom][...]) for chrom in chroms}  # type: ignore\n",
    "    return chrom_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = list(paths.values())[0]\n",
    "chr_bin_sizes = read_hdf5_sizes(a_file, chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chr_bin_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_positions(\n",
    "    feature_dict: Dict[str, Sequence[int]],\n",
    "    chr_bin_sizes: Dict[str, int],\n",
    "    output_name: str,\n",
    "    logdir: Path,\n",
    "):\n",
    "    \"\"\"Plot the features into a global genome position plot.\n",
    "\n",
    "    feature_dict: Dict[str, Iterable[int]]: A dictionary of feature names and positions.\n",
    "    chr_bin_sizes: Dict[str, int]: The chromosome sizes. Needs to be matching the feature_dict resolution.\n",
    "    output_name: str: The name of the output file.\n",
    "    logdir: Path: The directory to save the output file.\n",
    "    \"\"\"\n",
    "    layout = go.Layout(autosize=False, width=1500, height=500)\n",
    "    fig = go.Figure(layout=layout)\n",
    "\n",
    "    # Add the features\n",
    "    # Sort features by set size\n",
    "    sorted_features = sorted(\n",
    "        feature_dict.items(), key=lambda item: len(item[1]), reverse=False\n",
    "    )\n",
    "    for i, (feature_name, feature_positions) in enumerate(sorted_features):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=feature_positions,\n",
    "                y=i * np.ones(len(feature_positions)),\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=\"red\", size=2),\n",
    "                name=f\"{feature_name} ({len(feature_positions)})\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Add vertical line for each chrom end\n",
    "    line_position = 0\n",
    "    for i, chrom in enumerate(list(chr_bin_sizes)):\n",
    "        line_position += chr_bin_sizes[chrom]\n",
    "\n",
    "        # Add vertical line for each chromosome, except last one\n",
    "        if i != len(chr_bin_sizes) - 1:\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                xref=\"x\",  # Use the x-axis for positioning\n",
    "                yref=\"paper\",  # Use the figure's relative height for y positioning\n",
    "                x0=line_position,\n",
    "                x1=line_position,\n",
    "                y0=0,  # Start from bottom of the plot area\n",
    "                y1=1,  # Extend to the top of the plot area\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    dash=\"dashdot\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        fig.add_annotation(\n",
    "            x=line_position - 800,  # Position the label at the chromosome boundary\n",
    "            y=1\n",
    "            + 0.05\n",
    "            * (\n",
    "                i % 2\n",
    "            ),  # Adjust the y position to be near the top of the figure; use a relative value within 'paper' coordinate\n",
    "            text=chrom,  # Chromosome label\n",
    "            showarrow=False,  # Do not show an arrow pointing to the annotation\n",
    "            xref=\"x\",  # Use the x-axis for positioning\n",
    "            yref=\"paper\",  # Use the figure's relative height for y positioning\n",
    "            xanchor=\"left\",  # Anchor the text to the left of the x position\n",
    "            yanchor=\"bottom\",  # Anchor the text to the bottom of the y position\n",
    "            font=dict(family=\"Arial\", size=10, color=\"RoyalBlue\"),\n",
    "        )\n",
    "\n",
    "    # Update the layout\n",
    "    fig.update_layout(\n",
    "        title=\"Important feature positions\",\n",
    "        showlegend=False,\n",
    "        xaxis_title=\"Genomic position\",\n",
    "        xaxis=dict(range=[0 - 10, sum(chr_bin_sizes.values()) + 10]),\n",
    "        yaxis_title=\"Set of features\",\n",
    "        yaxis=dict(\n",
    "            tickmode=\"array\",\n",
    "            tickvals=list(range(len(feature_dict))),\n",
    "            ticktext=[\n",
    "                f\"{name} (n={len(features)})\" for name, features in sorted_features\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fig.write_html(logdir / f\"{output_name}.html\")\n",
    "    fig.write_image(logdir / f\"{output_name}.png\")\n",
    "    fig.write_image(logdir / f\"{output_name}.svg\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_important_features_dir = (\n",
    "    Path.home() / \"Projects/epiclass/output/models/SHAP/global_task_features/global_info\"\n",
    ")\n",
    "global_important_features_path = (\n",
    "    global_important_features_dir / \"global_task_features.json\"\n",
    ")\n",
    "with open(global_important_features_path, \"r\", encoding=\"utf8\") as f:\n",
    "    global_important_features = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9121daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_positions(\n",
    "    global_important_features,\n",
    "    chr_bin_sizes,\n",
    "    \"important_features_on_genome\",\n",
    "    logdir=global_important_features_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8dcf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enrichment_per_chrom(\n",
    "    chr_bin_sizes: Dict[str, int], bed_dir: Path\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Compute the enrichment per chromosome of each feature set.\n",
    "\n",
    "    Args:\n",
    "        chr_bin_sizes (Dict[str, int]): The chromosome sizes (number of bins).\n",
    "        bed_dir (Path): The directory containing the bed files of the same resolution.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the relative enrichment values for each feature set across chromosomes.\n",
    "        pd.DataFrame: A DataFrame containing the chromosome bin count for each feature set.\n",
    "    \"\"\"\n",
    "    # Read the bed files\n",
    "    bed_files = list(bed_dir.glob(\"*.bed\"))\n",
    "    chr_count = {}\n",
    "    relative_chr_count = {}\n",
    "    for bed_file in bed_files:\n",
    "        with open(bed_file, \"r\", encoding=\"utf8\") as f:\n",
    "            lines = f.readlines()\n",
    "        set_chr_count = Counter([line.split(\"\\t\")[0] for line in lines])\n",
    "        set_relative_chr_count = {\n",
    "            chrom: count / len(lines) for chrom, count in set_chr_count.items()\n",
    "        }\n",
    "\n",
    "        set_name = str(bed_file.stem).rsplit(\"_\", 1)[0]\n",
    "        chr_count[set_name] = set_chr_count\n",
    "        relative_chr_count[set_name] = set_relative_chr_count\n",
    "\n",
    "    # Chrom relative sizes\n",
    "    relative_chromsize = {\n",
    "        chrom: size / sum(chr_bin_sizes.values()) for chrom, size in chr_bin_sizes.items()\n",
    "    }\n",
    "\n",
    "    # Compute the enrichement\n",
    "    relative_enrichement = {}\n",
    "    for set_name, set_counter in relative_chr_count.items():\n",
    "        relative_enrichement[set_name] = {\n",
    "            chrom: count / relative_chromsize[chrom]\n",
    "            for chrom, count in set_counter.items()\n",
    "        }\n",
    "\n",
    "    relative_enrichement = pd.DataFrame(\n",
    "        data=relative_enrichement, index=list(chr_bin_sizes.keys())\n",
    "    ).transpose()\n",
    "    chr_count = pd.DataFrame(data=chr_count, index=list(chr_bin_sizes.keys())).transpose()\n",
    "    return relative_enrichement, chr_count  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d273d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_dir = global_important_features_dir / \"global_task_features_beds\"\n",
    "enrichment, chr_count = compute_enrichment_per_chrom(chr_bin_sizes, bed_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd5d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment.to_csv(global_important_features_dir / \"chromosome_feature_enrichment.csv\")\n",
    "chr_count.to_csv(global_important_features_dir / \"chromosome_feature_count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bin_metrics(npz_file: Path, output_name: str, chr_bin_sizes: Dict[str, int]):\n",
    "    \"\"\"Plot the bin metrics from a numpy file.\"\"\"\n",
    "    with np.load(npz_file) as data:\n",
    "        bin_metrics = {k: data[k] for k in data.files}\n",
    "\n",
    "    means = bin_metrics[\"mean\"]\n",
    "    std_devs = bin_metrics[\"std\"]\n",
    "    medians = bin_metrics[\"median\"]\n",
    "    iqrs = bin_metrics[\"iqr\"]\n",
    "\n",
    "    # subsample values\n",
    "    # means = means\n",
    "    # std_devs = std_devs\n",
    "    # medians = medians\n",
    "    # iqrs = iqrs\n",
    "\n",
    "    # Indices for x-axis, assuming each point's x-coordinate is its index\n",
    "    indices = np.arange(len(means))\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True)\n",
    "\n",
    "    # Add scatter plot for means with standard deviation as error bars to the first subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=indices,\n",
    "            y=means,\n",
    "            mode=\"markers\",\n",
    "            name=\"Mean with Std Dev\",\n",
    "            marker=dict(size=1),  # Smaller marker size\n",
    "            error_y=dict(\n",
    "                type=\"data\",\n",
    "                array=std_devs,\n",
    "                visible=True,\n",
    "                thickness=1,  # Thinner error bars\n",
    "                width=2,  # Narrower end caps on error bars\n",
    "            ),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,  # Position of the trace in the subplot grid\n",
    "    )\n",
    "\n",
    "    # Add scatter plot for medians with IQR as error bars to the second subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=indices,\n",
    "            y=medians,\n",
    "            mode=\"markers\",\n",
    "            name=\"Median with IQR\",\n",
    "            marker=dict(size=1),  # Smaller marker size\n",
    "            error_y=dict(\n",
    "                type=\"data\",\n",
    "                array=iqrs / 2,  # Approximation\n",
    "                visible=True,\n",
    "                thickness=1,  # Thinner error bars\n",
    "                width=2,  # Narrower end caps on error bars\n",
    "            ),\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1,  # Position of the trace in the subplot grid\n",
    "    )\n",
    "\n",
    "    # Update layout for clarity\n",
    "    fig.update_layout(\n",
    "        title=\"Separate Metrics with Error Bars\",\n",
    "        xaxis_title=\"Bin position\",\n",
    "        yaxis_title=\"Mean Values\",\n",
    "        legend_title=\"Metric Type\",\n",
    "    )\n",
    "\n",
    "    # Specific labels for the second subplot\n",
    "    fig.update_yaxes(title_text=\"Median Values\", row=2, col=1)\n",
    "\n",
    "    # Add vertical line for each chrom end to both subplots\n",
    "    for row in [1, 2]:\n",
    "        line_position = 0\n",
    "        for chrom in chr_bin_sizes:\n",
    "            line_position += chr_bin_sizes[chrom]\n",
    "            # Add vertical line to the first subplot\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                x0=line_position,\n",
    "                x1=line_position,\n",
    "                y0=0,  # Start from bottom of the plot area\n",
    "                y1=1,  # Extend to the top of the plot area\n",
    "                line=dict(\n",
    "                    color=\"black\",\n",
    "                    width=1,\n",
    "                    dash=\"dashdot\",\n",
    "                ),\n",
    "                xref=\"x\",  # Reference to the x-axis of the subplot\n",
    "                yref=\"y2 domain\",\n",
    "                row=row,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "            fig.add_annotation(\n",
    "                x=line_position - 1000,  # Position the label at the chromosome boundary\n",
    "                y=0.95,  # Adjust the y position to be near the top of the figure; use a relative value within 'paper' coordinate\n",
    "                text=chrom,  # Chromosome label\n",
    "                showarrow=False,  # Do not show an arrow pointing to the annotation\n",
    "                xref=\"x\",  # Use the x-axis for positioning\n",
    "                yref=\"y2 domain\",  # Use the figure's paper for y positioning\n",
    "                xanchor=\"left\",  # Anchor the text to the left of the x position\n",
    "                yanchor=\"bottom\",  # Anchor the text to the bottom of the y position\n",
    "                font=dict(family=\"Arial\", size=10, color=\"RoyalBlue\"),\n",
    "                row=row,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "    # Show plot\n",
    "    fig.write_html(logdir / f\"{output_name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130dccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_important_features(global_task_features_path) -> Dict[str, List[int]]:\n",
    "    \"\"\"Read the important features from the global task features file.\"\"\"\n",
    "    with open(global_task_features_path, \"r\", encoding=\"utf8\") as file:\n",
    "        important_features = json.load(file)\n",
    "    return important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cancer_important_bins() -> Dict[str, List[int]]:\n",
    "    \"\"\"Read the cancer important bins.\"\"\"\n",
    "    dir_path = Path.home() / \"scratch/epiclass/join_important_features/global_info/cancer\"\n",
    "    index_dict = {}\n",
    "\n",
    "    filepath = (\n",
    "        dir_path / \"cancer_intersection_merge_samplings_bed-details_blood_subset.tsv\"\n",
    "    )\n",
    "    df = pd.read_csv(filepath, names=[\"chr\", \"start\", \"end\", \"bin\", \"details\"], sep=\"\\t\")\n",
    "    index_dict[\"cancer_intersection_merge_sampling_blood_subset\"] = list(df[\"bin\"])\n",
    "\n",
    "    filepath = dir_path / \"cancer_intersection_merge_samplings_bed-details_2.tsv\"\n",
    "    df = pd.read_csv(filepath, names=[\"chr\", \"start\", \"end\", \"bin\", \"details\"], sep=\"\\t\")\n",
    "    index_dict[\"cancer_intersection_merge_sampling\"] = list(df[\"bin\"])\n",
    "\n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d22201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features_metrics(\n",
    "    important_features: Dict[str, List[int]],\n",
    "    npz_file_path: Path,\n",
    "    logdir: Path | None = None,\n",
    "    include_categories: Iterable[str] | None = None,\n",
    ") -> Dict[str, Tuple[int, float, float]]:\n",
    "    \"\"\"Using the important features positions, plot (violin) the mean values according to the given npz file.\n",
    "\n",
    "    Adds a violin for a random feature set of the same size, and one for the global distribution.\n",
    "\n",
    "    Compute the KS test for the random features and the global distribution, and add the p-value to the plot.\n",
    "\n",
    "    Args:\n",
    "    - important_features: A dictionary with category names as keys, and lists of feature positions as values.\n",
    "    - npz_file_path: The path to the npz file containing the bin metrics.\n",
    "    - logdir: The directory where to save the plots.\n",
    "    - include_categories: The categories to include in the plot.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with category names as keys, and tuples of sample size and p-values as values.\n",
    "    \"\"\"\n",
    "    with np.load(npz_file_path) as data:\n",
    "        bin_metrics = {metric: data[metric] for metric in data.keys()}\n",
    "\n",
    "    means = np.array(bin_metrics[\"mean\"], dtype=np.float64)\n",
    "\n",
    "    pvals = {}\n",
    "    for category_name, features_pos in important_features.items():\n",
    "        if include_categories and category_name not in include_categories:\n",
    "            continue\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        selected_features = np.array(\n",
    "            [means[pos] for pos in features_pos], dtype=np.float64\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=selected_features,\n",
    "                name=f\"{category_name} features (N={len(features_pos)})\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"all\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Random features comparison\n",
    "        N = len(features_pos)\n",
    "        np.random.seed(42)\n",
    "        random_features = np.random.choice(means, size=N, replace=False)\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=random_features,\n",
    "                name=f\"Random features (N={N})\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"all\",\n",
    "            )\n",
    "        )\n",
    "        _, pval_random = stats.ks_2samp(selected_features, random_features)\n",
    "        if pval_random < 0.0001:\n",
    "            annot_random = \" << 0.001\"\n",
    "        else:\n",
    "            annot_random = f\" = {pval_random:.3f}\"\n",
    "\n",
    "        # Global distribution comparison\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=means,\n",
    "                name=f\"All features N={len(means)}\",\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                points=\"all\",\n",
    "            )\n",
    "        )\n",
    "        _, pval_global = stats.ks_2samp(selected_features, means)\n",
    "        if pval_global < 0.0001:\n",
    "            annot_global = \" << 0.001\"\n",
    "        else:\n",
    "            annot_global = f\" = {pval_global:.3f}\"\n",
    "\n",
    "        # Annotations for p-values\n",
    "        fig.add_annotation(\n",
    "            x=1,\n",
    "            y=max(random_features) + 0.02,\n",
    "            text=f\"p-val {annot_random} (Selected vs. Random)\",\n",
    "            showarrow=False,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "        )\n",
    "        fig.add_annotation(\n",
    "            x=2,\n",
    "            y=max(means) + 0.02,\n",
    "            text=f\"p-val {annot_global} (Selected vs. Global)\",\n",
    "            showarrow=False,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "        )\n",
    "\n",
    "        # Small points\n",
    "        fig.update_traces(marker=dict(size=2))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Mean values for {category_name} features\",\n",
    "            xaxis_title=\"Feature set\",\n",
    "            yaxis_title=\"Mean values\",\n",
    "            violinmode=\"group\",\n",
    "            width=1200,\n",
    "            height=800,\n",
    "        )\n",
    "\n",
    "        # sanity check, pval random vs global\n",
    "        _, pval_random_vs_global = stats.ks_2samp(random_features, means)\n",
    "        if pval_random_vs_global < 0.05:\n",
    "            print(f\"WARNING: pval_random_vs_global: {pval_random_vs_global}\")\n",
    "\n",
    "        pvals[category_name] = (N, pval_random, pval_global, pval_random_vs_global)\n",
    "\n",
    "        if logdir:\n",
    "            fig.write_html(logdir / f\"{npz_file_path.stem}_{category_name}_violin.html\")\n",
    "            fig.write_image(logdir / f\"{npz_file_path.stem}_{category_name}_violin.png\")\n",
    "            fig.write_image(logdir / f\"{npz_file_path.stem}_{category_name}_violin.svg\")\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    return pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3908e7",
   "metadata": {},
   "source": [
    "## CNV hdf5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63923582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_file = \"/home/local/USHERBROOKE/rabj2301/Projects/epiclass/input/hdf5_list/CNV/test_6samples_metrics.npz\"\n",
    "# metrics_arrays = np.load(test_file)\n",
    "# for array in metrics_arrays.values():\n",
    "#     print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60073f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = logdir = base_logdir / \"epiatlas-dfreeze-v2.1/hdf5_stats\" / \"CNV\"\n",
    "npz_file = logdir / \"CNV_EpiAtlas_cancer_onlyLeukemia_100kb_all_none_metrics.npz\"\n",
    "if not npz_file.exists():\n",
    "    print(f\"{npz_file} does not exist\")\n",
    "\n",
    "# with np.load(npz_file) as data:\n",
    "#     for k in data.files:\n",
    "#         print(k, data[k].shape, data[k].dtype, data[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f44a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_bin_metrics(npz_file, output_name=npz_file.stem, chr_bin_sizes=chr_bin_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancer_subset_features = read_cancer_important_bins()\n",
    "# assert len(list(cancer_subset_features.values())[0]) == 233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = read_cancer_important_bins()\n",
    "\n",
    "# CNV_pvals = plot_important_features_metrics(selected_features, npz_file, logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame.from_dict(\n",
    "#     CNV_pvals, orient=\"index\", columns=[\"Feature set size\", \"pval_random\", \"pval_global\"]\n",
    "# )\n",
    "# df.to_csv(logdir / f\"{npz_file.stem}_pvals_ks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc3658",
   "metadata": {},
   "source": [
    "## ChromScore hdf5 values\n",
    "\n",
    "For each cell type important feature, find the average ChromScore value throughout associated cell types.  \n",
    "If bin is present in multiple classes, just use files for all those classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b05c1e",
   "metadata": {},
   "source": [
    "### Read ChromScore values, and map files to their cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscore_dir = paper_dir / \"data\" / \"ChromScore\"\n",
    "chromscore_file = chromscore_dir / \"hdf5_values_ChromScore_100kb_all_none_all.h5\"\n",
    "if not chromscore_file.exists():\n",
    "    print(f\"{npz_file} does not exist\")\n",
    "\n",
    "chromscores_df = pd.read_hdf(chromscore_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c874a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format = `md5sum  IHECRE00002460.ChromScore.bw`\n",
    "md5_mapping_file = chromscore_dir / \"md5sum_mapping.list\"\n",
    "\n",
    "md5_epirr_mapping = {}\n",
    "with open(md5_mapping_file, \"r\", encoding=\"utf8\") as f:\n",
    "    md5_epirr_mapping = {line.split()[0]: line.split()[1].split(\".\")[0] for line in f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from epirr_id_without_version to cell_type\n",
    "epirr_to_cell_type = dict(\n",
    "    zip(metadata_df[\"epirr_id_without_version\"], metadata_df[CELL_TYPE])\n",
    ")\n",
    "\n",
    "md5_cell_type_map = {\n",
    "    md5: epirr_to_cell_type[epirr] for md5, epirr in md5_epirr_mapping.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7caed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromscores_df[CELL_TYPE] = (\n",
    "    chromscores_df.index.map(md5_cell_type_map).str.replace(\" \", \"_\").str.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d093a706",
   "metadata": {},
   "source": [
    "### Read important bins values, and find possible classes for each unique bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf076e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = table_dir / \"dfreeze_v2/100kb_all_none/SHAP-MLP/cell_type\"\n",
    "features_file = features_dir / \"select_beds_top303.tar.gz\"\n",
    "\n",
    "ct_important_bins: Dict[str, List[int]] = {}\n",
    "with tarfile.open(features_file, \"r:gz\") as tar:\n",
    "    for member in tar.getmembers():\n",
    "        filename = member.name\n",
    "        if \"merge_samplings\" in filename and filename.endswith(\"bed\"):\n",
    "            file_obj: IO[bytes] = tar.extractfile(member)  # type: ignore\n",
    "\n",
    "            cell_type = (\n",
    "                filename.split(\"/\")[1]\n",
    "                .replace(\"merge_samplings_\", \"\")\n",
    "                .replace(\"_features.bed\", \"\")\n",
    "                .lower()\n",
    "            )\n",
    "            ct_important_bins[cell_type] = bed_to_bins(\n",
    "                file_obj, chroms=chromsizes, resolution=100 * 1000\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81467053",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bins = set()\n",
    "for bins in ct_important_bins.values():\n",
    "    all_bins.update(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d5a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find relevant cell types for each bin, optimized for pandas future vectorization\n",
    "relevant_pairs_list = []\n",
    "for cell_type, bins_list in ct_important_bins.items():\n",
    "    for bin_idx in bins_list:\n",
    "        relevant_pairs_list.append({\"bin_index\": bin_idx, CELL_TYPE: cell_type})\n",
    "\n",
    "bin_to_relevant_ct_df = pd.DataFrame(relevant_pairs_list)\n",
    "bin_to_relevant_ct_df[\"bin_index\"] = bin_to_relevant_ct_df[\"bin_index\"].astype(int)\n",
    "\n",
    "assert bin_to_relevant_ct_df.shape[0] > len(ct_important_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_to_relevant_ct_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c41507",
   "metadata": {},
   "source": [
    "### Find mean chromScore for each bin (for their relevant files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce905e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melting global chromscores for future operation, now all values are in one column\n",
    "bin_cols = [col for col in chromscores_df.columns if isinstance(col, int)]\n",
    "\n",
    "melted_chromscores = chromscores_df.reset_index().rename(columns={\"index\": \"md5sum\"})\n",
    "melted_chromscores = melted_chromscores.melt(\n",
    "    id_vars=[\"md5sum\", CELL_TYPE],\n",
    "    value_vars=bin_cols,\n",
    "    var_name=\"bin_index\",\n",
    "    value_name=\"chromscore_value\",\n",
    ")\n",
    "melted_chromscores[\"bin_index\"] = melted_chromscores[\"bin_index\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_chromscores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54395752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge melted chromscores with bin_to_relevant_ct_df, efficient for pandas\n",
    "# Filters out all irrelevant bins\n",
    "merged_df = pd.merge(\n",
    "    melted_chromscores, bin_to_relevant_ct_df, on=[\"bin_index\", CELL_TYPE], how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99864cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean chromscore for each bin\n",
    "mean_bin_chromscore_series = merged_df.groupby(\"bin_index\")[\"chromscore_value\"].mean()\n",
    "mean_bin_chromscore = mean_bin_chromscore_series.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75059fc",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features_chromscore(\n",
    "    mean_bin_chromscore: Dict[int, float],\n",
    "    chromscores_df: pd.DataFrame,\n",
    "    logdir: Path | None = None,\n",
    ") -> Tuple[int, float, float, float]:\n",
    "    \"\"\"\n",
    "    miaw\n",
    "    \"\"\"\n",
    "    all_mean_values = chromscores_df.mean(axis=0, numeric_only=True)\n",
    "    print(\"Mean values shape\", all_mean_values.shape)\n",
    "\n",
    "    selected_means = np.array(list(mean_bin_chromscore.values()), dtype=np.float64)\n",
    "    features_pos = list(mean_bin_chromscore.keys())\n",
    "    print(f\"Nb selected features: {len(selected_means)}\")\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            y=selected_means,\n",
    "            name=f\"Important features (N={len(features_pos)})\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            # points=\"all\",\n",
    "            hovertemplate=\"%{text}\",\n",
    "            text=[f\"Bin {pos}: {mean_bin_chromscore[pos]:.2f}\" for pos in features_pos],\n",
    "            spanmode=\"hard\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Random features comparison\n",
    "    N = len(features_pos)\n",
    "    np.random.seed(42)\n",
    "    random_features = np.random.choice(\n",
    "        range(chromscores_df.shape[1]), size=N, replace=False\n",
    "    )\n",
    "    random_means = all_mean_values[random_features]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            y=random_means,\n",
    "            name=f\"Random features (N={N})\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            # points=\"all\",\n",
    "            hovertemplate=\"%{text}\",\n",
    "            text=[\n",
    "                f\"Bin {pos}: {val:.2f}\" for pos, val in zip(random_features, random_means)\n",
    "            ],\n",
    "            spanmode=\"hard\",\n",
    "        )\n",
    "    )\n",
    "    # _, pval_random = stats.ks_2samp(selected_means, random_means)\n",
    "    # if pval_random < 0.0001:\n",
    "    #     annot_random = \" << 0.001\"\n",
    "    # else:\n",
    "    #     annot_random = f\" = {pval_random:.3f}\"\n",
    "\n",
    "    # Global distribution comparison\n",
    "    fig.add_trace(\n",
    "        go.Violin(\n",
    "            y=all_mean_values,\n",
    "            name=f\"All features N={len(all_mean_values)}\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "            spanmode=\"hard\",\n",
    "        )\n",
    "    )\n",
    "    # _, pval_global = stats.ks_2samp(selected_means, all_mean_values)\n",
    "    # if pval_global < 0.0001:\n",
    "    #     annot_global = \" << 0.001\"\n",
    "    # else:\n",
    "    #     annot_global = f\" = {pval_global:.3f}\"\n",
    "\n",
    "    # # Annotations for p-values\n",
    "    # fig.add_annotation(\n",
    "    #     x=1,\n",
    "    #     y=max(random_means) + 0.02,\n",
    "    #     text=f\"p-val {annot_random} (Selected vs. Random)\",\n",
    "    #     showarrow=False,\n",
    "    #     xref=\"x\",\n",
    "    #     yref=\"y\",\n",
    "    # )\n",
    "    # fig.add_annotation(\n",
    "    #     x=2,\n",
    "    #     y=max(all_mean_values) + 0.02,\n",
    "    #     text=f\"p-val {annot_global} (Selected vs. Global)\",\n",
    "    #     showarrow=False,\n",
    "    #     xref=\"x\",\n",
    "    #     yref=\"y\",\n",
    "    # )\n",
    "\n",
    "    # Small points\n",
    "    fig.update_traces(marker=dict(size=2))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Important cell type features chromScore\",\n",
    "        xaxis_title=\"Feature set\",\n",
    "        yaxis_title=\"Mean ChromScore values\",\n",
    "        violinmode=\"group\",\n",
    "        width=800,\n",
    "        height=600,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    if logdir is not None:\n",
    "        name = \"important_features_16ct_chromscore\"\n",
    "        fig.write_image(logdir / f\"{name}.svg\")\n",
    "        fig.write_image(logdir / f\"{name}.png\")\n",
    "        fig.write_html(logdir / f\"{name}.html\")\n",
    "\n",
    "    # # sanity check, pval random vs global\n",
    "    # _, pval_random_vs_global = stats.ks_2samp(random_features, all_mean_values)\n",
    "    # if pval_random_vs_global < 0.05:\n",
    "    #     print(f\"WARNING: pval_random_vs_global: {pval_random_vs_global}\")\n",
    "\n",
    "    # pvals = (N, pval_random, pval_global, pval_random_vs_global)\n",
    "\n",
    "    # return pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917dfc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245cf8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_important_features_chromscore(\n",
    "    mean_bin_chromscore=mean_bin_chromscore,\n",
    "    chromscores_df=chromscores_df,\n",
    "    logdir=logdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c786ae",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_md5s_path = input_base / \"hdf5_list\" / \"md5_shap_assay_explain.list\"\n",
    "# with open(shap_md5s_path, \"r\", encoding=\"utf8\") as f:\n",
    "#     shap_md5s = set(f.read().splitlines())\n",
    "\n",
    "\n",
    "def analyze_feature_vals(\n",
    "    regions_dict: Dict[int, Tuple],\n",
    "    md5s: List[str],\n",
    "    hdf5_list: Path,\n",
    "    logdir: Path,\n",
    "    name: str,\n",
    "    shap_md5s: List[str],\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate and save a violin plot of provided feature values for the provided md5s, with some md5s highlighted.\n",
    "\n",
    "    This function takes as input a list of md5s and a dictionary of regions, and generates a violin plot\n",
    "    of the feature values for these md5s. It also highlights specific md5s by adding lines+markers for them.\n",
    "    The function saves the plot as an HTML file and a PNG file in the provided log directory.\n",
    "\n",
    "    Args:\n",
    "        regions_dict (Dict[int, Tuple]): A dictionary mapping region indices to their respective genomic coordinates.\n",
    "        md5s (List[str]): A list of md5s to analyze.\n",
    "        hdf5_list (Path): Path to the list of hdf5 files to be used.\n",
    "        logdir (Path): Directory where the resulting plot should be saved.\n",
    "        name (str): Name used to save the resulting plot (will be part of the filename).\n",
    "    \"\"\"\n",
    "    hdf5_loader = Hdf5Loader(chrom_file=chromsize_path, normalization=True)\n",
    "    hdf5_loader.load_hdf5s(hdf5_list, md5s, strict=True)\n",
    "    N = len(hdf5_loader.signals)\n",
    "\n",
    "    nb_highlight = 3\n",
    "    highlight_md5s = list(set(md5s) & set(shap_md5s))[0:nb_highlight]\n",
    "\n",
    "    traces = []\n",
    "    highlight_values = {highlight_md5: [] for highlight_md5 in highlight_md5s}\n",
    "    for region, region_bed in regions_dict.items():\n",
    "        values = [signal[region] for signal in hdf5_loader.signals.values()]\n",
    "        region_str = f\"{region_bed[0]}:{region_bed[1]}-{region_bed[2]}\"\n",
    "\n",
    "        trace = go.Violin(\n",
    "            y=values,\n",
    "            name=region_str,\n",
    "            points=\"all\",\n",
    "            box_visible=True,\n",
    "            meanline_visible=True,\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "        for highlight_md5 in highlight_md5s:\n",
    "            highlight_value = hdf5_loader.signals[highlight_md5][region]\n",
    "            highlight_values[highlight_md5].append((region_str, highlight_value))\n",
    "\n",
    "    for (highlight_md5, highlight_value), marker_format in zip(\n",
    "        highlight_values.items(),\n",
    "        [[\"cross\", \"black\"], [\"circle\", \"blue\"], [\"diamond\", \"red\"]],\n",
    "    ):\n",
    "        x, y = zip(*highlight_value)\n",
    "        symbol, color = marker_format\n",
    "        highlight_trace = go.Scatter(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            mode=\"lines+markers\",\n",
    "            name=f\"{highlight_md5}\",\n",
    "            marker={\"size\": 6, \"symbol\": symbol, \"color\": color},\n",
    "        )\n",
    "        traces.append(highlight_trace)\n",
    "\n",
    "    # Create the layout\n",
    "    layout = go.Layout(\n",
    "        title=f\"Feature values distributions for {N} {name} samples (0blklst)\",\n",
    "        yaxis={\"title\": \"z-score\"},\n",
    "        xaxis={\"title\": \"Region\"},\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Create the figure with the data and layout\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    fig.write_html(logdir / f\"feature_values_{name}.html\")\n",
    "\n",
    "    width = 1200\n",
    "    fig.write_image(\n",
    "        logdir / f\"feature_values_{name}.png\", width=width, height=width * 3 / 4\n",
    "    )\n",
    "    # fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_file(md5, zscore: bool = True):\n",
    "    \"\"\"Produce a violin plot (save to html) of all feature values for a single sample.\"\"\"\n",
    "    if zscore:\n",
    "        mode = \"z-scores\"\n",
    "    else:\n",
    "        mode = \"raw values\"\n",
    "\n",
    "    hdf5_loader = Hdf5Loader(chrom_file=chromsize_path, normalization=zscore)\n",
    "    signals = hdf5_loader.load_hdf5s(hdf5_list_path, [md5], strict=True).signals\n",
    "\n",
    "    fig = px.violin(\n",
    "        data_frame=list(signals.values())[0],\n",
    "        box=True,\n",
    "        points=\"all\",\n",
    "        title=f\"Violin plot for {md5} {mode}\",\n",
    "    )\n",
    "    fig.write_html(f\"{md5}-{mode}.html\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_casting_error(filepath: Path | str, dataset_name: str):\n",
    "    \"\"\"Evaluate the casting error for a specific dataset in an HDF5 file.\"\"\"\n",
    "    with h5py.File(filepath, \"r\") as f:\n",
    "        dataset = f[dataset_name]\n",
    "        values = dataset[:]\n",
    "\n",
    "        # Cast to float32 and compare max diff\n",
    "        casted_dataset = dataset.astype(np.float32)[:]\n",
    "        diff = np.abs(casted_dataset - values)\n",
    "        max_diff = np.max(diff)\n",
    "        print(f\"Max diff when casting: {max_diff}\")\n",
    "        if max_diff > 1e-4:\n",
    "            print(\"Induced casting error\")\n",
    "            print(f\"Max value: {np.max(values)}\")\n",
    "            print(f\"Filepath: {filepath}\")\n",
    "            print(f\"Dataset name: {dataset_name}\")\n",
    "\n",
    "\n",
    "# traces = []\n",
    "# for filepath in paths:\n",
    "#     with h5py.File(filepath, \"r+\") as f:\n",
    "#         for _, group in f.items():\n",
    "#             for dataset_name, dataset in list(group.items()):\n",
    "#                 # Extract the values from the dataset\n",
    "#                 values = dataset[:]\n",
    "\n",
    "#                 # Create a violin trace\n",
    "#                 trace = go.Violin(y=values, name=dataset_name)\n",
    "\n",
    "#                 # Add the trace to the data list\n",
    "#                 traces.append(trace)\n",
    "\n",
    "#                 evaluate_casting_error(filepath, dataset_name)\n",
    "\n",
    "#     # Create the layout\n",
    "#     layout = go.Layout(title=\"Violin Plots\", yaxis={\"title\": \"Values\"})\n",
    "\n",
    "#     # Create the figure with the data and layout\n",
    "#     fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "#     # Show the violin plot\n",
    "#     fig.show()\n",
    "#     traces = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f67fa-023c-45a8-b454-99c15d0470b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_descriptive_stats(\n",
    "    df: pd.DataFrame, metadata_df: pd.DataFrame, metadata: Metadata, logdir: Path\n",
    "):\n",
    "    \"\"\"Evaluate the descriptive statistics for a DataFrame.\"\"\"\n",
    "    percentiles = [0.01] + list(np.arange(0.05, 1, 0.05)) + [0.99] + [0.999]\n",
    "    stats_df = df.apply(pd.DataFrame.describe, percentiles=percentiles, axis=1)  # type: ignore\n",
    "    metrics = set(stats_df.columns.values)\n",
    "    stats_df = stats_df.join(metadata_df)  # type: ignore\n",
    "\n",
    "    # Create violin plots, one plot for each metric, and a violin for each assay (per plot)\n",
    "    allowed_metrics = metrics - set([\"count\", \"mean\", \"std\"])\n",
    "    category_orders = {ASSAY: sorted(metadata.label_counter(ASSAY, verbose=False).keys())}\n",
    "    for column in stats_df:\n",
    "        if column not in allowed_metrics:\n",
    "            continue\n",
    "        fig = px.violin(\n",
    "            data_frame=stats_df,\n",
    "            x=column,\n",
    "            y=ASSAY,\n",
    "            box=True,\n",
    "            points=\"all\",\n",
    "            title=f\"Violin plot for {column}\",\n",
    "            color=ASSAY,\n",
    "            category_orders=category_orders,\n",
    "            height=800,\n",
    "            hover_data={\"md5sum\": (df.index)},\n",
    "        )\n",
    "        fig.write_image(logdir / f\"100kb_all_none_hdf5_{column}.png\")\n",
    "        fig.write_html(logdir / f\"100kb_all_none_hdf5_{column}.html\")\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e7c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have a list of arrays\n",
    "# hdf5_loader = Hdf5Loader(chrom_file=chromsize_path, normalization=True)\n",
    "# signals = hdf5_loader.load_hdf5s(hdf5_list_path, md5s, strict=True).signals\n",
    "# df = pd.DataFrame.from_dict(signals, orient=\"index\")\n",
    "# # df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
