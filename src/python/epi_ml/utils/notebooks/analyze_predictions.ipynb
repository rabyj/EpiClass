{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Analyze full prediction vector values.\"\"\"\n",
    "# pylint: disable=line-too-long, redefined-outer-name, import-error, pointless-statement, use-dict-literal, expression-not-assigned, unused-import, too-many-lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import itertools\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import sklearn.metrics\n",
    "from IPython.display import display\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from epi_ml.core.confusion_matrix import ConfusionMatrixWriter\n",
    "from epi_ml.utils.general_utility import get_valid_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIOMATERIAL_TYPE = \"harmonized_biomaterial_type\"\n",
    "CELL_TYPE = \"harmonized_sample_ontology_intermediate\"\n",
    "ASSAY = \"assay_epiclass\"\n",
    "SEX = \"harmonized_donor_sex\"\n",
    "CANCER = \"harmonized_sample_cancer_high\"\n",
    "DISEASE = \"harmonized_sample_disease_high\"\n",
    "LIFE_STAGE = \"harmonized_donor_life_stage\"\n",
    "TRACK = \"track_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_local_logdir = Path.home() / \"downloads\" / \"temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot table on assay and cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = (\n",
    "    general_local_logdir\n",
    "    / \"sex3_oversample_full-10fold-validation_prediction_augmented-all.csv\"\n",
    ")\n",
    "sex_df = pd.read_csv(results_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyzed_as_stranded</th>\n",
       "      <th>antibody</th>\n",
       "      <th>assay_epiclass</th>\n",
       "      <th>assay_type</th>\n",
       "      <th>automated_harmonized_donor_health_status_ontology_curie_ncit</th>\n",
       "      <th>automated_harmonized_donor_health_status_ontology_term_high_order</th>\n",
       "      <th>automated_harmonized_donor_health_status_ontology_term_high_order_unique</th>\n",
       "      <th>automated_harmonized_donor_health_status_ontology_term_intermediate_order</th>\n",
       "      <th>automated_harmonized_donor_health_status_ontology_term_intermediate_order_unique</th>\n",
       "      <th>automated_harmonized_sample_disease_ontology_curie_ncit</th>\n",
       "      <th>...</th>\n",
       "      <th>1rst/2nd prob ratio</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>mixed</th>\n",
       "      <th>files/epiRR</th>\n",
       "      <th>Predicted class Coherence count</th>\n",
       "      <th>Predicted class Coherence ratio</th>\n",
       "      <th>files/experiment</th>\n",
       "      <th>Track type coherence count</th>\n",
       "      <th>Track type coherence ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>md5sum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fffc8579e05214d5f77ccb1240b0e702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>h3k9me3</td>\n",
       "      <td>h3k9me3</td>\n",
       "      <td>ChIP-Seq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NCIT:C41132</td>\n",
       "      <td>...</td>\n",
       "      <td>41.45</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff8c22ec1de7cd4c004b50a4fa1b12d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>h3k36me3</td>\n",
       "      <td>h3k36me3</td>\n",
       "      <td>ChIP-Seq</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.41</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff806f6985888bc774e8dacf1f91925</th>\n",
       "      <td>NaN</td>\n",
       "      <td>h3k9me3</td>\n",
       "      <td>h3k9me3</td>\n",
       "      <td>ChIP-Seq</td>\n",
       "      <td>NCIT:C41132</td>\n",
       "      <td>None</td>\n",
       "      <td>General Qualifier</td>\n",
       "      <td>None</td>\n",
       "      <td>General Qualifier</td>\n",
       "      <td>NCIT:C41132</td>\n",
       "      <td>...</td>\n",
       "      <td>249.00</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff7a9c67e618f10e7399a443c8862df</th>\n",
       "      <td>NaN</td>\n",
       "      <td>h3k4me1</td>\n",
       "      <td>h3k4me1</td>\n",
       "      <td>ChIP-Seq</td>\n",
       "      <td>NCIT:C41132</td>\n",
       "      <td>None</td>\n",
       "      <td>General Qualifier</td>\n",
       "      <td>None</td>\n",
       "      <td>General Qualifier</td>\n",
       "      <td>NCIT:C4029</td>\n",
       "      <td>...</td>\n",
       "      <td>356.14</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff48c241745bc634487073bbeb7a5df</th>\n",
       "      <td>NaN</td>\n",
       "      <td>h3k36me3</td>\n",
       "      <td>h3k36me3</td>\n",
       "      <td>ChIP-Seq</td>\n",
       "      <td>NCIT:C4752</td>\n",
       "      <td>Lymphoproliferative Disorder</td>\n",
       "      <td>Lymphoproliferative Disorder</td>\n",
       "      <td>T/NK-Cell Lymphoproliferative Disorder</td>\n",
       "      <td>Lymphoid Leukemia</td>\n",
       "      <td>NCIT:C4752</td>\n",
       "      <td>...</td>\n",
       "      <td>369.37</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 analyzed_as_stranded  antibody  \\\n",
       "md5sum                                                            \n",
       "fffc8579e05214d5f77ccb1240b0e702                  NaN   h3k9me3   \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                  NaN  h3k36me3   \n",
       "fff806f6985888bc774e8dacf1f91925                  NaN   h3k9me3   \n",
       "fff7a9c67e618f10e7399a443c8862df                  NaN   h3k4me1   \n",
       "fff48c241745bc634487073bbeb7a5df                  NaN  h3k36me3   \n",
       "\n",
       "                                 assay_epiclass assay_type  \\\n",
       "md5sum                                                       \n",
       "fffc8579e05214d5f77ccb1240b0e702        h3k9me3   ChIP-Seq   \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d       h3k36me3   ChIP-Seq   \n",
       "fff806f6985888bc774e8dacf1f91925        h3k9me3   ChIP-Seq   \n",
       "fff7a9c67e618f10e7399a443c8862df        h3k4me1   ChIP-Seq   \n",
       "fff48c241745bc634487073bbeb7a5df       h3k36me3   ChIP-Seq   \n",
       "\n",
       "                                 automated_harmonized_donor_health_status_ontology_curie_ncit  \\\n",
       "md5sum                                                                                          \n",
       "fffc8579e05214d5f77ccb1240b0e702                                                NaN             \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                                                NaN             \n",
       "fff806f6985888bc774e8dacf1f91925                                        NCIT:C41132             \n",
       "fff7a9c67e618f10e7399a443c8862df                                        NCIT:C41132             \n",
       "fff48c241745bc634487073bbeb7a5df                                         NCIT:C4752             \n",
       "\n",
       "                                 automated_harmonized_donor_health_status_ontology_term_high_order  \\\n",
       "md5sum                                                                                               \n",
       "fffc8579e05214d5f77ccb1240b0e702                                                NaN                  \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                                                NaN                  \n",
       "fff806f6985888bc774e8dacf1f91925                                               None                  \n",
       "fff7a9c67e618f10e7399a443c8862df                                               None                  \n",
       "fff48c241745bc634487073bbeb7a5df                       Lymphoproliferative Disorder                  \n",
       "\n",
       "                                 automated_harmonized_donor_health_status_ontology_term_high_order_unique  \\\n",
       "md5sum                                                                                                      \n",
       "fffc8579e05214d5f77ccb1240b0e702                                                NaN                         \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                                                NaN                         \n",
       "fff806f6985888bc774e8dacf1f91925                                  General Qualifier                         \n",
       "fff7a9c67e618f10e7399a443c8862df                                  General Qualifier                         \n",
       "fff48c241745bc634487073bbeb7a5df                       Lymphoproliferative Disorder                         \n",
       "\n",
       "                                 automated_harmonized_donor_health_status_ontology_term_intermediate_order  \\\n",
       "md5sum                                                                                                       \n",
       "fffc8579e05214d5f77ccb1240b0e702                                                NaN                          \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                                                NaN                          \n",
       "fff806f6985888bc774e8dacf1f91925                                               None                          \n",
       "fff7a9c67e618f10e7399a443c8862df                                               None                          \n",
       "fff48c241745bc634487073bbeb7a5df             T/NK-Cell Lymphoproliferative Disorder                          \n",
       "\n",
       "                                 automated_harmonized_donor_health_status_ontology_term_intermediate_order_unique  \\\n",
       "md5sum                                                                                                              \n",
       "fffc8579e05214d5f77ccb1240b0e702                                                NaN                                 \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                                                NaN                                 \n",
       "fff806f6985888bc774e8dacf1f91925                                  General Qualifier                                 \n",
       "fff7a9c67e618f10e7399a443c8862df                                  General Qualifier                                 \n",
       "fff48c241745bc634487073bbeb7a5df                                  Lymphoid Leukemia                                 \n",
       "\n",
       "                                 automated_harmonized_sample_disease_ontology_curie_ncit  \\\n",
       "md5sum                                                                                     \n",
       "fffc8579e05214d5f77ccb1240b0e702                                        NCIT:C41132        \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                                                NaN        \n",
       "fff806f6985888bc774e8dacf1f91925                                        NCIT:C41132        \n",
       "fff7a9c67e618f10e7399a443c8862df                                         NCIT:C4029        \n",
       "fff48c241745bc634487073bbeb7a5df                                         NCIT:C4752        \n",
       "\n",
       "                                  ... 1rst/2nd prob ratio  female    male  \\\n",
       "md5sum                            ...                                       \n",
       "fffc8579e05214d5f77ccb1240b0e702  ...               41.45  0.9740  0.0235   \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d  ...                9.41  0.8324  0.0790   \n",
       "fff806f6985888bc774e8dacf1f91925  ...              249.00  0.9960  0.0040   \n",
       "fff7a9c67e618f10e7399a443c8862df  ...              356.14  0.9972  0.0028   \n",
       "fff48c241745bc634487073bbeb7a5df  ...              369.37  0.9973  0.0027   \n",
       "\n",
       "                                   mixed files/epiRR  \\\n",
       "md5sum                                                 \n",
       "fffc8579e05214d5f77ccb1240b0e702  0.0025          23   \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d  0.0885          23   \n",
       "fff806f6985888bc774e8dacf1f91925  0.0000          16   \n",
       "fff7a9c67e618f10e7399a443c8862df  0.0000          23   \n",
       "fff48c241745bc634487073bbeb7a5df  0.0000          23   \n",
       "\n",
       "                                 Predicted class Coherence count  \\\n",
       "md5sum                                                             \n",
       "fffc8579e05214d5f77ccb1240b0e702                              23   \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                              23   \n",
       "fff806f6985888bc774e8dacf1f91925                              16   \n",
       "fff7a9c67e618f10e7399a443c8862df                              19   \n",
       "fff48c241745bc634487073bbeb7a5df                              23   \n",
       "\n",
       "                                 Predicted class Coherence ratio  \\\n",
       "md5sum                                                             \n",
       "fffc8579e05214d5f77ccb1240b0e702                        1.000000   \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                        1.000000   \n",
       "fff806f6985888bc774e8dacf1f91925                        1.000000   \n",
       "fff7a9c67e618f10e7399a443c8862df                        0.826087   \n",
       "fff48c241745bc634487073bbeb7a5df                        1.000000   \n",
       "\n",
       "                                 files/experiment Track type coherence count  \\\n",
       "md5sum                                                                         \n",
       "fffc8579e05214d5f77ccb1240b0e702                3                          3   \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                3                          3   \n",
       "fff806f6985888bc774e8dacf1f91925                3                          3   \n",
       "fff7a9c67e618f10e7399a443c8862df                3                          3   \n",
       "fff48c241745bc634487073bbeb7a5df                3                          3   \n",
       "\n",
       "                                 Track type coherence ratio  \n",
       "md5sum                                                       \n",
       "fffc8579e05214d5f77ccb1240b0e702                        1.0  \n",
       "fff8c22ec1de7cd4c004b50a4fa1b12d                        1.0  \n",
       "fff806f6985888bc774e8dacf1f91925                        1.0  \n",
       "fff7a9c67e618f10e7399a443c8862df                        1.0  \n",
       "fff48c241745bc634487073bbeb7a5df                        1.0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_table(df: pd.DataFrame, category_label: str) -> pd.DataFrame:\n",
    "    \"\"\"Create a pivot table for predictions results.\"\"\"\n",
    "    index_columns = [category_label, ASSAY, CELL_TYPE]\n",
    "    pivot = df.pivot_table(\n",
    "        index=index_columns,\n",
    "        columns=\"Predicted class\",\n",
    "        values=\"Same?\",\n",
    "        aggfunc=[\"count\", \"mean\"],\n",
    "        margins=True,\n",
    "        margins_name=\"Total\",\n",
    "        fill_value=0,\n",
    "    )\n",
    "\n",
    "    mean_columns = [\n",
    "        (aggfunc, pred_class)\n",
    "        for aggfunc, pred_class in pivot.columns\n",
    "        if aggfunc == \"mean\"\n",
    "    ]\n",
    "    mean_columns.remove((\"mean\", \"Total\"))\n",
    "    pivot.drop(columns=mean_columns, inplace=True)\n",
    "\n",
    "    return pivot\n",
    "\n",
    "\n",
    "sex_pivot = pivot_table(sex_df, SEX)\n",
    "sex_pivot.to_csv(\n",
    "    general_local_logdir\n",
    "    / \"sex3_oversample_full-10fold-validation_prediction_augmented-all_pivot.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logdir = (\n",
    "    Path.home()\n",
    "    / \"mounts/narval-mount/project-rabyj/epilap/output/logs/epiatlas-dfreeze-v2.1/hg38_100kb_all_none\"\n",
    ")\n",
    "pred_folders = [\n",
    "    base_logdir / name\n",
    "    for name in [\n",
    "        \"harmonized_donor_life_stage_1l_3000n/no-unknown/10fold-oversampling\",\n",
    "        # \"assay_epiclass_1l_3000n/11c/10fold-oversampling\",\n",
    "        # \"harmonized_donor_sex_1l_3000n/w-mixed/10fold-oversample\"\n",
    "    ]\n",
    "]\n",
    "pred_files = [\n",
    "    pred_folder / \"full-10fold-validation_prediction_augmented-all.csv\"\n",
    "    for pred_folder in pred_folders\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_file in pred_files:\n",
    "    assert pred_file.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per sample, different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pred_file in pred_files:\n",
    "#         df = pd.read_csv(\n",
    "#             pred_file,\n",
    "#             sep=\",\",\n",
    "#             usecols=[\"True class\", \"Predicted class\", \"Max pred\"],\n",
    "#         )\n",
    "\n",
    "#         for threshold in [0, 0.7, 0.9]:\n",
    "#             sub_df  = df[df[\"Max pred\"] >= threshold]\n",
    "\n",
    "#             true, pred = sub_df.iloc[:, 0], sub_df.iloc[:, 1]\n",
    "#             labels = sorted(set(true.unique().tolist() + pred.unique().tolist()))\n",
    "#             confusion_mat = sklearn.metrics.confusion_matrix(true, pred, labels=labels)\n",
    "\n",
    "#             writer = ConfusionMatrixWriter(labels=labels, confusion_matrix=confusion_mat)\n",
    "#             writer.to_all_formats(\n",
    "#                 logdir=pred_file.parent,\n",
    "#                 name=str(pred_file.stem) + f\"-confusion_matrix-{threshold*100}\",\n",
    "#             )\n",
    "#             plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per EpiRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_class(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Given a DataFrame representing a single EpiRR, determine the predicted majority class.\n",
    "\n",
    "    Uses max prediction value to break ties.\n",
    "    Args:\n",
    "        df (pd.DataFrame): A DataFrame containing predictions for a single EpiRR.\n",
    "\n",
    "    Returns:\n",
    "        str: The majority class label for this EpiRR.\n",
    "    \"\"\"\n",
    "    class_counts = df[\"Predicted class\"].value_counts()\n",
    "    max_count = class_counts.max()\n",
    "    majority_classes = class_counts[class_counts == max_count].index.tolist()\n",
    "\n",
    "    if len(majority_classes) == 1:\n",
    "        return majority_classes[0]\n",
    "\n",
    "    avg_max_pred = df.groupby(\"Predicted class\")[\"Max pred\"].mean()\n",
    "    return avg_max_pred.loc[majority_classes].idxmax()  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_file in pred_files:\n",
    "    df = pd.read_csv(\n",
    "        pred_file,\n",
    "        sep=\",\",\n",
    "    )\n",
    "\n",
    "    # px.box(df, x=\"True class\", y=\"Max pred\", color=\"Predicted class\", title=pred_file.stem).show()\n",
    "\n",
    "    # only one true class per epiRR\n",
    "    total_epirrs = df[\"EpiRR\"].nunique()\n",
    "    print(\"Total number of EpiRRs:\", total_epirrs)\n",
    "    assert (\n",
    "        df[[\"EpiRR\", \"True class\"]].value_counts().shape[0]\n",
    "        == df[[\"EpiRR\"]].value_counts().shape[0]\n",
    "    )\n",
    "\n",
    "    for threshold in [0, 0.7, 0.9]:\n",
    "        threshold_df = df[df[\"Max pred\"] >= threshold]\n",
    "\n",
    "        # Group by EpiRR and apply the function to find the majority class for each EpiRR\n",
    "        majority_class_series = threshold_df.groupby(\"EpiRR\").apply(get_majority_class)\n",
    "        majority_class_series.name = \"Predicted class\"\n",
    "\n",
    "        threshold_df = threshold_df[[\"EpiRR\", \"True class\"]].drop_duplicates()\n",
    "        epirr_df = threshold_df.join(majority_class_series, how=\"inner\", on=\"EpiRR\")\n",
    "        epirr_df = epirr_df.set_index(\"EpiRR\")\n",
    "\n",
    "        print(\n",
    "            epirr_df[\n",
    "                (epirr_df[\"True class\"] == \"adult\")\n",
    "                & (epirr_df[\"Predicted class\"] == \"embryonic\")\n",
    "            ]\n",
    "        )\n",
    "        # true, pred = epirr_df[\"True class\"], epirr_df[\"Predicted class\"]\n",
    "        # assert len(true) == len(pred)\n",
    "        # assert len(true) <= total_epirrs\n",
    "\n",
    "        # labels = sorted(set(true.unique().tolist() + pred.unique().tolist()))\n",
    "        # confusion_mat = sklearn.metrics.confusion_matrix(true, pred, labels=labels)\n",
    "\n",
    "        # writer = ConfusionMatrixWriter(labels=labels, confusion_matrix=confusion_mat)\n",
    "\n",
    "        # out_logdir = pred_file.parent / \"conf_per_epirr\"\n",
    "        # out_logdir.mkdir(exist_ok=True)\n",
    "        # paths = writer.to_all_formats(\n",
    "        #     logdir=out_logdir,\n",
    "        #     name=str(pred_file.stem) + f\"-confusion_matrix-epirr-t{threshold*100}\",\n",
    "        # )\n",
    "        # print(paths[-1])\n",
    "        # plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the number of predicted classes for each EpiRR\n",
    "# class_counts = threshold_df.groupby(\"EpiRR\")[\"Predicted class\"].nunique()\n",
    "\n",
    "# # Find EpiRRs with more than one predicted class\n",
    "# epiRRs_with_multiple_classes = class_counts[class_counts > 1].index\n",
    "\n",
    "# # Filter the DataFrame to only include these EpiRRs\n",
    "# final_df = threshold_df[threshold_df[\"EpiRR\"].isin(epiRRs_with_multiple_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_class_2(group: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Given a DataFrame, determine the majority class per EpiRR.\n",
    "\n",
    "    Args:\n",
    "        group (pd.DataFrame): A DataFrame containing aggregated data for each EpiRR.\n",
    "\n",
    "    Returns:\n",
    "        str: The majority class label.\n",
    "    \"\"\"\n",
    "    # Sorting by count and mean\n",
    "    sorted_group = group.sort_values(\n",
    "        by=[(\"Max pred\", \"count\"), (\"Max pred\", \"mean\")], ascending=[False, False]\n",
    "    )\n",
    "\n",
    "    # Select the first (majority) class\n",
    "    majority_class = sorted_group.index[0][\n",
    "        2\n",
    "    ]  # The third element in the index tuple should be \"Predicted class\"\n",
    "\n",
    "    return majority_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check specific EpiRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pred_file in pred_files:\n",
    "\n",
    "#     df = pd.read_csv(\n",
    "#         pred_file,\n",
    "#         sep=\",\",\n",
    "#     )\n",
    "\n",
    "#     px.box(df, x=\"True class\", y=\"Max pred\", color=\"Predicted class\", title=pred_file.stem).show()\n",
    "\n",
    "#     # Check that there's only one true class for each EpiRR\n",
    "#     assert df.groupby(\"EpiRR\")[\"True class\"].nunique().eq(1).all()\n",
    "#     print(\"Total number of EpiRRs:\", df[\"EpiRR\"].nunique())\n",
    "\n",
    "#     threshold_df = df.groupby([\"EpiRR\",\"harmonized_donor_type\", \"True class\",\"Predicted class\", \"assay_epiclass\"]).agg({'Max pred': ['mean', 'median', 'count']})\n",
    "#     display(threshold_df.loc[\"IHECRE00003713.7\"])\n",
    "#     # classes = threshold_df.groupby(\"EpiRR\").apply(get_majority_class_2)\n",
    "#     # display(classes)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction distributions (per cell of confusion matrix)\n",
    "\n",
    "Analyze prediction values of correct vs false predictions. Can we find a good prediction score threshold that lets us eliminate important errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdir = Path.home() / \"downloads\" / \"temp\"\n",
    "\n",
    "# path = logdir / \"sex3_oversample_full-10fold-validation_prediction_augmented-all.csv\"\n",
    "# df = pd.read_csv(path, index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = df[\"True class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"harmonized_donor_sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label in classes:\n",
    "#     df_label = df[df[\"True class\"] == label]\n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     # Iterate classes each target and add a violin plot for it\n",
    "#     for target in classes:\n",
    "#         vals = df_label[df_label[\"Predicted class\"] == target][\"Max pred\"]\n",
    "#         print(df_label[\"assay_epiclass\"].value_counts())\n",
    "\n",
    "#         fig.add_trace(\n",
    "#             go.Violin(\n",
    "#                 y=vals,\n",
    "#                 name=f\"{target} ({len(vals)})\",\n",
    "#                 box_visible=True,\n",
    "#                 meanline_visible=True,\n",
    "#                 points=\"all\",\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         title_text=f\"Predicted value distribution for {label} ({df_label.shape[0]})\",\n",
    "#         yaxis_title=\"Prediction score\",\n",
    "#         xaxis_title=\"Target\",\n",
    "#     )\n",
    "#     fig.update_yaxes(range=[1 / len(classes), 1.01])\n",
    "\n",
    "#     fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assay_list(df: pd.DataFrame) -> List[List[str]]:\n",
    "    \"\"\"Return list of assay labels. Includes rna and wgb label pairs.\"\"\"\n",
    "    assay_labels = df[\"assay_epiclass\"].unique().tolist()\n",
    "    assay_labels = [[assay_label] for assay_label in assay_labels]\n",
    "    assay_labels = assay_labels + [\n",
    "        [\"mrna_seq\", \"rna_seq\"],\n",
    "        [\"wgbs-standard\", \"wgbs-pbat\"],\n",
    "    ]\n",
    "    return assay_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex chrY coverage information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = Path.home() / \"downloads\" / \"temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = logdir / \"sex3_oversample_full-10fold-validation_prediction_augmented-all.csv\"\n",
    "sex_df = pd.read_csv(path, index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_path = logdir / \"chrXY_coverage_all.csv\"\n",
    "coverage_df = pd.read_csv(coverage_path, index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = sex_df.merge(coverage_df, left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.to_csv(\n",
    "#     logdir / \"sex3_oversample_full-10fold-validation_prediction_augmented-all-chrY.csv\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df, coverage_df, merged_df]:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[~merged_df[TRACK].str.contains(pat=\"pval|fc\", case=False)]\n",
    "# merged_df = merged_df[~merged_df[ASSAY].str.contains(pat=\"wgb|input\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_DICT = {\"female\": \"red\", \"male\": \"blue\", \"mixed\": \"purple\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_labels = get_assay_list(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All samples (1 sample = 1 data point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir_10fold_per_assay = (\n",
    "    general_local_logdir\n",
    "    / \"chrY_coverage_results\"\n",
    "    / \"10fold_valid\"\n",
    "    / \"conf_matrix_per_assay\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a 3x3 subplot layout\n",
    "coverage_label = \"chrY\"\n",
    "classes = merged_df[\"True class\"].unique()\n",
    "\n",
    "# Iterate over each label to populate the subplots\n",
    "for assay_list in assay_labels:\n",
    "    assay_df = merged_df[merged_df[ASSAY].isin(assay_list)]\n",
    "    for threshold in [0, 0.7, 0.9]:\n",
    "        row = 1\n",
    "        col = 1\n",
    "        fig = make_subplots(\n",
    "            rows=3,\n",
    "            cols=3,\n",
    "            shared_yaxes=True,\n",
    "            x_title=\"Predicted class (nb of predictions)\",\n",
    "            y_title=\"Mean coverage\",\n",
    "            row_titles=list(classes),\n",
    "            column_titles=list(classes),\n",
    "            vertical_spacing=0.08,\n",
    "            horizontal_spacing=0.01,\n",
    "        )\n",
    "        threshold_df = assay_df[assay_df[\"Max pred\"] >= threshold]\n",
    "        for label in classes:\n",
    "            df_label = threshold_df[threshold_df[\"True class\"] == label]\n",
    "\n",
    "            # Iterate over each target and add a violin plot for it\n",
    "            for target in classes:\n",
    "                sub_df = df_label[df_label[\"Predicted class\"] == target]\n",
    "\n",
    "                if len(assay_list) == 1:\n",
    "                    hovertext = [\n",
    "                        f\"{md5sum}:(chrY={chrY_val:.3f}, pred={pred:.3f})\"\n",
    "                        for md5sum, pred, chrY_val in zip(\n",
    "                            sub_df.index, sub_df[\"Max pred\"], sub_df[coverage_label]\n",
    "                        )\n",
    "                    ]\n",
    "                else:\n",
    "                    hovertext = [\n",
    "                        f\"{md5sum},{assay}:(chrY={chrY_val:.3f}, pred={pred:.3f})\"\n",
    "                        for md5sum, pred, chrY_val, assay in zip(\n",
    "                            sub_df.index,\n",
    "                            sub_df[\"Max pred\"],\n",
    "                            sub_df[coverage_label],\n",
    "                            sub_df[ASSAY],\n",
    "                        )\n",
    "                    ]\n",
    "                fig.add_trace(\n",
    "                    go.Violin(\n",
    "                        y=sub_df[coverage_label],\n",
    "                        name=f\"{target} ({sub_df.shape[0]})\",\n",
    "                        box_visible=True,\n",
    "                        meanline_visible=True,\n",
    "                        points=\"all\",\n",
    "                        text=hovertext,\n",
    "                        line_color=COLORS_DICT[target],\n",
    "                        hovertemplate=\"%{text}\",\n",
    "                    ),\n",
    "                    row=row,\n",
    "                    col=col,\n",
    "                )\n",
    "\n",
    "                # Move to the next subplot position\n",
    "                col += 1\n",
    "                if col > 3:\n",
    "                    col = 1\n",
    "                    row += 1\n",
    "\n",
    "        # Update global layout and traces\n",
    "        fig.update_traces(marker=dict(size=1))\n",
    "        fig.update_yaxes(range=[-0.001, max(assay_df[coverage_label])])\n",
    "\n",
    "        # Directly using annotations param does not work with make_subplots\n",
    "        existing_annotations = fig.layout.annotations\n",
    "        new_annotation = dict(\n",
    "            x=1.01,  # Position on the x-axis\n",
    "            y=0.5,  # Position on the y-axis\n",
    "            showarrow=False,  # Do not show arrow\n",
    "            text=\"Reference class\",  # The text you want to display\n",
    "            xref=\"paper\",  # 'x' coordinate is set in relative coordinates\n",
    "            yref=\"paper\",  # 'y' coordinate is set in relative coordinates\n",
    "            xanchor=\"left\",  # Text starts from the left of the x-coordinate\n",
    "            yanchor=\"middle\",  # Middle aligned vertically\n",
    "            font=dict(size=16),\n",
    "            textangle=90,\n",
    "        )\n",
    "        updated_annotations = list(existing_annotations) + [new_annotation]\n",
    "\n",
    "        title = f\"Mean chrY coverage per file, {','.join(assay_list)} (pred>{threshold})<br>(no fc/pval)\"\n",
    "\n",
    "        fig.update_layout(\n",
    "            title_text=f\"{title} (n={threshold_df.shape[0]})\",\n",
    "            showlegend=False,\n",
    "            annotations=updated_annotations,\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        title = get_valid_filename(title).replace(\"_br_\", \"_\")\n",
    "        fig.write_html(logdir_10fold_per_assay / f\"{title}.html\")\n",
    "        fig.write_image(logdir_10fold_per_assay / f\"{title}.png\", scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chrY + chrX + ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = merged_df[merged_df[\"Max pred\"] > 0.9]\n",
    "# merged_df = merged_df[\n",
    "#     ~merged_df[\"assay_epiclass\"].str.contains(pat=\"input|wgb\", case=False)\n",
    "# ]\n",
    "\n",
    "# for label in classes:\n",
    "#     df_label = merged_df[merged_df[\"Predicted class\"] == label]\n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     # Iterate classes each target and add a violin plot for it\n",
    "#     for target in classes:\n",
    "#         for coverage_label in [\"chrY\", \"chrX\", \"chrY/chrX\"]:\n",
    "#             sub_df = df_label[df_label[\"True class\"] == target]\n",
    "\n",
    "#             fig.add_trace(\n",
    "#                 go.Violin(\n",
    "#                     y=sub_df[coverage_label],\n",
    "#                     name=f\"{target}: {coverage_label} ({sub_df.shape[0]})\",\n",
    "#                     box_visible=True,\n",
    "#                     meanline_visible=True,\n",
    "#                     points=\"all\",\n",
    "#                     text=sub_df.index,\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#     # title = f\"Coverage distribution for prediction {label}\"\n",
    "#     title = f\"Coverage distribution for prediction {label}, max_pred > 0.9\"\n",
    "#     fig.update_layout(\n",
    "#         title_text=f\"{title} ({df_label.shape[0]})\",\n",
    "#         yaxis_title=\"Mean coverage\",\n",
    "#         xaxis_title=\"True class\"\n",
    "#     )\n",
    "#     fig.update_traces(marker=dict(size=1))\n",
    "#     fig.update_yaxes(range=[-0.001, 2])\n",
    "\n",
    "\n",
    "#     fig.show()\n",
    "\n",
    "#     title = get_valid_filename(title)\n",
    "#     # fig.write_html(logdir / f\"{title}.html\")\n",
    "#     # fig.write_image(logdir / f\"{title}.png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label in classes:\n",
    "#     df_label = merged_df[merged_df[\"True class\"] == label]\n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     # Iterate classes each target and add a violin plot for it\n",
    "#     for target in classes:\n",
    "#         for coverage_label in [\"chrY\", \"chrX\", \"chrY/chrX\"]:\n",
    "#             sub_df = df_label[df_label[\"Predicted class\"] == target]\n",
    "\n",
    "#             fig.add_trace(\n",
    "#                 go.Violin(\n",
    "#                     y=sub_df[coverage_label],\n",
    "#                     name=f\"{target}: {coverage_label} ({sub_df.shape[0]})\",\n",
    "#                     box_visible=True,\n",
    "#                     meanline_visible=True,\n",
    "#                     points=\"all\",\n",
    "#                     text=sub_df.index,\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#     # title = f\"Coverage distribution for label {label}\"\n",
    "#     title = f\"Coverage distribution for label {label}, max_pred > 0.9\"\n",
    "#     fig.update_layout(\n",
    "#         title_text=f\"{title} ({df_label.shape[0]})\",\n",
    "#         yaxis_title=\"Mean coverage\",\n",
    "#         xaxis_title=\"Predicted class\",\n",
    "#     )\n",
    "#     fig.update_yaxes(range=[-0.001, 1.5])\n",
    "#     fig.update_traces(marker=dict(size=1))\n",
    "\n",
    "#     fig.show()\n",
    "\n",
    "#     title = get_valid_filename(title)\n",
    "#     # fig.write_html(logdir / f\"{title}.html\")\n",
    "#     # fig.write_image(logdir / f\"{title}.png\", scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epiRR version (1 epiRR ~ 1 data point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = merged_df[\"Predicted class\"].unique()\n",
    "\n",
    "epirr_df = (\n",
    "    merged_df.groupby([\"EpiRR\", \"True class\", \"Predicted class\"])\n",
    "    .agg({\"Max pred\": [\"mean\", \"median\"], \"chrY\": [\"mean\", \"median\"], \"EpiRR\": [\"count\"]})\n",
    "    .reset_index()\n",
    "    .set_index(\"EpiRR\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epirr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = epirr_df[\n",
    "#     (epirr_df[\"True class\"] == \"mixed\")\n",
    "#     & (epirr_df[\"Predicted class\"] == \"female\")\n",
    "#     & (~epirr_df[\"track_type\"].str.contains(\"fc|pval\"))\n",
    "# ]\n",
    "# display(test)\n",
    "# print(test.index.value_counts().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed_columns = [\"True class\", \"Predicted class\", \"EpiRR\", \"Max pred\"]\n",
    "# merged_df[\n",
    "#     (merged_df[\"True class\"] == \"mixed\")\n",
    "#     & (merged_df[\"Predicted class\"] == \"female\")\n",
    "#     & (~merged_df[\"track_type\"].str.contains(\"fc|pval\"))\n",
    "# ][needed_columns].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_label = \"chrY\"\n",
    "\n",
    "for metric, pred_threshold in itertools.product([\"mean\", \"median\"], [0, 0.7, 0.9]):\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=3,\n",
    "        shared_yaxes=True,\n",
    "        x_title=\"Predicted class (nb of epiRR)\",\n",
    "        y_title=f\"{metric} coverage\",\n",
    "        row_titles=list(classes),\n",
    "        column_titles=list(classes),\n",
    "        vertical_spacing=0.08,\n",
    "        horizontal_spacing=0.01,\n",
    "    )\n",
    "\n",
    "    row = 1\n",
    "    col = 1\n",
    "    threshold_sub_df = epirr_df[epirr_df[\"Max pred\"][f\"{metric}\"] > pred_threshold]\n",
    "    for label in classes:\n",
    "        df_label = threshold_sub_df[threshold_sub_df[\"True class\"] == label]\n",
    "        for target in classes:\n",
    "            sub_df = df_label[df_label[\"Predicted class\"] == target]\n",
    "\n",
    "            hovertext = [\n",
    "                f\"{epirr} (n={count}) pred:{pred:.02f}\"\n",
    "                for (epirr, count), pred in zip(\n",
    "                    sub_df.index, sub_df[\"Max pred\"][f\"{metric}\"]\n",
    "                )\n",
    "            ]\n",
    "            fig.add_trace(\n",
    "                go.Violin(\n",
    "                    y=sub_df[coverage_label][f\"{metric}\"],\n",
    "                    name=f\"{target}: {metric}({coverage_label}) ({sub_df.shape[0]})\",\n",
    "                    box_visible=True,\n",
    "                    meanline_visible=True,\n",
    "                    points=\"all\",\n",
    "                    line_color=COLORS_DICT[target],\n",
    "                    text=hovertext,\n",
    "                    hovertemplate=\"%{text}\",\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col,\n",
    "            )\n",
    "\n",
    "            # Move to the next subplot position\n",
    "            col += 1\n",
    "            if col > 3:\n",
    "                col = 1\n",
    "                row += 1\n",
    "\n",
    "    # Update global layout and traces\n",
    "    fig.update_traces(marker=dict(size=1))\n",
    "    fig.update_yaxes(range=[-0.001, 1.5])\n",
    "\n",
    "    # Directly using annotations param does not work with make_subplots\n",
    "    existing_annotations = fig.layout.annotations\n",
    "    new_annotation = dict(\n",
    "        x=1.01,  # Position on the x-axis\n",
    "        y=0.5,  # Position on the y-axis\n",
    "        showarrow=False,  # Do not show arrow\n",
    "        text=\"Reference class\",  # The text you want to display\n",
    "        xref=\"paper\",  # 'x' coordinate is set in relative coordinates\n",
    "        yref=\"paper\",  # 'y' coordinate is set in relative coordinates\n",
    "        xanchor=\"left\",  # Text starts from the left of the x-coordinate\n",
    "        yanchor=\"middle\",  # Middle aligned vertically\n",
    "        font=dict(size=16),\n",
    "        textangle=90,\n",
    "    )\n",
    "    updated_annotations = list(existing_annotations) + [new_annotation]\n",
    "\n",
    "    title = f\"Coverage distribution of {metric}({coverage_label}) per epiRR<br>{metric}(max_pred) > {pred_threshold} (no fc/pval/input/wgb)\"\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f\"{title} (n={threshold_sub_df.shape[0]})\",\n",
    "        showlegend=False,\n",
    "        annotations=updated_annotations,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    # title = get_valid_filename(title).replace(\"_br_\", \"_\")\n",
    "    # fig.write_html(logdir / f\"{title}.html\")\n",
    "    # fig.write_image(logdir / f\"{title}.png\", scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chrY - unknown samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_path = general_local_logdir / \"chrY_coverage_results\" / \"chrXY_coverage_all.csv\"\n",
    "coverage_df = pd.read_csv(coverage_path, index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_predict_path = (\n",
    "    general_local_logdir\n",
    "    / \"sex3_complete_no_valid_oversample_test_prediction_100kb_all_none_dfreeze_v2.1_sex_mixed_unknown_augmented-all.csv\"\n",
    ")\n",
    "unknown_predict_df = pd.read_csv(unknown_predict_path, index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"unknown\"\n",
    "unknown_predict_df = unknown_predict_df[unknown_predict_df[\"True class\"] == label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_predict_df = unknown_predict_df[\n",
    "    ~unknown_predict_df[TRACK].str.contains(pat=\"pval|fc\", case=False)\n",
    "]\n",
    "unknown_predict_df = unknown_predict_df.merge(\n",
    "    coverage_df, left_index=True, right_index=True, how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All samples (1 sample = 1 data point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_logdir = general_local_logdir / \"chrY_coverage_results\" / \"unknown_per_assay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = unknown_predict_df[\"Predicted class\"].unique()\n",
    "coverage_label = \"chrY\"\n",
    "\n",
    "assay_labels = get_assay_list(unknown_predict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for assay_list in assay_labels:\n",
    "    # Initialize subplots figure\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=1,\n",
    "        subplot_titles=(\"pred>0\", \"pred>0.7\", \"pred>0.9\"),\n",
    "        vertical_spacing=0.075,\n",
    "        x_title=\"Predicted class (nb of predictions)\",\n",
    "        y_title=\"Mean coverage\",\n",
    "    )\n",
    "\n",
    "    assay_sub_df = unknown_predict_df[\n",
    "        unknown_predict_df[\"assay_epiclass\"].isin(assay_list)\n",
    "    ]\n",
    "\n",
    "    for idx, pred_threshold in enumerate([0, 0.7, 0.9]):\n",
    "        threshold_sub_df = assay_sub_df[assay_sub_df[\"Max pred\"] > pred_threshold]\n",
    "\n",
    "        for target in classes:\n",
    "            sub_df = threshold_sub_df[threshold_sub_df[\"Predicted class\"] == target]\n",
    "\n",
    "            if len(assay_list) == 1:\n",
    "                hovertext = [\n",
    "                    f\"{md5sum}:(chrY={chrY_val:.3f}, pred={pred:.3f})\"\n",
    "                    for md5sum, pred, chrY_val in zip(\n",
    "                        sub_df.index, sub_df[\"Max pred\"], sub_df[coverage_label]\n",
    "                    )\n",
    "                ]\n",
    "            else:\n",
    "                hovertext = [\n",
    "                    f\"{md5sum},{assay}:(chrY={chrY_val:.3f}, pred={pred:.3f})\"\n",
    "                    for md5sum, pred, chrY_val, assay in zip(\n",
    "                        sub_df.index,\n",
    "                        sub_df[\"Max pred\"],\n",
    "                        sub_df[coverage_label],\n",
    "                        sub_df[ASSAY],\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            # Add traces with checks for empty subsets\n",
    "            if sub_df.shape[0] == 0:\n",
    "                y_values = [\n",
    "                    threshold_sub_df[coverage_label].mean()\n",
    "                ]  # Minimal synthetic data\n",
    "                sample_count = 0\n",
    "                hovertext = [\"PLACEHOLDER - NO DATA\"]\n",
    "            else:\n",
    "                y_values = sub_df[coverage_label]\n",
    "                sample_count = sub_df.shape[0]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Violin(\n",
    "                    y=y_values,\n",
    "                    name=f\"{target}: {coverage_label} ({sample_count})\",\n",
    "                    box_visible=True,\n",
    "                    meanline_visible=True,\n",
    "                    points=\"all\",\n",
    "                    text=hovertext,\n",
    "                    hovertemplate=\"%{text}\",\n",
    "                    line_color=COLORS_DICT[target],\n",
    "                    legendgroup=target,\n",
    "                ),\n",
    "                row=idx + 1,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "    title = f\"Coverage distribution for {coverage_label} in {','.join(assay_list)} (no fc/pval)\"\n",
    "    fig.update_layout(title_text=f\"{title}\", height=1200)\n",
    "\n",
    "    # Update y-axis range\n",
    "    try:\n",
    "        fig.update_yaxes(range=[-0.001, max(assay_sub_df[coverage_label])])\n",
    "    except ValueError:\n",
    "        # Set a default y-axis range when no samples are available\n",
    "        fig.update_yaxes(range=[-0.001, 1])\n",
    "\n",
    "    fig.update_traces(marker=dict(size=1))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    title = get_valid_filename(title)\n",
    "    fig.write_html(unknown_logdir / f\"{title}.html\")\n",
    "    fig.write_image(unknown_logdir / f\"{title}.png\", scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epiRR version (1 epiRR ~ 1 data point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_predict_df = unknown_predict_df[\n",
    "    ~unknown_predict_df[ASSAY].str.contains(pat=\"wgb\", case=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = unknown_predict_df[\"Predicted class\"].unique()\n",
    "\n",
    "epirr_df = (\n",
    "    unknown_predict_df.groupby([\"EpiRR\", \"Predicted class\"])\n",
    "    .agg({\"Max pred\": [\"mean\", \"median\"], \"chrY\": [\"mean\", \"median\"], \"EpiRR\": [\"count\"]})\n",
    "    .reset_index()\n",
    "    .set_index(\"EpiRR\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unknown_predict_df.shape)\n",
    "print(epirr_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epirr_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir_unknown_epirr = (\n",
    "    general_local_logdir / \"chrY_coverage_results\" / \"unknown_per_epirr\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_label = \"chrY\"\n",
    "thresholds = [0, 0.7, 0.9]\n",
    "\n",
    "for agg_metric in [\"mean\", \"median\"]:\n",
    "    subplot_titles = [f\"{agg_metric}(pred)>{threshold}\" for threshold in thresholds]\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=1,\n",
    "        subplot_titles=subplot_titles,\n",
    "        vertical_spacing=0.075,\n",
    "        x_title=\"Predicted class (nb of predictions)\",\n",
    "        y_title=\"agg(Mean chrY coverage) \",\n",
    "    )\n",
    "\n",
    "    for row_idx, pred_threshold in enumerate(thresholds):\n",
    "        threshold_sub_df = epirr_df[\n",
    "            epirr_df[\"Max pred\"][f\"{agg_metric}\"] > pred_threshold\n",
    "        ]\n",
    "\n",
    "        for target in classes:\n",
    "            sub_df = threshold_sub_df[threshold_sub_df[\"Predicted class\"] == target]\n",
    "\n",
    "            # Add traces with checks for empty subsets\n",
    "            if sub_df.shape[0] == 0:\n",
    "                y_values = [\n",
    "                    threshold_sub_df[coverage_label][f\"{agg_metric}\"].mean()\n",
    "                ]  # Minimal synthetic data\n",
    "                sample_count = 0\n",
    "                sample_text = [\"PLACEHOLDER - NO DATA\"]\n",
    "            else:\n",
    "                y_values = sub_df[coverage_label][f\"{agg_metric}\"]\n",
    "                sample_count = sub_df.shape[0]\n",
    "                sample_text = [\n",
    "                    (f\"{value:.3f}\", epirr, f\"{agg_metric}={pred:.3f}(n={count})\")\n",
    "                    for value, (epirr, count), pred in zip(\n",
    "                        y_values, sub_df.index, sub_df[\"Max pred\"][f\"{agg_metric}\"]\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Violin(\n",
    "                    y=y_values,\n",
    "                    name=f\"{target}: {agg_metric}({coverage_label}) ({sample_count})\",\n",
    "                    box_visible=True,\n",
    "                    meanline_visible=True,\n",
    "                    points=\"all\",\n",
    "                    text=sample_text,\n",
    "                    hovertemplate=\"%{text}\",\n",
    "                    line_color=COLORS_DICT[target],\n",
    "                    legendgroup=target,\n",
    "                ),\n",
    "                row=row_idx + 1,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "    title = f\"Coverage distribution of {agg_metric}({coverage_label}) for {label} per epiRR (no fc/pval/wgb)\"\n",
    "    fig.update_layout(\n",
    "        title_text=f\"{title}\", height=1200  # Adjust the overall height of the figure\n",
    "    )\n",
    "\n",
    "    # Update y-axis range\n",
    "    try:\n",
    "        fig.update_yaxes(range=[-0.001, max(epirr_df[coverage_label][f\"{agg_metric}\"])])\n",
    "    except ValueError as e:\n",
    "        fig.update_yaxes(range=[-0.001, 1])\n",
    "\n",
    "    fig.update_traces(marker=dict(size=1))\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    title = get_valid_filename(title).replace(\"_br_\", \"_\")\n",
    "    fig.write_html(logdir_unknown_epirr / f\"{title}.html\")\n",
    "    fig.write_image(logdir_unknown_epirr / f\"{title}.png\", scale=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
