{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Get ENCODE EpiRRs, and determine which datasets are in EpiATLAS\"\"\"\n",
    "# pylint: disable=import-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from epi_ml.core.metadata import Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAY = \"assay_epiclass\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download summary of all EpiRR epigenomes: https://www.ebi.ac.uk/epirr/docs  \n",
    "This was already done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "metadata_dir = base_dir / \"data/metadata\"\n",
    "if not metadata_dir.exists():\n",
    "    raise ValueError(f\"Path {metadata_dir} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse EpiRR general metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_metadata_dir = metadata_dir / \"encode\"\n",
    "\n",
    "filename = \"epirr_epigenomes_2025-02\"\n",
    "epigenomes_summary_path = encode_metadata_dir / f\"{filename}.json\"\n",
    "\n",
    "with open(epigenomes_summary_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    epigenomes_summary = json.load(f)\n",
    "\n",
    "epigenomes_summary_df = pd.DataFrame(epigenomes_summary)\n",
    "epigenomes_summary_df.to_csv(encode_metadata_dir / f\"{filename}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(epigenomes_summary_df[\"project\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_epirrs = epigenomes_summary_df[epigenomes_summary_df[\"project\"] == \"ENCODE\"][\n",
    "    \"accession\"\n",
    "].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ENCODE EpiRRs: {len(encode_epirrs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download specific experiments metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download metadata for all encode epigenomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_metadata_path = encode_metadata_dir / \"encode_epigenomes_metadata_2025-02.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not encode_metadata_path.exists():\n",
    "    # Base URL\n",
    "    base_url = \"https://www.ebi.ac.uk/epirr/api/v1/epigenome?accession={}\"\n",
    "\n",
    "    # Collect metadata in a list\n",
    "    metadata_list = []\n",
    "\n",
    "    # Use tqdm for a progress bar\n",
    "    for epirr in tqdm(encode_epirrs, desc=\"Fetching Metadata\", unit=\"entry\"):\n",
    "        response = requests.get(\n",
    "            base_url.format(epirr), headers={\"accept\": \"application/json\"}\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            metadata_list.append(response.json())  # Append parsed JSON\n",
    "        else:\n",
    "            print(f\"Failed to fetch {epirr}: {response.status_code}\")\n",
    "\n",
    "    with open(encode_metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata_list, f, indent=2)\n",
    "\n",
    "    print(f\"Metadata saved to {encode_metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse specific metadata for accessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_metadata_path = encode_metadata_dir / \"encode_epigenomes_metadata_2025-02.json\"\n",
    "with open(encode_metadata_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    encode_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessions_and_epirr = []\n",
    "for dset in encode_metadata:\n",
    "    epirr = dset[\"accession\"]\n",
    "    primary_ids = [file[\"primary_id\"] for file in dset[\"raw_data\"]]\n",
    "    for primary_id in primary_ids:\n",
    "        accessions_and_epirr.append((primary_id, epirr))\n",
    "\n",
    "    # # it's an input file, multiple occurences is fine\n",
    "    # if \"ENCSR266XMB\" in primary_ids:\n",
    "    #     print(dset[\"raw_data\"])\n",
    "print(\"ENCODE total accessions:\", len(accessions_and_epirr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_ids_count = Counter([primary_id for primary_id, _ in accessions_and_epirr])\n",
    "print(\"ENCODE unique accessions:\", len(set(primary_ids_count.keys())))\n",
    "print(primary_ids_count.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(epirr for _, epirr in accessions_and_epirr) == set(encode_epirrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with EpiATLAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiatlas_metadata_path = (\n",
    "    metadata_dir / \"official\" / \"IHEC_metadata_harmonization.v1.2.extended.csv\"\n",
    ")\n",
    "epiatlas_df = pd.read_csv(epiatlas_metadata_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiatlas_epirrs = set(epiatlas_df[\"epirr_id_without_version\"].tolist())\n",
    "common_epirrs = set(encode_epirrs).intersection(epiatlas_epirrs)\n",
    "diff_epirr = set(encode_epirrs).difference(epiatlas_epirrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ENCODE EpiRRs: {len(encode_epirrs)}\")\n",
    "print(f\"EpiATLAS EpiRRs: {len(epiatlas_epirrs)}\")\n",
    "print(f\"ENCODE EpiRRs in EpiATLAS: {len(common_epirrs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_accessions_df = pd.DataFrame.from_records(\n",
    "    accessions_and_epirr, columns=[\"experiment_accession\", \"epirr_no_version\"]\n",
    ")\n",
    "print(encode_accessions_df.shape)\n",
    "\n",
    "encode_accessions_df[\"in_epiatlas\"] = encode_accessions_df[\"epirr_no_version\"].isin(\n",
    "    common_epirrs\n",
    ")\n",
    "display(encode_accessions_df[\"in_epiatlas\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(encode_accessions_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_accessions_df.to_csv(\n",
    "    encode_metadata_dir / \"encode_epirrs_2025-02.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EpiRR is less useful because ENCODE only submitted complete epigenomes. EpiATLAS also includes partial ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with previous ENCODE metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_meta_df = pd.read_csv(\n",
    "    encode_metadata_dir / \"encode_metadata_2023-10-25_clean-v2.csv\"\n",
    ")\n",
    "encode_ihec_df = pd.read_csv(encode_metadata_dir / \"ENCODE_IHEC_keys.tsv\", sep=\"\\t\")\n",
    "print(encode_meta_df.shape)\n",
    "print(encode_ihec_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(encode_meta_df.head())\n",
    "display(encode_ihec_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_accession_1 = encode_meta_df[\"experiment_accession\"].nunique()\n",
    "N_accession_2 = encode_ihec_df[\"accession\"].nunique()\n",
    "print(f\"ENCODE metadata 2023-10-25 accessions: {N_accession_1}\")\n",
    "print(f\"ENCODE-IHEC file accessions: {N_accession_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(encode_ihec_df[ASSAY].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(encode_meta_df[ASSAY].value_counts(dropna=False))\n",
    "display(\n",
    "    encode_meta_df[~encode_meta_df[\"md5sum\"].isin(encode_ihec_df[\"ENC_ID\"])][\n",
    "        \"Assay\"\n",
    "    ].value_counts(dropna=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: non-core files are not included in ENCODE_IHEC_keys.tsv. That's okay because these files were only used for training assay13, and were not included in any other classifier training. We now have enough information to create an almost complete \"in_epiatlas\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `in_epiatlas` creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_ihec_df[\"in_epiatlas\"] = encode_ihec_df[\"is_EpiAtlas_EpiRR\"].notnull()\n",
    "display(encode_ihec_df[\"in_epiatlas\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: accession, in_epiatlas pairs consistent (accessions are not unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_ihec_df_pairs = encode_ihec_df[[\"accession\", \"in_epiatlas\"]].values.tolist()\n",
    "encode_ihec_df_pairs = tuple(zip(*encode_ihec_df_pairs))\n",
    "if len(encode_ihec_df_pairs) != len(set(encode_ihec_df_pairs)):\n",
    "    raise ValueError(\"Inconsistent 'in_epiatlas' values:\", encode_ihec_df_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epirr_in_epiatlas = encode_accessions_df[[\"in_epiatlas\", \"experiment_accession\"]]\n",
    "alt_in_epiatlas = encode_ihec_df[[\"in_epiatlas\", \"accession\"]]\n",
    "\n",
    "common_accessions = set(epirr_in_epiatlas[\"experiment_accession\"]).intersection(\n",
    "    set(alt_in_epiatlas[\"accession\"])\n",
    ")\n",
    "alt_in_epiatlas_common = alt_in_epiatlas[\n",
    "    alt_in_epiatlas[\"accession\"].isin(common_accessions)\n",
    "]\n",
    "epirr_in_epiatlas_common = epirr_in_epiatlas[\n",
    "    epirr_in_epiatlas[\"experiment_accession\"].isin(common_accessions)\n",
    "]\n",
    "\n",
    "inconsistent_accession_tuples = []\n",
    "for accession in common_accessions:\n",
    "    in_epitlas_1 = epirr_in_epiatlas_common[\n",
    "        epirr_in_epiatlas_common[\"experiment_accession\"] == accession\n",
    "    ][\"in_epiatlas\"].values\n",
    "    in_epitlas_2 = alt_in_epiatlas_common[\n",
    "        alt_in_epiatlas_common[\"accession\"] == accession\n",
    "    ][\"in_epiatlas\"].values\n",
    "    if len(in_epitlas_1) != 1:\n",
    "        # print(accession, in_epitlas_1)\n",
    "        in_epitlas_1 = any(in_epitlas_1)\n",
    "    else:\n",
    "        in_epitlas_1 = in_epitlas_1[0]\n",
    "    if len(in_epitlas_2) != 1:\n",
    "        # print(accession, in_epitlas_2)\n",
    "        in_epitlas_2 = any(in_epitlas_2)\n",
    "    else:\n",
    "        in_epitlas_2 = in_epitlas_2[0]\n",
    "\n",
    "    if in_epitlas_1 != in_epitlas_2:\n",
    "        inconsistent_accession_tuples.append((accession, in_epitlas_1, in_epitlas_2))\n",
    "        # raise ValueError(\"Inconsistent 'in_epiatlas' values:\", accession, in_epitlas_1, in_epitlas_2)\n",
    "\n",
    "print(\"Inconsistent 'in_epiatlas' values:\", len(inconsistent_accession_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_accession_values = [dset[0] for dset in inconsistent_accession_tuples]\n",
    "suspect_df = encode_ihec_df[\n",
    "    encode_ihec_df[\"accession\"].isin(inconsistent_accession_values)\n",
    "]\n",
    "display(suspect_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_biosample_accs = suspect_df[suspect_df[\"biosample_accession\"].str.endswith(\"DMP\")][\n",
    "    \"accession\"\n",
    "].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_epirr_inputs_acc = [\"ENCSR000AHE\", \"ENCSR000DMW\", \"ENCSR000EWW\", \"ENCSR768LHG\"]\n",
    "for acc in one_epirr_inputs_acc:\n",
    "    print(acc, acc in inconsistent_accession_values)\n",
    "\n",
    "display(encode_ihec_df[encode_ihec_df[\"accession\"].isin(one_epirr_inputs_acc)])\n",
    "display(encode_meta_df[encode_meta_df[\"experiment_accession\"].isin(one_epirr_inputs_acc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(encode_ihec_df[encode_ihec_df[\"accession\"].isin(one_biosample_accs)])\n",
    "display(encode_meta_df[encode_meta_df[\"experiment_accession\"].isin(one_biosample_accs)])\n",
    "display(\n",
    "    encode_accessions_df[\n",
    "        encode_accessions_df[\"experiment_accession\"].isin(one_biosample_accs)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_epirr_example = set(\n",
    "    encode_accessions_df[\n",
    "        encode_accessions_df[\"experiment_accession\"].isin(one_biosample_accs)\n",
    "    ][\"epirr_no_version\"].values.tolist()\n",
    ")\n",
    "if len(problematic_epirr_example) > 1:\n",
    "    raise ValueError(\"One biosample with multiple epirrs\", problematic_epirr_example)\n",
    "\n",
    "problematic_epirr_example = problematic_epirr_example.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EpiClass actual training metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiclass_metadata_path = (\n",
    "    metadata_dir / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl.json\"\n",
    ")\n",
    "epiclass_metadata = Metadata(epiclass_metadata_path)\n",
    "epiclass_df = pd.DataFrame.from_records(list(epiclass_metadata.datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiclass_epirrs = set(epiclass_df[\"epirr_id_without_version\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(problematic_epirr_example in epiclass_epirrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Some errors have been made during the creation of \"ENCODE_IHEC_keys.tsv\". As demonstrated by having a set of files from a biosamples being marked as not having an epirr, when we found the corresponding epirr in the training metadata. We need to recreate the metadata from zero to guarantee the right values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
