{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbook to create figures destined for the paper.\"\"\"\n",
    "# pylint: disable=import-error, redefined-outer-name, use-dict-literal, too-many-lines, unused-import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import confusion_matrix as sk_cm\n",
    "\n",
    "from epi_ml.core.confusion_matrix import ConfusionMatrixWriter\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import (\n",
    "    ASSAY,\n",
    "    CELL_TYPE,\n",
    "    IHECColorMap,\n",
    "    MetadataHandler,\n",
    "    SplitResultsHandler,\n",
    "    merge_similar_assays,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "base_data_dir = base_dir / \"data\"\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "if not base_fig_dir.exists():\n",
    "    raise FileNotFoundError(f\"Directory {base_fig_dir} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IHECColorMap = IHECColorMap(base_fig_dir)\n",
    "assay_colors = IHECColorMap.assay_color_map\n",
    "cell_type_colors = IHECColorMap.cell_type_color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results_handler = SplitResultsHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 2 - EpiClass results on EpiAtlas other metadata\n",
    "\n",
    "For all sub-figures 2+3 use v1.1 of sample metadata (called v2.1 internally)\n",
    "\n",
    "A) Histogram of performance (accuracy and F1 scores) for each category (using metadata v1)  \n",
    "B) Violin plot of average z-score on chrY per sex, black dots for pred same class and red for pred different class.  \n",
    "- Do the split male female violin per assay (only FC, merge 2xwgbs and 2xrna, no rna unique_raw). \n",
    "- Use scatter for points on each side, agree same color as violin, disagree other.\n",
    "- Point labels: uuid, epirr  \n",
    "\n",
    "C) ---  \n",
    "D) ---  \n",
    "E) SHAP cell-types GO  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 2.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if all training runs were done with oversampling on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_results_dir = base_data_dir / \"dfreeze_v1\"\n",
    "if not v1_results_dir.exists():\n",
    "    raise FileNotFoundError(f\"Directory {v1_results_dir} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_oversampling(base_data_dir: Path):\n",
    "    \"\"\"Check for oversampling status in the results.\"\"\"\n",
    "    # Identify experiments\n",
    "    exp_key_line = \"The current experiment key is\"\n",
    "    exp_keys_dict = defaultdict(list)\n",
    "    for category in v1_results_dir.iterdir():\n",
    "        for stdout_file in category.glob(\"*/output_job*.o\"):\n",
    "            with open(stdout_file, \"r\", encoding=\"utf8\") as f:\n",
    "                lines = [l.rstrip() for l in f if exp_key_line in l]\n",
    "            exp_keys = [l.split(exp_key_line)[1].strip() for l in lines]\n",
    "            exp_keys_dict[category.name].extend(exp_keys)\n",
    "\n",
    "    # Get all hparam values\n",
    "    gen_run_metadata = (\n",
    "        base_data_dir / \"all_results_cometml_filtered_oversampling-fixed.csv\"\n",
    "    )\n",
    "    run_metadata = pd.read_csv(gen_run_metadata, header=0)\n",
    "\n",
    "    # Check oversampling values\n",
    "    all_exp_keys = set()\n",
    "    for exp_keys in exp_keys_dict.values():\n",
    "        all_exp_keys.update(exp_keys)\n",
    "\n",
    "    df = run_metadata[run_metadata[\"experimentKey\"].isin(all_exp_keys)]\n",
    "    display(df[\"hparams/oversampling\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_oversampling(base_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
