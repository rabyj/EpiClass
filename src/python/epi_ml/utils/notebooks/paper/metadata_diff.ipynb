{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Workbooks to analyze metadata differences.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Workbooks to analyze metadata differences.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import io\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from epi_ml.core.metadata import Metadata\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import (\n",
    "    BIOMATERIAL_TYPE,\n",
    "    CELL_TYPE,\n",
    "    DISEASE,\n",
    "    LIFE_STAGE,\n",
    "    SEX,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dir = Path().home() / \"Projects/epiclass/output/paper\"\n",
    "paper_meta_dir = paper_dir / \"data\" / \"metadata\"\n",
    "\n",
    "table_dir = paper_dir / \"tables\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our training metadata VS official metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata we use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = paper_meta_dir / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl.json\"\n",
    "training_metadata = Metadata(path)\n",
    "files_df = training_metadata.to_df()\n",
    "training_df = files_df.copy(deep=True)\n",
    "\n",
    "# keeping biological samples only, not track types or assays (EpiRR level)\n",
    "training_df = training_df.drop_duplicates(subset=[\"epirr_id_without_version\"])\n",
    "my_epirrs = set(training_df[\"epirr_id_without_version\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevants_cols = [CELL_TYPE, BIOMATERIAL_TYPE, SEX, DISEASE, LIFE_STAGE]\n",
    "training_df = training_df[[\"epirr_id_without_version\"] + relevants_cols]\n",
    "training_df = training_df.set_index(\"epirr_id_without_version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Official metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading version v1.0: https://raw.githubusercontent.com/IHEC/epiATLAS-metadata-harmonization/refs/heads/main/openrefine/v1.0/IHEC_metadata_harmonization.v1.0.extended.csv\n",
      "Downloading version v1.1: https://raw.githubusercontent.com/IHEC/epiATLAS-metadata-harmonization/refs/heads/main/openrefine/v1.1/IHEC_metadata_harmonization.v1.1.extended.csv\n",
      "Downloading version v1.2: https://raw.githubusercontent.com/IHEC/epiATLAS-metadata-harmonization/refs/heads/main/openrefine/v1.2/IHEC_metadata_harmonization.v1.2.extended.csv\n",
      "Downloading version v1.3: https://raw.githubusercontent.com/IHEC/epiATLAS-metadata-harmonization/refs/heads/main/openrefine/v1.3/IHEC_metadata_harmonization.v1.3.extended.csv\n",
      "Error downloading https://raw.githubusercontent.com/IHEC/epiATLAS-metadata-harmonization/refs/heads/main/openrefine/v1.3/IHEC_metadata_harmonization.v1.3.extended.csv: 404 Client Error: Not Found for url: https://raw.githubusercontent.com/IHEC/epiATLAS-metadata-harmonization/refs/heads/main/openrefine/v1.3/IHEC_metadata_harmonization.v1.3.extended.csv\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "\n",
    "url_template = \"https://raw.githubusercontent.com/IHEC/epiATLAS-metadata-harmonization/refs/heads/main/openrefine/{version}/IHEC_metadata_harmonization.{version}.extended.csv\"\n",
    "for version in [\"v1.0\", \"v1.1\", \"v1.2\", \"v1.3\"]:\n",
    "    myurl = url_template.format(version=version)\n",
    "    print(f\"Downloading version {version}: {myurl}\")\n",
    "\n",
    "    try:\n",
    "        # Download the file\n",
    "        response = requests.get(myurl, stream=True)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx, 5xx)\n",
    "\n",
    "        # Load file as a DataFrame\n",
    "        content = response.content\n",
    "        df = pd.read_csv(io.StringIO(content.decode(\"utf-8\")))\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {myurl}: {e}\")\n",
    "\n",
    "    dfs[version] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify dataframes to fit with our metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v, df in dfs.items():\n",
    "    df[\"epirr_id_without_version\"] = df[\"EpiRR\"].str.split(\".\").str[0]\n",
    "    df = df.set_index(\"epirr_id_without_version\")\n",
    "    df.fillna(\"unknown\", inplace=True)\n",
    "    dfs[v] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown_ls_epirrs = training_df[(training_df[LIFE_STAGE] == \"unknown\") & (training_df[BIOMATERIAL_TYPE] == \"cell line\")].index.unique()\n",
    "# unknown_ls_epirrs = pd.Series(unknown_ls_epirrs)\n",
    "# unknown_ls_epirrs.to_csv(paper_meta_dir / \"training_metadata_unknown_LS_cell_line.list\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating json of differences (VS v1.0/v1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_idxs = defaultdict(set)\n",
    "for cat in relevants_cols:\n",
    "    for version in [\"v1.0\", \"v1.1\"]:\n",
    "        meta = dfs[version]\n",
    "        meta = meta[meta.index.isin(my_epirrs)]\n",
    "\n",
    "        # sort same way\n",
    "        meta = meta.loc[training_df.index]\n",
    "\n",
    "        # find idx where value is different\n",
    "        diff = meta[cat] != training_df[cat]\n",
    "        diff_idxs = diff[diff].index\n",
    "\n",
    "        if not diff_idxs.empty:\n",
    "            problematic_idxs[cat].update(diff_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_changes = {col: {} for col in relevants_cols if col in problematic_idxs}\n",
    "for col in relevants_cols:\n",
    "    cat_idxs = problematic_idxs[col]\n",
    "    for idx in cat_idxs:\n",
    "        values = {\n",
    "            \"training\": training_df.loc[idx, col],\n",
    "            \"v1.0-official\": dfs[\"v1.0\"].loc[idx, col],\n",
    "            \"v1.1-official\": dfs[\"v1.1\"].loc[idx, col],\n",
    "            \"v1.2-official\": dfs[\"v1.2\"].loc[idx, col],\n",
    "            \"v1.3-official\": dfs[\"v1.3\"].loc[idx, col],\n",
    "        }\n",
    "        all_changes[col][idx] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes in harmonized_sample_ontology_intermediate: 29\n",
      "Changes in harmonized_biomaterial_type: 6\n",
      "Changes in harmonized_donor_sex: 0\n",
      "Changes in harmonized_sample_disease_high: 14\n",
      "Changes in harmonized_donor_life_stage: 0\n"
     ]
    }
   ],
   "source": [
    "for col in relevants_cols:\n",
    "    if col in problematic_idxs:\n",
    "        print(f\"Changes in {col}: {len(problematic_idxs[col])}\")\n",
    "    else:\n",
    "        print(f\"No changes in {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"training_metadata_vs_official.json\"\n",
    "path = paper_meta_dir / filename\n",
    "\n",
    "with open(path, \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(all_changes, f, indent=4, allow_nan=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harmonized_sample_ontology_intermediate\n",
      "IHECRE00003725: neural progenitor cell != stem cell derived cell line (v1.0=neural progenitor cell, v1.2=stem cell derived cell line)\n",
      "IHECRE00003726: neural cell != stem cell derived cell line (v1.0=unknown, v1.2=stem cell derived cell line)\n",
      "IHECRE00003728: neural progenitor cell != stem cell derived cell line (v1.0=neural progenitor cell, v1.2=stem cell derived cell line)\n",
      "IHECRE00003729: neural cell != stem cell derived cell line (v1.0=unknown, v1.2=stem cell derived cell line)\n",
      "harmonized_biomaterial_type\n",
      "IHECRE00003724: primary cell != cell line (v1.0=primary cell, v1.2=cell line)\n",
      "IHECRE00003725: primary cell != cell line (v1.0=primary cell, v1.2=cell line)\n",
      "IHECRE00003726: primary cell != cell line (v1.0=primary cell, v1.2=cell line)\n",
      "IHECRE00003727: primary cell != cell line (v1.0=primary cell, v1.2=cell line)\n",
      "IHECRE00003728: primary cell != cell line (v1.0=primary cell, v1.2=cell line)\n",
      "IHECRE00003729: primary cell != cell line (v1.0=primary cell, v1.2=cell line)\n",
      "harmonized_sample_disease_high\n",
      "Unique EpiRRs with changes: 6\n"
     ]
    }
   ],
   "source": [
    "diff_epirrs = set()\n",
    "for cat_label, diff_dict in all_changes.items():\n",
    "    print(cat_label)\n",
    "    for epirr, values_dict in sorted(diff_dict.items()):\n",
    "        training_val = values_dict[\"training\"]\n",
    "        official_val = values_dict[\"v1.1-official\"]\n",
    "        v1_0_val = values_dict[\"v1.0-official\"]\n",
    "        v1_2_val = values_dict[\"v1.2-official\"]\n",
    "        if training_val != official_val:\n",
    "            print(\n",
    "                f\"{epirr}: {training_val} != {official_val} (v1.0={v1_0_val}, v1.2={v1_2_val})\"\n",
    "            )\n",
    "            diff_epirrs.add(epirr)\n",
    "\n",
    "print(f\"Unique EpiRRs with changes: {len(diff_epirrs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: SEX v1.2 = SEX v1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_metadata_dir = (\n",
    "    Path.home() / \"Projects/epiclass/output/paper/data/metadata/official\"\n",
    ")\n",
    "\n",
    "official_metadata_dfs = {}\n",
    "for version in [\"v1.1\", \"v1.2\", \"v1.3\"]:\n",
    "    path = official_metadata_dir / f\"IHEC_metadata_harmonization.{version}.extended.csv\"\n",
    "    df = pd.read_csv(path, sep=\",\")\n",
    "    official_metadata_dfs[version] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEX = \"harmonized_donor_sex\"\n",
    "sex_mislabels_path = (\n",
    "    official_metadata_dir / \"BadQual-mislabels\" / \"official_Sex_mislabeled.csv\"\n",
    ")\n",
    "sex_mislabels_df = pd.read_csv(sex_mislabels_path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_epirrs = {}\n",
    "subset_df = sex_mislabels_df\n",
    "for version, df in official_metadata_dfs.items():\n",
    "    relevant_df = df.loc[:, [\"epirr_id_without_version\", SEX]]\n",
    "    subset_df = relevant_df.merge(\n",
    "        subset_df,\n",
    "        left_on=\"epirr_id_without_version\",\n",
    "        right_on=\"EpiRR_no-v\",\n",
    "        how=\"right\",\n",
    "        suffixes=(f\"_{version}\", \"\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = subset_df.drop(\n",
    "    columns=[col for col in subset_df.columns if col.startswith(\"epirr_id\")]\n",
    ")\n",
    "subset_df = subset_df.drop(columns=[SEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (subset_df[f\"{SEX}_v1.3\"] != subset_df[f\"{SEX}_v1.2\"]).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = official_metadata_dfs[\"v1.2\"].merge(\n",
    "    official_metadata_dfs[\"v1.3\"],\n",
    "    on=\"epirr_id_without_version\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_v1.2\", \"_v1.3\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (merged_df[f\"{SEX}_v1.3\"] != merged_df[f\"{SEX}_v1.2\"]).sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: How much RNA Unique_raw tracks (unstranded data) in the training metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = table_dir / \"experiments_including_unique_raw_files.list\"\n",
    "outfile.unlink(missing_ok=True)\n",
    "outfile.touch()\n",
    "\n",
    "v2_meta_df = files_df\n",
    "md5_unique_raw = v2_meta_df[v2_meta_df[\"track_type\"] == \"Unique_raw\"].index.unique()\n",
    "\n",
    "with outfile.open(\"w\", encoding=\"utf-8\") as out:\n",
    "    print(f\"Total Unique_raw md5sums: {len(md5_unique_raw)}\", file=out)\n",
    "    for pred_file in table_dir.rglob(\"*pred*.csv\"):\n",
    "        if any(label in str(pred_file) for label in [\"recount3\", \"encode\"]):\n",
    "            continue\n",
    "        df = pd.read_csv(pred_file, sep=\",\", low_memory=False)\n",
    "\n",
    "        # Get md5sums\n",
    "        try:\n",
    "            md5sums = set(df[\"md5sum\"])\n",
    "        except KeyError:\n",
    "            if isinstance(df.index[0], str) and len(df.index[0]) == 32:\n",
    "                md5sums = set(df.index)\n",
    "            else:\n",
    "                print(f\"Could not find md5sum column in {pred_file}\", file=out)\n",
    "                continue\n",
    "\n",
    "        shared_md5sums = md5sums.intersection(md5_unique_raw)\n",
    "\n",
    "        pred_file_relpath = pred_file.relative_to(table_dir)\n",
    "        print(f\"{pred_file_relpath}: {len(shared_md5sums)}\", file=out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
