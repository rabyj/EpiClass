{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbook destined to analyze mis-predictions from various cell type metadata groupings.\n",
    "\"\"\"\n",
    "# pylint: disable=import-error, redefined-outer-name, use-dict-literal, too-many-lines, unused-import, unused-argument, too-many-branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import functools\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix as sk_cm\n",
    "\n",
    "from epi_ml.core.confusion_matrix import ConfusionMatrixWriter\n",
    "from epi_ml.utils.classification_merging_utils import merge_dataframes\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import (\n",
    "    ASSAY,\n",
    "    CELL_TYPE,\n",
    "    MetadataHandler,\n",
    "    SplitResultsHandler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "base_data_dir = base_dir / \"data\"\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "if not base_fig_dir.exists():\n",
    "    raise FileNotFoundError(f\"Directory {base_fig_dir} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results_handler = SplitResultsHandler()\n",
    "metadata_handler = MetadataHandler(paper_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = metadata_handler.load_metadata_df(\"v2\", merge_assays=False)\n",
    "file_info.reset_index(drop=False, inplace=True)\n",
    "file_info = file_info[[\"epirr_id_without_version\", \"uuid\", \"md5sum\", \"track_type\", ASSAY]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_metadata_dir = base_data_dir / \"metadata\" / \"official\"\n",
    "\n",
    "metadata_v1_2_path = (\n",
    "    official_metadata_dir / \"IHEC_metadata_harmonization.v1.2.extended.csv\"\n",
    ")\n",
    "metadata_v1_2 = pd.read_csv(metadata_v1_2_path, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metadata = file_info.merge(metadata_v1_2, how=\"left\", on=\"epirr_id_without_version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_100kb = base_data_dir / \"training_results\" / \"dfreeze_v2\" / \"hg38_100kb_all_none\"\n",
    "\n",
    "all_split_dfs = split_results_handler.general_split_metrics(\n",
    "    results_dir=data_dir_100kb,\n",
    "    merge_assays=False,\n",
    "    include_categories=[\"cell_type_PE\", \"cell_type_martin\", CELL_TYPE],\n",
    "    exclude_names=[\"27\", \"16\"],\n",
    "    return_type=\"split_results\",\n",
    "    oversampled_only=True,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_split_dfs_concat: Dict[\n",
    "    str, pd.DataFrame\n",
    "] = split_results_handler.concatenate_split_results(\n",
    "    all_split_dfs, concat_first_level=True  # type: ignore\n",
    ")\n",
    "\n",
    "for name, df in all_split_dfs_concat.items():\n",
    "    split = df.pop(\"split\")\n",
    "    df.insert(0, \"split\", split)\n",
    "    df = split_results_handler.add_max_pred(df)\n",
    "    max_pred = df.pop(\"Max pred\")\n",
    "    df.insert(3, \"Max pred\", max_pred)\n",
    "    all_split_dfs_concat[name] = df\n",
    "    df.rename(columns={\"True class\": \"Expected class\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each category: pivot per predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_cols = [\"EpiRR\", \"Expected class\", \"Predicted class\"]\n",
    "\n",
    "for name, df in all_split_dfs_concat.items():\n",
    "    new_df = df.reset_index(drop=True)\n",
    "    new_df = new_df.merge(file_metadata, how=\"left\", on=\"md5sum\")\n",
    "    new_df.rename(columns={\"Max pred\": \"pred_score\"}, inplace=True)\n",
    "\n",
    "    # files per epirr\n",
    "    epirr_counts = new_df.groupby(\"EpiRR\").size().reset_index(name=\"total_epirr_files\")\n",
    "\n",
    "    # Do your original groupby\n",
    "    groupby = new_df.groupby(groupby_cols).agg(\n",
    "        {\"pred_score\": [\"mean\", \"median\", \"std\", \"count\", \"min\", \"max\"]}, axis=1\n",
    "    )\n",
    "    # Reset index and flatten column names\n",
    "    groupby = groupby.reset_index()\n",
    "    groupby.columns = [\n",
    "        col[0] if col[1] == \"\" else f\"{col[0]},{col[1]}\" for col in groupby.columns\n",
    "    ]\n",
    "    groupby = groupby.merge(epirr_counts, on=\"EpiRR\")\n",
    "\n",
    "    # Calculate the percentage\n",
    "    groupby[\"count_ratio\"] = (\n",
    "        groupby[(\"pred_score,count\")] / groupby[\"total_epirr_files\"] * 100\n",
    "    ).round(2)\n",
    "\n",
    "    groupby = groupby.sort_values([\"EpiRR\", \"count_ratio\"], ascending=[True, False])\n",
    "    groupby_w_metadata = groupby.merge(metadata_v1_2, how=\"left\", on=\"EpiRR\")\n",
    "\n",
    "    groupby_w_metadata.to_csv(\n",
    "        data_dir_100kb / f\"{name}_pivot_predicted_class.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_dfs(pred_dfs: Dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"Merge all different cell type predictions into a single DataFrame.\"\"\"\n",
    "    # Make all different columns have unique relevant names except for the pred vector\n",
    "    same_col_len = 4\n",
    "    new_dfs = {}\n",
    "    for i, (cat, df) in enumerate(pred_dfs.items()):\n",
    "        df = df.copy()\n",
    "\n",
    "        old_names = df.columns[0:same_col_len]\n",
    "        new_names = [f\"{old_name} ({cat})\" for old_name in old_names]\n",
    "        df.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n",
    "\n",
    "        pred_vector_cols = df.columns[same_col_len:-1]\n",
    "        new_names = [f\"{pred_vector}_df{i}\" for pred_vector in pred_vector_cols]\n",
    "        df.rename(columns=dict(zip(pred_vector_cols, new_names)), inplace=True)\n",
    "\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        new_dfs[cat] = df\n",
    "\n",
    "    merge_dataframes_func = functools.partial(merge_dataframes)\n",
    "    full_merged_df = functools.reduce(merge_dataframes_func, new_dfs.values())\n",
    "    md5sum = full_merged_df.pop(\"md5sum\")\n",
    "    full_merged_df.insert(0, \"md5sum\", md5sum)\n",
    "    return full_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merged_df = merge_all_dfs(all_split_dfs_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = full_merged_df.merge(file_metadata, how=\"left\", on=\"md5sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv(\n",
    "#     data_dir_100kb / \"all_custom_cell_type_predictions_augmented.csv\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = (\n",
    "    base_fig_dir\n",
    "    / \"flagship\"\n",
    "    / \"ct_assay_accuracy\"\n",
    "    / \"other_cell_type_groupings\"\n",
    "    / \"confusion_matrices\"\n",
    ")\n",
    "if not logdir.exists():\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name, df in all_split_dfs_concat.items():\n",
    "    y_pred = df[\"Predicted class\"]\n",
    "    y_true = df[\"Expected class\"]\n",
    "    labels = sorted(set(y_true) | set(y_pred))\n",
    "\n",
    "    this_logdir = logdir / name\n",
    "    this_logdir.mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "    for minPredScore in [0, 0.6, 0.8]:\n",
    "        df = df[df[\"Max pred\"] >= minPredScore]\n",
    "        y_pred = df[\"Predicted class\"]\n",
    "        y_true = df[\"Expected class\"]\n",
    "\n",
    "        cm = sk_cm(y_true, y_pred, normalize=None, labels=labels)\n",
    "        cm_writer = ConfusionMatrixWriter(\n",
    "            labels=labels,\n",
    "            confusion_matrix=cm,\n",
    "        )\n",
    "\n",
    "        filename = f\"full-10fold-validation_prediction-confusion-matrix-threshold-{minPredScore:.2f}_{name}\"\n",
    "        cm_writer.to_all_formats(\n",
    "            logdir=this_logdir,\n",
    "            name=filename,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
