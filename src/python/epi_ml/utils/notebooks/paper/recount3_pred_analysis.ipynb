{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbook to analyse classifier predictions on recount3 data.\"\"\"\n",
    "\n",
    "# pylint: disable=duplicate-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display  # pylint: disable=unused-import\n",
    "\n",
    "from epi_ml.utils.notebooks.paper.metrics_per_assay import MetricsPerAssay\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import (\n",
    "    ASSAY,\n",
    "    BIOMATERIAL_TYPE,\n",
    "    CANCER,\n",
    "    LIFE_STAGE,\n",
    "    SEX,\n",
    "    check_label_coherence,\n",
    "    format_labels,\n",
    "    merge_life_stages,\n",
    "    rename_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "\n",
    "table_dir = base_dir / \"tables\"\n",
    "\n",
    "base_data_dir = base_dir / \"data\"\n",
    "metadata_dir = base_data_dir / \"metadata\" / \"recount3\"\n",
    "\n",
    "preds_dir = table_dir / \"dfreeze_v2\" / \"predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preds_path = preds_dir / \"recount3_merged_preds_metadata_freeze1.csv.xz\"\n",
    "\n",
    "full_df = pd.read_csv(\n",
    "    full_preds_path,\n",
    "    sep=\",\",\n",
    "    low_memory=False,\n",
    "    compression=\"xz\",\n",
    ")\n",
    "full_df.fillna(\"unknown\", inplace=True)\n",
    "full_df.replace(\"indeterminate\", \"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line_vals = [\"cell_line\", \"cell line\", \"unknown\", \"other\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat labels/columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-relevant columns\n",
    "to_drop = [\n",
    "    col\n",
    "    for col in full_df.columns\n",
    "    if any(l in col for l in [\"extracted_term\", \"combined_\"])\n",
    "]\n",
    "full_df.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "categories = [\"assay\", \"sex\", \"cancer\", \"lifestage\", \"biomat\"]\n",
    "proper_categories = [ASSAY, SEX, CANCER, LIFE_STAGE, BIOMATERIAL_TYPE]\n",
    "cat_remapping = dict(zip(categories, proper_categories))\n",
    "\n",
    "to_rename = {\n",
    "    f\"expected_{name}\": f\"Expected class ({cat_remapping[name]})\" for name in categories\n",
    "}\n",
    "full_df = rename_columns(full_df, to_rename, exact_match=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = proper_categories\n",
    "\n",
    "column_templates = {\n",
    "    \"True\": \"Expected class ({})\",\n",
    "    \"Predicted\": \"Predicted class ({})\",\n",
    "}\n",
    "\n",
    "all_columns = []\n",
    "for cat in all_categories:\n",
    "    all_columns.append(column_templates[\"True\"].format(cat))\n",
    "    all_columns.append(column_templates[\"Predicted\"].format(cat))\n",
    "\n",
    "full_df = format_labels(full_df, all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-modification check\n",
    "all_categories.remove(ASSAY)\n",
    "check_label_coherence(full_df, all_categories, column_templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assay predictions details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_col_label = column_templates[\"True\"].format(ASSAY)\n",
    "pred_col_label = column_templates[\"Predicted\"].format(ASSAY)\n",
    "max_pred_label = f\"Max pred ({ASSAY})\"\n",
    "\n",
    "orderby_cols = [true_col_label, pred_col_label]\n",
    "\n",
    "mask = full_df[true_col_label].isin([\"unknown\"])\n",
    "assay_df = full_df[~mask].copy()\n",
    "\n",
    "N = assay_df.shape[0]\n",
    "\n",
    "for max_pred in [0, 0.6, 0.8]:\n",
    "    # continue\n",
    "    subset = assay_df[assay_df[max_pred_label] >= max_pred]\n",
    "    counts = subset[pred_col_label].value_counts(dropna=False)\n",
    "\n",
    "    N_subset = counts.sum()\n",
    "    counts_perc = counts / N_subset\n",
    "    correct_perc = counts_perc[\"rna_seq\"] + counts_perc[\"mrna_seq\"]\n",
    "    print(f\"min_PredScore >= {max_pred} ({N_subset/N:.2%} left): {correct_perc:.2%}\\n\")\n",
    "\n",
    "    print(\"Predictions grouped, assay types left as is\")\n",
    "    groupby = (\n",
    "        subset.groupby(orderby_cols)\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"Count\"})\n",
    "        .sort_values(by=[true_col_label, \"Count\"], ascending=[True, False])\n",
    "    )\n",
    "    print(groupby, \"\\n\")\n",
    "\n",
    "    print(\"Predictions grouped, all rna types = rna\")\n",
    "    tmp_df = subset.copy()\n",
    "    tmp_df.loc[:, true_col_label] = \"rna_seq\"\n",
    "    tmp_df.loc[:, pred_col_label].replace(\"mrna_seq\", \"rna_seq\", inplace=True)\n",
    "    groupby = (\n",
    "        tmp_df.groupby(orderby_cols)\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"Count\"})\n",
    "        .sort_values(by=[true_col_label, \"Count\"], ascending=[True, False])\n",
    "    )\n",
    "    print(groupby, \"\\n\")\n",
    "\n",
    "    print(\"Breakdown by assay type\")\n",
    "    assay_breakdown = subset[true_col_label].value_counts(dropna=False)\n",
    "    print(assay_breakdown / assay_breakdown.sum(), \"\\n\")\n",
    "    for assay_type in assay_breakdown.index:\n",
    "        assay_type_subset = subset[subset[true_col_label] == assay_type].copy()\n",
    "\n",
    "        counts = assay_type_subset[pred_col_label].value_counts()\n",
    "        N_subset = counts.sum()\n",
    "        counts_perc = counts / N_subset\n",
    "        correct_perc = counts_perc[\"rna_seq\"] + counts_perc[\"mrna_seq\"]\n",
    "        print(f\"{assay_type} acc: {correct_perc:.2%}\\n\")\n",
    "        print(f\"{assay_type} preds:\\n{counts_perc}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and F1-score summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_df.copy(deep=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_handler = MetricsPerAssay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = table_dir / \"dfreeze_v2\" / \"predictions\" / \"metrics\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [CANCER, SEX, BIOMATERIAL_TYPE]\n",
    "\n",
    "column_templates[\"Max pred\"] = \"Max pred ({})\"\n",
    "\n",
    "# ASSAY needs to exist in full_df\n",
    "full_df[ASSAY] = full_df[true_col_label]\n",
    "\n",
    "compute_fct_kwargs = {\n",
    "    \"no_epiatlas\": False,\n",
    "    \"merge_assays\": False,\n",
    "    \"categories\": categories,\n",
    "    \"column_templates\": column_templates,\n",
    "    \"core_assays\": df[true_col_label].unique().tolist(),\n",
    "    \"non_core_assays\": [],  # no \"non-core\" assays\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"recount3_metrics_per_assay\"\n",
    "\n",
    "metrics_handler.compute_multiple_metric_formats(\n",
    "    preds=full_df.copy(),\n",
    "    folders_to_save=[output_dir],\n",
    "    general_filename=base_filename,\n",
    "    verbose=False,\n",
    "    return_df=False,\n",
    "    compute_fct_kwargs=compute_fct_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only files where Assay predictions are (m)rna-seq and predScore >= 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"recount3_metrics_per_assay_assay11c-filtered\"\n",
    "\n",
    "print(full_df.shape)\n",
    "filtered_df = full_df[\n",
    "    (full_df[max_pred_label] >= 0.6)\n",
    "    & (full_df[pred_col_label].isin([\"rna_seq\", \"mrna_seq\"]))\n",
    "].copy()\n",
    "print(filtered_df.shape)\n",
    "\n",
    "metrics_handler.compute_multiple_metric_formats(\n",
    "    preds=filtered_df.copy(),  # type: ignore\n",
    "    folders_to_save=[output_dir],\n",
    "    general_filename=base_filename,\n",
    "    verbose=False,\n",
    "    return_df=False,\n",
    "    compute_fct_kwargs=compute_fct_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No cell line (for life stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compute_fct_kwargs = compute_fct_kwargs.copy()\n",
    "new_compute_fct_kwargs[\"categories\"] = [f\"{LIFE_STAGE}_merged\"]\n",
    "\n",
    "biomat_col = column_templates[\"True\"].format(BIOMATERIAL_TYPE)\n",
    "\n",
    "for df, filename in zip(\n",
    "    [filtered_df.copy(), full_df.copy()],\n",
    "    [\n",
    "        \"recount3_metrics_per_assay_assay11c-filtered_no_cell_line\",\n",
    "        \"recount3_metrics_per_assay_no_cell_line\",\n",
    "    ],\n",
    "):\n",
    "    print(filename)\n",
    "    df = df[~df[biomat_col].isin(cell_line_vals)]\n",
    "    print(df.shape)\n",
    "\n",
    "    df = merge_life_stages(\n",
    "        df=df,\n",
    "        lifestage_column_name=LIFE_STAGE,\n",
    "        column_name_templates=list(column_templates.values()),\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    metrics_handler.compute_multiple_metric_formats(\n",
    "        preds=df,  # type: ignore\n",
    "        folders_to_save=[output_dir],\n",
    "        general_filename=filename,\n",
    "        verbose=False,\n",
    "        return_df=False,\n",
    "        compute_fct_kwargs=new_compute_fct_kwargs,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass_py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
