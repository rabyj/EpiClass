{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbook to analyse classifier predictions on recount3 data.\"\"\"\n",
    "\n",
    "# pylint: disable=duplicate-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display  # pylint: disable=unused-import\n",
    "from sklearn.metrics import classification_report, confusion_matrix as sk_cm\n",
    "\n",
    "from epi_ml.utils.notebooks.paper.metrics_per_assay import MetricsPerAssay\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import (\n",
    "    ASSAY,\n",
    "    BIOMATERIAL_TYPE,\n",
    "    CANCER,\n",
    "    LIFE_STAGE,\n",
    "    SEX,\n",
    "    merge_life_stages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "\n",
    "table_dir = base_dir / \"tables\"\n",
    "\n",
    "base_data_dir = base_dir / \"data\"\n",
    "metadata_dir = base_data_dir / \"metadata\" / \"recount3\"\n",
    "\n",
    "predictions_dir = table_dir / \"dfreeze_v2\" / \"predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_name = \"harmonized_metadata_20250122_leuk2\"\n",
    "preds_path = predictions_dir / f\"recount3_merged_preds_{meta_name}.tsv.gz\"\n",
    "\n",
    "full_df = pd.read_csv(preds_path, sep=\"\\t\", compression=\"gzip\")\n",
    "print(full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line_vals = [\"cell_line\", \"cell line\", \"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check life stage filtering\n",
    "\n",
    "# print(full_df[BIOMATERIAL_TYPE].value_counts(dropna=False))\n",
    "\n",
    "# assay_pred_col = \"Predicted class (assay_epiclass)\"\n",
    "# assay_max_pred_col = \"Max pred (assay_epiclass)\"\n",
    "\n",
    "# cond1 = full_df[assay_pred_col].isin([\"rna_seq\", \"mrna_seq\"])\n",
    "# cond2 = full_df[assay_max_pred_col] > 0.6\n",
    "# df = full_df[cond1 & cond2]\n",
    "# print(\"After 11c filtering (m/rna > 0.6)\")\n",
    "# print(df.shape)\n",
    "# print(df[LIFE_STAGE].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "# cond3 = df[LIFE_STAGE] != \"unknown\"\n",
    "# df = df[cond3]\n",
    "# print(df.shape)\n",
    "# print(\"After unknown filtering\")\n",
    "# print(df[LIFE_STAGE].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "# cond4 = ~(df[BIOMATERIAL_TYPE].isin(cell_line_vals))\n",
    "# df = df[cond4]\n",
    "# print(\"After cell line filtering\")\n",
    "# print(df.shape)\n",
    "# print(df[LIFE_STAGE].value_counts(dropna=False), \"\\n\")\n",
    "# print(df[BIOMATERIAL_TYPE].value_counts(dropna=False), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assay predictions details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_df = full_df[full_df[ASSAY] != \"unknown\"]\n",
    "N = assay_df.shape[0]\n",
    "\n",
    "for max_pred in [0, 0.6, 0.8]:\n",
    "    # continue\n",
    "    subset = assay_df[assay_df[f\"Max pred ({ASSAY})\"] >= max_pred]\n",
    "    counts = subset[f\"Predicted class ({ASSAY})\"].value_counts()\n",
    "\n",
    "    N_subset = counts.sum()\n",
    "    counts_perc = counts / N_subset\n",
    "    correct_perc = counts_perc[\"rna_seq\"] + counts_perc[\"mrna_seq\"]\n",
    "    print(f\"min_PredScore >= {max_pred} ({N_subset/N:.2%} left): {correct_perc:.2%}\\n\")\n",
    "\n",
    "    print(\"Predictions grouped, assay types left as is\")\n",
    "    groupby = (\n",
    "        subset.groupby([ASSAY, f\"Predicted class ({ASSAY})\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"Count\"})\n",
    "        .sort_values(by=[ASSAY, \"Count\"], ascending=[True, False])\n",
    "    )\n",
    "    print(groupby, \"\\n\")\n",
    "\n",
    "    print(\"Predictions grouped, all rna types = rna\")\n",
    "    tmp_df = subset.copy()\n",
    "    tmp_df.loc[:, ASSAY] = \"rna_seq\"\n",
    "    tmp_df.loc[:, f\"Predicted class ({ASSAY})\"].replace(\n",
    "        \"mrna_seq\", \"rna_seq\", inplace=True\n",
    "    )\n",
    "    groupby = (\n",
    "        tmp_df.groupby([ASSAY, f\"Predicted class ({ASSAY})\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"Count\"})\n",
    "        .sort_values(by=[ASSAY, \"Count\"], ascending=[True, False])\n",
    "    )\n",
    "    print(groupby, \"\\n\")\n",
    "\n",
    "    print(\"Breakdown by assay type\")\n",
    "    assay_breakdown = subset[ASSAY].value_counts(dropna=False)\n",
    "    print(assay_breakdown / assay_breakdown.sum(), \"\\n\")\n",
    "    for assay_type in assay_breakdown.index:\n",
    "        assay_type_subset = subset[subset[ASSAY] == assay_type].copy()\n",
    "\n",
    "        counts = assay_type_subset[f\"Predicted class ({ASSAY})\"].value_counts()\n",
    "        N_subset = counts.sum()\n",
    "        counts_perc = counts / N_subset\n",
    "        correct_perc = counts_perc[\"rna_seq\"] + counts_perc[\"mrna_seq\"]\n",
    "        print(f\"{assay_type} acc: {correct_perc:.2%}\\n\")\n",
    "        print(f\"{assay_type} preds:\\n{counts_perc}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other metadata categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in [SEX, CANCER, LIFE_STAGE, BIOMATERIAL_TYPE]:\n",
    "    print(full_df[cat].value_counts(dropna=False), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_df.copy(deep=True)\n",
    "\n",
    "for max_pred in [0, 0.6, 0.8]:\n",
    "    # for max_pred in [0]:\n",
    "    # continue\n",
    "    subset = df[df[f\"Max pred ({ASSAY})\"] >= max_pred]\n",
    "    print(f\"min_PredScore >= {max_pred}\\n\")\n",
    "\n",
    "    for cat in [SEX, CANCER, LIFE_STAGE, BIOMATERIAL_TYPE]:\n",
    "        pred_label = f\"Predicted class ({cat})\"\n",
    "        true_label = f\"Expected class ({cat})\"\n",
    "\n",
    "        if cat == CANCER:\n",
    "            subset = subset.replace(\"healthy\", \"non-cancer\")\n",
    "\n",
    "        known_pred = subset[~subset[true_label].isin([\"unknown\", \"other\"])]\n",
    "        if cat == LIFE_STAGE:\n",
    "            diff = len(known_pred)\n",
    "            known_pred = known_pred[known_pred[BIOMATERIAL_TYPE] != \"cell line\"]\n",
    "            diff -= len(known_pred)\n",
    "            print(f\"Excluded cell lines for {cat} predictions: {diff}\")\n",
    "\n",
    "        # print(known_pred[true_label].value_counts(dropna=False))\n",
    "        y_pred = known_pred[pred_label].str.lower().str.replace(\" \", \"_\")\n",
    "        y_true = known_pred[true_label].str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "        classes = sorted(set(y_pred.unique()) | set(y_true.unique()))\n",
    "\n",
    "        N_known = known_pred.shape[0]\n",
    "        N_unknown = subset.shape[0] - N_known\n",
    "        # print(f\"Unknown (%): {(N_unknown)/subset.shape[0]*100:.2f}\")\n",
    "\n",
    "        N_correct = (y_pred == y_true).sum()\n",
    "        print(f\"{cat} prediction match (%): {N_correct/N_known*100:.2f}\\n\")\n",
    "        print(classes)\n",
    "        print(y_pred.value_counts(dropna=False), \"\\n\")\n",
    "        print(y_true.value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "        print(classification_report(y_true, y_pred, target_names=classes, zero_division=0) + \"\\n\")  # type: ignore\n",
    "\n",
    "        print(f\"confusion matrix classes row order: {classes}\")\n",
    "        cm = sk_cm(y_true, y_pred, normalize=\"true\", labels=classes)\n",
    "        with np.printoptions(precision=3):\n",
    "            print(str(cm) + \"\\n\\n\")\n",
    "\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and F1-score summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_handler = MetricsPerAssay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = table_dir / \"dfreeze_v2\" / \"predictions\" / \"metrics\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [CANCER, SEX, BIOMATERIAL_TYPE]\n",
    "column_templates = {\n",
    "    \"True\": \"Expected class ({})\",\n",
    "    \"Predicted\": \"Predicted class ({})\",\n",
    "    \"Max pred\": \"Max pred ({})\",\n",
    "}\n",
    "compute_fct_kwargs = {\n",
    "    \"no_epiatlas\": False,\n",
    "    \"merge_assays\": False,\n",
    "    \"categories\": categories,\n",
    "    \"column_templates\": column_templates,\n",
    "    \"core_assays\": df[ASSAY].unique().tolist(),\n",
    "    \"non_core_assays\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"recount3_metrics_per_assay\"\n",
    "\n",
    "metrics_handler.compute_multiple_metric_formats(\n",
    "    preds=df,\n",
    "    folders_to_save=[output_dir],\n",
    "    general_filename=base_filename,\n",
    "    verbose=False,\n",
    "    return_df=False,\n",
    "    compute_fct_kwargs=compute_fct_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only files where Assay predictions are (m)rna-seq and predScore >= 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"recount3_metrics_per_assay_assay11c-filtered\"\n",
    "\n",
    "filtered_df = df[\n",
    "    (df[f\"Max pred ({ASSAY})\"] >= 0.6)\n",
    "    & (df[f\"Predicted class ({ASSAY})\"].isin([\"rna_seq\", \"mrna_seq\"]))\n",
    "]\n",
    "\n",
    "metrics_handler.compute_multiple_metric_formats(\n",
    "    preds=filtered_df,  # type: ignore\n",
    "    folders_to_save=[output_dir],\n",
    "    general_filename=base_filename,\n",
    "    verbose=False,\n",
    "    return_df=False,\n",
    "    compute_fct_kwargs=compute_fct_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging messenger and total RNA for a new assay_epiclass label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, filename in zip(\n",
    "    [filtered_df.copy(), full_df.copy()],\n",
    "    [\n",
    "        \"recount3_metrics_per_assay_merge_total_mrna_assay11c-filtered\",\n",
    "        \"recount3_metrics_per_assay_merge_total_mrna\",\n",
    "    ],\n",
    "):\n",
    "    df[ASSAY].replace(\n",
    "        {\n",
    "            \"mrna_seq\": \"messenger_or_total_rna\",\n",
    "            \"rna_seq\": \"messenger_or_total_rna\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    compute_fct_kwargs.update(\n",
    "        {\n",
    "            \"core_assays\": df[ASSAY].unique().tolist(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    metrics_handler.compute_multiple_metric_formats(\n",
    "        preds=tmp_df,  # type: ignore\n",
    "        folders_to_save=[output_dir],\n",
    "        general_filename=filename,\n",
    "        verbose=False,\n",
    "        return_df=False,\n",
    "        compute_fct_kwargs=compute_fct_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No cell line (for life stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_fct_kwargs.update(\n",
    "    {\n",
    "        \"categories\": [LIFE_STAGE, f\"{LIFE_STAGE}_merged\"],\n",
    "    }\n",
    ")\n",
    "# Gotta exclude 'unknown' biomaterial type since it could be cell lines\n",
    "no_cell_line_df = filtered_df[\n",
    "    ~filtered_df[BIOMATERIAL_TYPE].isin([\"cell line\", \"unknown\"])\n",
    "].copy()\n",
    "print(no_cell_line_df[BIOMATERIAL_TYPE].value_counts(dropna=False), \"\\n\")\n",
    "print(no_cell_line_df[LIFE_STAGE].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cell_line_df = merge_life_stages(\n",
    "    no_cell_line_df, column_name_templates=list(column_templates.values()) + [\"{}\"]\n",
    ")\n",
    "print(no_cell_line_df[f\"{LIFE_STAGE}_merged\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"recount3_metrics_per_assay_assay11c-filtered_no_cell_line\"\n",
    "\n",
    "metrics_handler.compute_multiple_metric_formats(\n",
    "    preds=no_cell_line_df,  # type: ignore\n",
    "    folders_to_save=[output_dir],\n",
    "    general_filename=base_filename,\n",
    "    verbose=False,\n",
    "    return_df=False,\n",
    "    compute_fct_kwargs=compute_fct_kwargs,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
