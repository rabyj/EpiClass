{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbook to analyse classifier predictions on recount3 data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import classification_report, confusion_matrix as sk_cm\n",
    "\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import ASSAY, LIFE_STAGE, SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISEASE = \"harmonized_sample_disease_high\"\n",
    "CANCER = \"harmonized_sample_cancer_high\"\n",
    "BIOMAT = \"harmonized_biomaterial_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "\n",
    "table_dir = base_dir / \"tables\"\n",
    "\n",
    "base_data_dir = base_dir / \"data\"\n",
    "metadata_dir = base_data_dir / \"metadata\"\n",
    "predictions_dir = base_data_dir / \"training_results\" / \"predictions\"\n",
    "\n",
    "recount3_folder = predictions_dir / \"recount3\" / \"hg38_100kb_all_none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_name = \"harmonized_metadata_20250122_leuk2\"\n",
    "preds_path = recount3_folder / f\"recount3_merged_preds_{meta_name}.tsv.gz\"\n",
    "full_df = pd.read_csv(preds_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assay predictions details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_df = full_df[full_df[ASSAY] != \"unknown\"]\n",
    "N = assay_df.shape[0]\n",
    "\n",
    "for max_pred in [0, 0.6, 0.8]:\n",
    "    subset = assay_df[assay_df[f\"Max pred ({ASSAY})\"] >= max_pred]\n",
    "    counts = subset[f\"Predicted class ({ASSAY})\"].value_counts()\n",
    "\n",
    "    N_subset = counts.sum()\n",
    "    counts_perc = counts / N_subset\n",
    "    correct_perc = counts_perc[\"rna_seq\"] + counts_perc[\"mrna_seq\"]\n",
    "    print(f\"min_PredScore >= {max_pred} ({N_subset/N:.2%} left): {correct_perc:.2%}\\n\")\n",
    "\n",
    "    print(\"Predictions grouped, assay types left as is\")\n",
    "    groupby = (\n",
    "        subset.groupby([ASSAY, f\"Predicted class ({ASSAY})\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"Count\"})\n",
    "        .sort_values(by=[ASSAY, \"Count\"], ascending=[True, False])\n",
    "    )\n",
    "    print(groupby, \"\\n\")\n",
    "\n",
    "    print(\"Predictions grouped, all rna types = rna\")\n",
    "    tmp_df = subset.copy()\n",
    "    tmp_df.loc[:, ASSAY] = \"rna_seq\"\n",
    "    tmp_df.loc[:, f\"Predicted class ({ASSAY})\"].replace(\n",
    "        \"mrna_seq\", \"rna_seq\", inplace=True\n",
    "    )\n",
    "    groupby = (\n",
    "        tmp_df.groupby([ASSAY, f\"Predicted class ({ASSAY})\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"Count\"})\n",
    "        .sort_values(by=[ASSAY, \"Count\"], ascending=[True, False])\n",
    "    )\n",
    "    print(groupby, \"\\n\")\n",
    "\n",
    "    print(\"Breakdown by assay type\")\n",
    "    assay_breakdown = subset[ASSAY].value_counts(dropna=False)\n",
    "    print(assay_breakdown / assay_breakdown.sum(), \"\\n\")\n",
    "    for assay_type in assay_breakdown.index:\n",
    "        assay_type_subset = subset[subset[ASSAY] == assay_type].copy()\n",
    "\n",
    "        counts = assay_type_subset[f\"Predicted class ({ASSAY})\"].value_counts()\n",
    "        N_subset = counts.sum()\n",
    "        counts_perc = counts / N_subset\n",
    "        correct_perc = counts_perc[\"rna_seq\"] + counts_perc[\"mrna_seq\"]\n",
    "        print(f\"{assay_type} acc: {correct_perc:.2%}\\n\")\n",
    "        print(f\"{assay_type} preds:\\n{counts_perc}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other metadata categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in [SEX, CANCER, LIFE_STAGE, BIOMAT]:\n",
    "    display(full_df[cat].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_df.copy(deep=True)\n",
    "for max_pred in [0, 0.6, 0.8]:\n",
    "    subset = df[df[f\"Max pred ({ASSAY})\"] >= max_pred]\n",
    "    print(f\"min_PredScore >= {max_pred}\\n\")\n",
    "\n",
    "    for cat in [SEX, CANCER, LIFE_STAGE, BIOMAT]:\n",
    "        pred_label = f\"Predicted class ({cat})\"\n",
    "        true_label = f\"Expected class ({cat})\"\n",
    "\n",
    "        if cat == CANCER:\n",
    "            subset = subset.replace(\"healthy\", \"non-cancer\")\n",
    "\n",
    "        known_pred = subset[~subset[true_label].isin([\"unknown\", \"other\"])]\n",
    "        if cat == LIFE_STAGE:\n",
    "            diff = len(known_pred)\n",
    "            known_pred = known_pred[known_pred[BIOMAT] != \"cell line\"]\n",
    "            diff -= len(known_pred)\n",
    "            print(f\"Excluded cell lines for {cat} predictions: {diff}\")\n",
    "\n",
    "        # print(known_pred[true_label].value_counts(dropna=False))\n",
    "\n",
    "        classes = sorted(\n",
    "            set(known_pred[pred_label].unique()) | set(known_pred[pred_label].unique())\n",
    "        )\n",
    "\n",
    "        N_known = known_pred.shape[0]\n",
    "        N_unknown = subset.shape[0] - N_known\n",
    "        # print(f\"Unknown (%): {(N_unknown)/subset.shape[0]*100:.2f}\")\n",
    "\n",
    "        y_pred = known_pred[pred_label]\n",
    "        y_true = known_pred[true_label]\n",
    "        N_correct = (y_pred == y_true).sum()\n",
    "        print(f\"{cat} prediction match (%): {N_correct/N_known*100:.2f}\\n\")\n",
    "        print(classes)\n",
    "        print(y_pred.value_counts(dropna=False), \"\\n\")\n",
    "        print(y_true.value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "        print(classification_report(y_true, y_pred, target_names=classes, zero_division=0) + \"\\n\")  # type: ignore\n",
    "\n",
    "        print(f\"confusion matrix classes row order: {classes}\")\n",
    "        cm = sk_cm(y_true, y_pred, normalize=\"true\", labels=classes)\n",
    "        with np.printoptions(precision=3):\n",
    "            print(str(cm) + \"\\n\\n\")\n",
    "\n",
    "    print(\"-----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
