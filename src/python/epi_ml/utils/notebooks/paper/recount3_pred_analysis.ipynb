{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbook to analyse classifier predictions on recount3 data.\"\"\"\n",
    "\n",
    "# pylint: disable=duplicate-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display  # pylint: disable=unused-import\n",
    "\n",
    "from epi_ml.utils.notebooks.paper.metrics_per_assay import MetricsPerAssay\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import (\n",
    "    ASSAY,\n",
    "    BIOMATERIAL_TYPE,\n",
    "    CANCER,\n",
    "    LIFE_STAGE,\n",
    "    SEX,\n",
    "    check_label_coherence,\n",
    "    merge_life_stages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "\n",
    "table_dir = base_dir / \"tables\"\n",
    "\n",
    "base_data_dir = base_dir / \"data\"\n",
    "metadata_dir = base_data_dir / \"metadata\" / \"recount3\"\n",
    "\n",
    "preds_dir = table_dir / \"dfreeze_v2\" / \"predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preds_path = preds_dir / \"recount3_merged_preds_metadata_freeze1.csv.gz\"\n",
    "\n",
    "full_df = pd.read_csv(\n",
    "    full_preds_path,\n",
    "    sep=\",\",\n",
    "    low_memory=False,\n",
    "    compression=\"gzip\",\n",
    ")\n",
    "full_df.fillna(\"unknown\", inplace=True)\n",
    "full_df.replace(\"indeterminate\", \"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformize biomat labels\n",
    "col = f\"Predicted class ({BIOMATERIAL_TYPE})\"\n",
    "full_df[col] = full_df[col].str.replace(\" \", \"_\").str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that expected/predicted labels are coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = [SEX, BIOMATERIAL_TYPE, CANCER, LIFE_STAGE]\n",
    "column_templates = {\n",
    "    \"True\": \"{}\",\n",
    "    \"Predicted\": \"Predicted class ({})\",\n",
    "}\n",
    "check_label_coherence(full_df, all_categories, column_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line_vals = [\"cell_line\", \"cell line\", \"unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assay predictions details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assay_df = full_df[\n",
    "    ~full_df[ASSAY].isin(\n",
    "        [\n",
    "            \"unknown\",\n",
    "        ]\n",
    "    )\n",
    "].copy()\n",
    "N = assay_df.shape[0]\n",
    "\n",
    "for max_pred in [0, 0.6, 0.8]:\n",
    "    # continue\n",
    "    subset = assay_df[assay_df[f\"Max pred ({ASSAY})\"] >= max_pred]\n",
    "    counts = subset[f\"Predicted class ({ASSAY})\"].value_counts()\n",
    "\n",
    "    N_subset = counts.sum()\n",
    "    counts_perc = counts / N_subset\n",
    "    correct_perc = counts_perc[\"rna_seq\"] + counts_perc[\"mrna_seq\"]\n",
    "    print(f\"min_PredScore >= {max_pred} ({N_subset/N:.2%} left): {correct_perc:.2%}\\n\")\n",
    "\n",
    "    print(\"Predictions grouped, assay types left as is\")\n",
    "    groupby = (\n",
    "        subset.groupby([ASSAY, f\"Predicted class ({ASSAY})\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"Count\"})\n",
    "        .sort_values(by=[ASSAY, \"Count\"], ascending=[True, False])\n",
    "    )\n",
    "    print(groupby, \"\\n\")\n",
    "\n",
    "    print(\"Predictions grouped, all rna types = rna\")\n",
    "    tmp_df = subset.copy()\n",
    "    tmp_df.loc[:, ASSAY] = \"rna_seq\"\n",
    "    tmp_df.loc[:, f\"Predicted class ({ASSAY})\"].replace(\n",
    "        \"mrna_seq\", \"rna_seq\", inplace=True\n",
    "    )\n",
    "    groupby = (\n",
    "        tmp_df.groupby([ASSAY, f\"Predicted class ({ASSAY})\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"Count\"})\n",
    "        .sort_values(by=[ASSAY, \"Count\"], ascending=[True, False])\n",
    "    )\n",
    "    print(groupby, \"\\n\")\n",
    "\n",
    "    print(\"Breakdown by assay type\")\n",
    "    assay_breakdown = subset[ASSAY].value_counts(dropna=False)\n",
    "    print(assay_breakdown / assay_breakdown.sum(), \"\\n\")\n",
    "    for assay_type in assay_breakdown.index:\n",
    "        assay_type_subset = subset[subset[ASSAY] == assay_type].copy()\n",
    "\n",
    "        counts = assay_type_subset[f\"Predicted class ({ASSAY})\"].value_counts()\n",
    "        N_subset = counts.sum()\n",
    "        counts_perc = counts / N_subset\n",
    "        correct_perc = counts_perc[\"rna_seq\"] + counts_perc[\"mrna_seq\"]\n",
    "        print(f\"{assay_type} acc: {correct_perc:.2%}\\n\")\n",
    "        print(f\"{assay_type} preds:\\n{counts_perc}\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and F1-score summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_handler = MetricsPerAssay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = table_dir / \"dfreeze_v2\" / \"predictions\" / \"metrics\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [CANCER, SEX, BIOMATERIAL_TYPE]\n",
    "column_templates = {\n",
    "    \"True\": \"{}\",\n",
    "    \"Predicted\": \"Predicted class ({})\",\n",
    "    \"Max pred\": \"Max pred ({})\",\n",
    "}\n",
    "compute_fct_kwargs = {\n",
    "    \"no_epiatlas\": False,\n",
    "    \"merge_assays\": False,\n",
    "    \"categories\": categories,\n",
    "    \"column_templates\": column_templates,\n",
    "    \"core_assays\": df[ASSAY].unique().tolist(),\n",
    "    \"non_core_assays\": [],  # no \"non-core\" assays\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"recount3_metrics_per_assay\"\n",
    "\n",
    "metrics_handler.compute_multiple_metric_formats(\n",
    "    preds=full_df.copy(),\n",
    "    folders_to_save=[output_dir],\n",
    "    general_filename=base_filename,\n",
    "    verbose=False,\n",
    "    return_df=False,\n",
    "    compute_fct_kwargs=compute_fct_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only files where Assay predictions are (m)rna-seq and predScore >= 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_filename = \"recount3_metrics_per_assay_assay11c-filtered\"\n",
    "\n",
    "print(full_df.shape)\n",
    "filtered_df = full_df[\n",
    "    (full_df[f\"Max pred ({ASSAY})\"] >= 0.6)\n",
    "    & (full_df[f\"Predicted class ({ASSAY})\"].isin([\"rna_seq\", \"mrna_seq\"]))\n",
    "].copy()\n",
    "print(filtered_df.shape)\n",
    "\n",
    "metrics_handler.compute_multiple_metric_formats(\n",
    "    preds=filtered_df.copy(),  # type: ignore\n",
    "    folders_to_save=[output_dir],\n",
    "    general_filename=base_filename,\n",
    "    verbose=False,\n",
    "    return_df=False,\n",
    "    compute_fct_kwargs=compute_fct_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging messenger and total RNA for a new assay_epiclass label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, filename in zip(\n",
    "    [filtered_df.copy(), full_df.copy()],\n",
    "    [\n",
    "        \"recount3_metrics_per_assay_merge_total_mrna_assay11c-filtered\",\n",
    "        \"recount3_metrics_per_assay_merge_total_mrna\",\n",
    "    ],\n",
    "):\n",
    "    print(filename)\n",
    "    df[ASSAY] = df[ASSAY].replace(\n",
    "        {\n",
    "            \"mrna_seq\": \"messenger_or_total_rna\",\n",
    "            \"rna_seq\": \"messenger_or_total_rna\",\n",
    "        },\n",
    "    )\n",
    "    new_compute_fct_kwargs = compute_fct_kwargs.copy()\n",
    "    new_compute_fct_kwargs[\"core_assays\"] = df[ASSAY].unique().tolist()\n",
    "\n",
    "    metrics_handler.compute_multiple_metric_formats(\n",
    "        preds=df,  # type: ignore\n",
    "        folders_to_save=[output_dir],\n",
    "        general_filename=filename,\n",
    "        verbose=False,\n",
    "        return_df=False,\n",
    "        compute_fct_kwargs=new_compute_fct_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No cell line (for life stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compute_fct_kwargs = compute_fct_kwargs.copy()\n",
    "new_compute_fct_kwargs[\"categories\"] = [f\"{LIFE_STAGE}_merged\"]\n",
    "\n",
    "for df, filename in zip(\n",
    "    [filtered_df.copy(), full_df.copy()],\n",
    "    [\n",
    "        \"recount3_metrics_per_assay_assay11c-filtered_no_cell_line\",\n",
    "        \"recount3_metrics_per_assay_no_cell_line\",\n",
    "    ],\n",
    "):\n",
    "    print(filename)\n",
    "    df = df[~df[BIOMATERIAL_TYPE].isin(cell_line_vals)]\n",
    "\n",
    "    print(df.shape)\n",
    "    for cat in [ASSAY, f\"{LIFE_STAGE}_merged\", BIOMATERIAL_TYPE]:\n",
    "        print(df[cat].value_counts(dropna=False), \"\\n\")\n",
    "\n",
    "    # Making a version of predicted class + max pred that have correct names + merged\n",
    "    df = merge_life_stages(\n",
    "        df=df,\n",
    "        lifestage_column_name=LIFE_STAGE,\n",
    "        column_name_templates=[\"Max pred ({})\", \"Predicted class ({})\"],\n",
    "    )\n",
    "\n",
    "    metrics_handler.compute_multiple_metric_formats(\n",
    "        preds=df,  # type: ignore\n",
    "        folders_to_save=[output_dir],\n",
    "        general_filename=filename,\n",
    "        verbose=False,\n",
    "        return_df=False,\n",
    "        compute_fct_kwargs=new_compute_fct_kwargs,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
