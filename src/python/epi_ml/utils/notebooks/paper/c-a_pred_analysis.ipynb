{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbook to analyse Chip-Atlas predictions, destined for the paper.\n",
    "\"\"\"\n",
    "# pylint: disable=import-error, redefined-outer-name, use-dict-literal, too-many-lines, unused-import, unused-argument, too-many-branches, pointless-statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Set, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import (\n",
    "    ASSAY,\n",
    "    ASSAY_MERGE_DICT,\n",
    "    ASSAY_ORDER,\n",
    "    CELL_TYPE,\n",
    "    LIFE_STAGE,\n",
    "    SEX,\n",
    "    IHECColorMap,\n",
    "    merge_similar_assays,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAY_ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "base_data_dir = base_dir / \"data\"\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "if not base_fig_dir.exists():\n",
    "    raise FileNotFoundError(f\"Directory {base_fig_dir} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_pred_path = (\n",
    "    base_data_dir / \"training_results\" / \"C-A\" / \"CA_metadata_4DB+all_pred_rabyj.tsv\"\n",
    ")\n",
    "ca_pred_df = pd.read_csv(ca_pred_path, sep=\"\\t\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Assay | Exp Key                               | Nb Files | Training Size | Oversampling | Expected Nb Files                      |\n",
    "|-------|---------------------------------------|----------|---------------|--------------|---------------------------------------|\n",
    "| 13c   | dd3710b73c0341af85a17ce1998362d0      | 24989    | 116550        | true         | 24989                                 |\n",
    "| 11c   | 0f8e5eb996114868a17057bebe64f87c      | 20922    | 46128         | true         | 20922                                 |\n",
    "| 7c    | 69488630801b4a05a53b5d9e572f0aaa      | 16788    | 34413         | true         | 16788 (contre-vérifié)                |\n",
    "\n",
    "*using hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_pred_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input filename list (for umap)\n",
    "# input_ids = ca_pred_df[ca_pred_df[\"manual_target_consensus\"] == \"input\"][\"Experimental-id\"]\n",
    "# input_ids[\"filename\"] = input_ids + \"_100kb_all_none.hdf5\"\n",
    "# input_ids[\"filename\"].to_csv(base_data_dir / \"training_results\" / \"C-A\" / \"C-A_100kb_all_none_input.list\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_assays = ASSAY_ORDER[0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIX ca_pred_df[\"Max_pred_assay_11c\"] commas!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ca_pred_df.shape)\n",
    "min_pred = 0.8\n",
    "ca_pred_df = ca_pred_df[\n",
    "    (ca_pred_df[\"Max_pred_assay_13c\"].astype(float) > min_pred)\n",
    "    | (ca_pred_df[\"Max_pred_assay_7c\"].astype(float) > min_pred)\n",
    "]\n",
    "print(ca_pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for assay in core_assays:\n",
    "    print(f\"{assay}\")\n",
    "    assay_df = ca_pred_df[ca_pred_df[\"manual_target_consensus\"] == assay]\n",
    "    for col in [\n",
    "        \"Predicted_class_assay_7c\",\n",
    "        \"Predicted_class_assay_11c\",\n",
    "        \"Predicted_class_assay_13c\",\n",
    "    ]:\n",
    "        display(assay_df[col].value_counts() / len(assay_df) * 100)\n",
    "        if col == \"Predicted_class_assay_13c\":\n",
    "            wrong_pred = assay_df[assay_df[col] != assay]\n",
    "            display(\n",
    "                wrong_pred[\"2nd_pred_class_assay_13c\"].value_counts()\n",
    "                / len(wrong_pred)\n",
    "                * 100\n",
    "            )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgbs_dist = ca_pred_df[ca_pred_df[\"Predicted_class_assay_13c\"] == \"wgbs-standard\"][\n",
    "    \"manual_target_consensus\"\n",
    "]\n",
    "display(wgbs_dist.value_counts())\n",
    "display(wgbs_dist.value_counts() / len(wgbs_dist) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What is the actual target when wgbs-standard is predicted?\")\n",
    "for col in [\"Predicted_class_assay_11c\", \"Predicted_class_assay_13c\"]:\n",
    "    print(col)\n",
    "    wgbs_dist = ca_pred_df[ca_pred_df[col] == \"wgbs-standard\"][\"manual_target_consensus\"]\n",
    "    display(wgbs_dist.value_counts())\n",
    "    display(wgbs_dist.value_counts() / len(wgbs_dist) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"What is the actual target when non-core is predicted?\")\n",
    "col = \"Predicted_class_assay_13c\"\n",
    "wgbs_dist = ca_pred_df[ca_pred_df[col] == \"non-core\"][\"manual_target_consensus\"]\n",
    "display(wgbs_dist.value_counts())\n",
    "display(wgbs_dist.value_counts() / len(wgbs_dist) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
