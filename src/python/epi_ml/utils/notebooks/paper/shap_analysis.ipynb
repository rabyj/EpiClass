{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Code related to SHAP analyses for flagship paper + supplementary figures.\"\"\"\n",
    "# pylint: disable=line-too-long, redefined-outer-name, import-error, duplicate-code, unreachable, unused-argument, use-dict-literal, unused-import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How relevant files were downloaded\n",
    "\n",
    "~~~bash\n",
    "base_path=\"/home/rabyj/scratch/epilap-logs/epiatlas-dfreeze-v2.1/hg38_100kb_all_none/harmonized_sample_ontology_intermediate_1l_3000n/10fold-oversampling\"\n",
    "rsync --info=progress2 -aR narval:${base_path}/./split*/*.md5 .\n",
    "\n",
    "# rsync --info=progress2 -aR --exclude \"*.npz\" --exclude \"analysis_n*_f80.00/\" narval:${base_path}/./split*/shap .\n",
    "rsync --info=progress2 -aR narval:${base_path}/./split*/shap/*background*.npz .\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tarfile\n",
    "from collections import Counter, defaultdict\n",
    "from math import floor\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.special import softmax\n",
    "\n",
    "from epi_ml.core.data_source import EpiDataSource\n",
    "from epi_ml.utils.bed_utils import bed_ranges_to_bins, read_bed_to_ranges\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import ASSAY, CELL_TYPE, MetadataHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CANCER = \"harmonized_sample_cancer_high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "base_data_dir = (\n",
    "    base_dir / \"data\" / \"training_results\" / \"dfreeze_v2\" / \"hg38_100kb_all_none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsize_path = paper_dir / \"data\" / \"chromsizes\" / \"hg38.noy.chrom.sizes\"\n",
    "chroms = EpiDataSource.load_external_chrom_file(chromsize_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_handler = MetadataHandler(paper_dir)\n",
    "metadata = metadata_handler.load_metadata(\"v2\")\n",
    "metadata_df = pd.DataFrame.from_records(list(metadata.datasets))\n",
    "metadata_df.set_index(\"md5sum\", inplace=True)\n",
    "metadata_df[\"md5sum\"] = metadata_df.index\n",
    "del metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_dir = base_data_dir / f\"{CELL_TYPE}_1l_3000n\" / \"10fold-oversampling\"\n",
    "cancer_dir = base_data_dir / f\"{CANCER}_1l_3000n\" / \"10fold-oversampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in [cell_type_dir, cancer_dir]:\n",
    "    assert folder.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background selection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_training_vs_background(parent_dir: Path):\n",
    "    \"\"\"Create a table that compares the training data to the SHAP background data for each split.\n",
    "\n",
    "    Args:\n",
    "        parent_dir: The directory containing each split/fold directory.\n",
    "    \"\"\"\n",
    "    split_composition_dfs = {}  # pylint: disable=unused-variable\n",
    "    for split_dir in parent_dir.glob(\"split*\"):\n",
    "        if not split_dir.is_dir():\n",
    "            continue\n",
    "        split = split_dir.name  # pylint: disable=unused-variable\n",
    "\n",
    "        training_data_path = list(split_dir.glob(\"*training*.md5\"))\n",
    "        if len(training_data_path) != 1:\n",
    "            raise ValueError(f\"Multiple training data files found in {split_dir}\")\n",
    "        training_data_path = training_data_path[0]\n",
    "\n",
    "        background_data_path = list(split_dir.glob(\"shap/*background*.npz\"))\n",
    "        if len(background_data_path) != 1:\n",
    "            raise ValueError(f\"Multiple background data files found in {split_dir}\")\n",
    "        background_data_path = background_data_path[0]\n",
    "\n",
    "        training_md5s = set(\n",
    "            pd.read_csv(training_data_path, index_col=False, header=None)[0].values\n",
    "        )\n",
    "        background_data = np.load(background_data_path)\n",
    "        background_md5s = set(background_data[\"background_md5s\"])\n",
    "\n",
    "        # print(f\"Split: {split}\")\n",
    "        # print(f\"Training data: {len(training_md5s)}\")\n",
    "        # print(f\"Background data: {len(background_md5s)}\")\n",
    "\n",
    "        # Sanity check: background data is a subset of training data\n",
    "        diff = background_md5s - training_md5s\n",
    "        if diff:\n",
    "            raise ValueError(\n",
    "                f\"Background data is not a subset of the training data in {split_dir}: {len(diff)} md5s unique to background data.\"\n",
    "            )\n",
    "\n",
    "        # for diff ratio, do ((ratio background - ration training))*100 -> positive if background has more\n",
    "        # do assay / cell type / output class ratios\n",
    "        # table should have full number + ratios + diff ratio for each metadata category\n",
    "        # do for each split, save to a file, then average accross splits\n",
    "\n",
    "    raise NotImplementedError(\"Finish this function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for folder in [cell_type_dir, cancer_dir]:\n",
    "#     compare_all_training_vs_background(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP values ranking\n",
    "\n",
    "SHAP rank significance analysis (sample ontology)\n",
    "\n",
    "- Gather rank of all bins for sample output class (20k x 30k matrix)\n",
    "- For each % of highest values starting from top to 10%, compute mean SHAP value (20k x 10 matrix)\n",
    "- Create a graph that represents the ratio between 0-1% and 1-2% chunks, etc up until 10%, for each sample. 1 violin or boxplot per chunk (10 plots), 20k points per plot.\n",
    "\n",
    "Then, with flagship cell GO, get rank distribution of features \"unique\" in group1 VS group2 (t-cell, neutrophil: k27ac vs k27me3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute SHAP rankings / 1% chunks means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(shap_dir: Path) -> Tuple[Dict, Dict]:\n",
    "    \"\"\"Load evaluation and background data from specified directory.\n",
    "\n",
    "    Args:\n",
    "        shap_dir (Path): Directory containing the SHAP data files.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple containing evaluation results and background data.\n",
    "    \"\"\"\n",
    "    # Find all npz files once\n",
    "    npz_files = list(shap_dir.glob(\"*.npz\"))\n",
    "    eval_files = [f for f in npz_files if \"evaluation\" in f.name]\n",
    "    background_files = [f for f in npz_files if \"background\" in f.name]\n",
    "\n",
    "    if len(eval_files) != 1:\n",
    "        raise ValueError(\n",
    "            f\"Expected one evaluation file, found {len(eval_files)} in {shap_dir}\"\n",
    "        )\n",
    "    if len(background_files) != 1:\n",
    "        raise ValueError(\n",
    "            f\"Expected one background file, found {len(background_files)} in {shap_dir}\"\n",
    "        )\n",
    "\n",
    "    eval_results = dict(np.load(eval_files[0], allow_pickle=True))\n",
    "    background_data = dict(np.load(background_files[0], allow_pickle=True))\n",
    "\n",
    "    return eval_results, background_data\n",
    "\n",
    "\n",
    "def compute_mean_shap_values(\n",
    "    shap_matrices: List[np.ndarray],\n",
    "    md5_indices: List[str],\n",
    "    classes: Dict[str, int],\n",
    "    metadata_df: pd.DataFrame,\n",
    ") -> Dict[str, Dict]:\n",
    "    \"\"\"Rank amplitude of shap values and computes the mean SHAP values for specific segments of feature importance rankings\n",
    "    for each sample, and aggregates this information along with their softmax transformations.\n",
    "\n",
    "    This function processes SHAP values for given classes, extracts the relevant SHAP values\n",
    "    for each sample using its MD5 index, ranks these values, and calculates the mean of these values\n",
    "    in the top 10% segments. Additionally, it applies a softmax transformation to the SHAP values\n",
    "    and computes the mean for these as well, allowing for comparison between raw and transformed importance.\n",
    "\n",
    "    Args:\n",
    "        shap_matrices (List[np.ndarray]): SHAP values for all classes.\n",
    "        md5s (List[str]): Indices corresponding to MD5 hashes.\n",
    "        classes (dict): Mapping of class names to indices.\n",
    "        metadata_df (pd.DataFrame): DataFrame containing metadata.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Dict]: Dictionary of SHAP details for each sample ({md5: details}).\n",
    "    \"\"\"\n",
    "    input_size = len(shap_matrices[0][0])\n",
    "    chunks_10perc_idx = [\n",
    "        (floor(input_size / 100) * i, floor(input_size / 100) * (i + 1))\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    shap_details = {}\n",
    "\n",
    "    for md5_idx, md5 in enumerate(md5_indices):\n",
    "        cell_type: str = metadata_df.loc[md5][CELL_TYPE]  # type: ignore\n",
    "        class_idx = classes[cell_type]\n",
    "        sample_shaps = shap_matrices[class_idx][md5_idx]\n",
    "\n",
    "        sample_shaps = np.abs(sample_shaps)  # magnitude only\n",
    "        softmax_shaps = softmax(sample_shaps)\n",
    "        ranks = np.argsort(sample_shaps)[::-1]  # descending order, greatest to smallest\n",
    "\n",
    "        sorted_shap_vals = sample_shaps[ranks]\n",
    "        sorted_softmax_shap_vals = softmax_shaps[ranks]\n",
    "\n",
    "        mean_10perc_vals = [\n",
    "            np.mean(sorted_shap_vals[idx1:idx2], dtype=np.float64)\n",
    "            for idx1, idx2 in chunks_10perc_idx\n",
    "        ]\n",
    "        mean_10perc_vals_softmax = [\n",
    "            np.mean(sorted_softmax_shap_vals[idx1:idx2], dtype=np.float64)\n",
    "            for idx1, idx2 in chunks_10perc_idx\n",
    "        ]\n",
    "\n",
    "        shap_details[md5] = {\n",
    "            \"ranks\": ranks,\n",
    "            \"mean_10perc_vals\": mean_10perc_vals,\n",
    "            \"mean_10perc_vals_softmax\": mean_10perc_vals_softmax,\n",
    "        }\n",
    "\n",
    "    return shap_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shap_tables(shap_details: Dict[str, Dict]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Create tables containing SHAP details for each sample.\n",
    "\n",
    "    Args:\n",
    "        shap_details (Dict[str, Dict]): Dictionary of SHAP details for each sample\n",
    "            format: {md5: {\"ranks\": vals, \"mean_10perc_vals\": vals, \"mean_10perc_vals_softmax\": vals}}\n",
    "\n",
    "    Returns:\n",
    "       Dict[str, pd.DataFrame]: List of DataFrames containing each shap details category.\n",
    "    \"\"\"\n",
    "    ranks = pd.DataFrame.from_dict(\n",
    "        data={md5: details[\"ranks\"] for md5, details in shap_details.items()},\n",
    "        orient=\"index\",\n",
    "        dtype=\"int32\",\n",
    "    )\n",
    "\n",
    "    mean_10perc_vals = pd.DataFrame.from_dict(\n",
    "        data={md5: details[\"mean_10perc_vals\"] for md5, details in shap_details.items()},\n",
    "        orient=\"index\",\n",
    "        dtype=\"float64\",\n",
    "    )\n",
    "    mean_10perc_vals.columns = [f\"mean(top {i}% to {i+1}%)\" for i in range(10)]\n",
    "\n",
    "    mean_10perc_vals_softmax = pd.DataFrame.from_dict(\n",
    "        data={\n",
    "            md5: details[\"mean_10perc_vals_softmax\"]\n",
    "            for md5, details in shap_details.items()\n",
    "        },\n",
    "        orient=\"index\",\n",
    "        dtype=\"float64\",\n",
    "    )\n",
    "    mean_10perc_vals_softmax.columns = mean_10perc_vals.columns\n",
    "\n",
    "    return {\n",
    "        \"ranks\": ranks,\n",
    "        \"mean_10perc_vals\": mean_10perc_vals,\n",
    "        \"mean_10perc_vals_softmax\": mean_10perc_vals_softmax,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_shap_tables(\n",
    "    tables: Dict[str, pd.DataFrame], output_dir: Path, verbose: bool = True\n",
    "):\n",
    "    \"\"\"Save SHAP tables to specified directory.\n",
    "\n",
    "    Args:\n",
    "        tables (Dict[str, pd.DataFrame]): Dictionary of tables to save.\n",
    "        output_dir (Path): Directory to save the tables.\n",
    "    \"\"\"\n",
    "    for name, table in tables.items():\n",
    "        if name == \"ranks\":\n",
    "            output_path = output_dir / \"shap_abs_ranks.npz\"\n",
    "            np.savez_compressed(\n",
    "                output_path,\n",
    "                **{\n",
    "                    \"index\": table.index.values,\n",
    "                    \"columns\": table.columns.values,\n",
    "                    \"values\": table.values,\n",
    "                },\n",
    "            )\n",
    "            if verbose:\n",
    "                print(f\"Saved SHAP ranks to {output_path}\")\n",
    "        else:\n",
    "            output_path = output_dir / f\"shap_table_{name}.csv\"\n",
    "            table.to_csv(output_path)\n",
    "            if verbose:\n",
    "                print(f\"Saved SHAP details to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name = \"split0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_details = defaultdict(dict)\n",
    "# for shap_dir in cell_type_dir.glob(f\"{split_name}/shap\"):\n",
    "#     if not shap_dir.is_dir():\n",
    "#         continue\n",
    "\n",
    "#     try:\n",
    "#         eval_results, background_data = load_data(shap_dir)\n",
    "#     except ValueError as e:\n",
    "#         print(e)\n",
    "#         continue\n",
    "\n",
    "#     classes = {class_name: int(idx) for idx, class_name in background_data[\"classes\"]}\n",
    "\n",
    "#     shap_matrices = eval_results[\"shap_values\"]\n",
    "\n",
    "#     shap_details.update(\n",
    "#         compute_mean_shap_values(\n",
    "#             shap_matrices, eval_results[\"evaluation_md5s\"], classes, metadata_df\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# del shap_matrices, eval_results, background_data\n",
    "\n",
    "\n",
    "# shap_tables = create_shap_tables(shap_details)\n",
    "\n",
    "\n",
    "# output_dir = cell_type_dir / \"global_shap_analysis\"\n",
    "# if not output_dir.exists():\n",
    "#     raise ValueError(f\"Output directory {output_dir} does not exist.\")\n",
    "\n",
    "# output_dir = output_dir / f\"{split_name}_details\"\n",
    "# output_dir.mkdir(exist_ok=True)\n",
    "# save_shap_tables(shap_tables, output_dir)\n",
    "\n",
    "# print(f\"Processed {len(shap_details)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph computed means ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_shap_10perc(shap_table_mean_path: Path, output_dir: Path):\n",
    "    \"\"\"Plot the variation of mean SHAP values accross 1% segments (top 10)\"\"\"\n",
    "    df = pd.read_csv(shap_table_mean_path, index_col=0)\n",
    "    fig = go.Figure()\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        try:\n",
    "            ratio = df.iloc[:, idx] / df.iloc[:, idx + 1]\n",
    "        except IndexError:\n",
    "            continue\n",
    "        fig.add_trace(\n",
    "            go.Violin(\n",
    "                y=ratio,\n",
    "                name=f\"Ratio {col} / {df.columns[idx+1]}\",\n",
    "                points=\"all\",\n",
    "                marker=dict(size=1),\n",
    "                hovertemplate=\"%{text}\",\n",
    "                text=[f\"{md5}: {diff}\" for md5, diff in zip(df.index, ratio)],\n",
    "                box_visible=True,\n",
    "                meanline_visible=True,\n",
    "                spanmode=\"hard\",\n",
    "            )\n",
    "        )\n",
    "    fig.update_layout(\n",
    "        title=\"Ratio of mean SHAP values between 1% segments\",\n",
    "        xaxis_title=\"1% segment\",\n",
    "        yaxis_title=\"Ratio\",\n",
    "    )\n",
    "\n",
    "    # Save figure\n",
    "    output = output_dir / shap_table_mean_path.stem\n",
    "\n",
    "    fig.write_html(f\"{output}.html\")\n",
    "    fig.write_image(f\"{output}.png\")\n",
    "    fig.write_image(f\"{output}.svg\")\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_vals_path = cell_type_dir / \"global_shap_analysis\" / \"shap_table_mean_10perc_vals_softmax.csv\"\n",
    "# if not mean_vals_path.exists():\n",
    "#     raise FileNotFoundError(mean_vals_path)\n",
    "# graph_shap_10perc(mean_vals_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beds_to_bins(\n",
    "    feature_beds_tar: Path, chroms: List[Tuple[str, int]]\n",
    ") -> Dict[str, List[int]]:\n",
    "    \"\"\"Extracts and processes .bed files from a tar.gz archive, specifically targeting T cells and neutrophils with h3k27ac or h3k27me3 markers.\n",
    "\n",
    "    Args:\n",
    "        feature_beds_tar (Path): The path to the tar.gz file containing .bed files.\n",
    "        chroms (List[Tuple[str, int]]): List of tuples containing chromosome names and their lengths.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[int]]: A dictionary with keys as feature names and values as lists of bins derived from the .bed ranges.\n",
    "    \"\"\"\n",
    "    feature_bins = {}\n",
    "\n",
    "    with tarfile.open(feature_beds_tar, \"r:gz\") as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if (\n",
    "                member.name.endswith(\".bed\")\n",
    "                and (\"T_cell\" in member.name or \"neutrophil\" in member.name)\n",
    "                and (\"h3k27ac\" in member.name or \"h3k27me3\" in member.name)\n",
    "            ):\n",
    "                with tar.extractfile(member) as f:  # type: ignore\n",
    "                    bed_ranges = read_bed_to_ranges(f)\n",
    "                    bed_bins = bed_ranges_to_bins(\n",
    "                        bed_ranges, chroms=chroms, resolution=100 * 1000\n",
    "                    )\n",
    "                    name = Path(member.name).stem.replace(\"_feature\", \"\")\n",
    "                    feature_bins[name] = bed_bins\n",
    "\n",
    "    return feature_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((metadata_df[CELL_TYPE] == \"T cell\") & (metadata_df[ASSAY] == \"h3k27ac\")).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df[CELL_TYPE].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph rank of important relevant features from previous analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_beds_tar = cell_type_dir / \"global_shap_analysis\" / \"select_beds_top303.tar.gz\"\n",
    "\n",
    "feature_bins_dict = beds_to_bins(\n",
    "    feature_beds_tar=feature_beds_tar,\n",
    "    chroms=chroms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_bins_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading rank values.\")\n",
    "output_dir = cell_type_dir / \"global_shap_analysis\" / f\"{split_name}_details\"\n",
    "rank_file = output_dir / \"shap_abs_ranks.npz\"\n",
    "print(rank_file)\n",
    "\n",
    "with np.load(rank_file, allow_pickle=True) as f:\n",
    "    rank_values = f[\"values\"]\n",
    "    rank_md5s = f[\"index\"]\n",
    "    rank_bins = f[\"columns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_ranks_sample_ontology(\n",
    "    rank_file: Path, feature_bins: List[int], output_dir: Path, metadata_df: pd.DataFrame\n",
    "):\n",
    "    \"\"\"Graph the rank of specific sample ontology features, from perspective of different classes.\"\"\"\n",
    "    # metadata groups: t-cell/neutrophil with h3k27ac/h3k27me3\n",
    "    cell_types = [\"T cell\", \"neutrophil\"]\n",
    "    assays = [\"h3k27ac\", \"h3k27me3\"]\n",
    "    md5s_dict = {\n",
    "        f\"{cell}_{assay}_md5s\": list(\n",
    "            metadata_df[(metadata_df[CELL_TYPE] == cell) & (metadata_df[ASSAY] == assay)][\n",
    "                \"md5sum\"\n",
    "            ].values\n",
    "        )\n",
    "        for cell in cell_types\n",
    "        for assay in assays\n",
    "    }\n",
    "\n",
    "    # get md5s for each of the four metadata groups, and then get the ranks for each of the shared bins.\n",
    "    # one boxplot group per metadata group, with the sample ranks for each shared bin)\n",
    "    fig = go.Figure()\n",
    "    for name, md5s in md5s_dict.items():\n",
    "        avail_md5s = np.isin(rank_md5s, md5s)\n",
    "        shared_ranks = rank_values[avail_md5s]\n",
    "        print(f\"{name}: {shared_ranks.shape}\")\n",
    "\n",
    "        # Each bin is a different boxplot within the group\n",
    "        for bin_index in sorted(feature_bins):\n",
    "            feature_ranks = [np.where(ranks == bin_index)[0][0] for ranks in shared_ranks]\n",
    "            fig.add_trace(\n",
    "                go.Box(\n",
    "                    x=[f\"{name.replace('_md5s', '')} (n={len(feature_ranks)})\"]\n",
    "                    * len(feature_ranks),\n",
    "                    y=feature_ranks,\n",
    "                    name=f\"{name}_bin_{bin_index}\",\n",
    "                    # legendgroup=name,\n",
    "                    # legendgrouptitle=dict(text=name),\n",
    "                    line=dict(color=\"black\", width=1),\n",
    "                    showlegend=False,\n",
    "                    boxpoints=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"miaw (n={len(feature_bins)} bins)\",\n",
    "        xaxis_title=\"Feature bin\",\n",
    "        yaxis_title=\"Rank\",\n",
    "        boxmode=\"group\",\n",
    "        width=1000,\n",
    "        height=1000,\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare old results important features with currently computed ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = [\"T cell\", \"neutrophil\"]\n",
    "assays = [\"h3k27ac\", \"h3k27me3\"]\n",
    "md5s_dict = {\n",
    "    f\"{cell}_{assay}_md5s\": list(\n",
    "        metadata_df[(metadata_df[CELL_TYPE] == cell) & (metadata_df[ASSAY] == assay)][\n",
    "            \"md5sum\"\n",
    "        ].values\n",
    "    )\n",
    "    for cell in cell_types\n",
    "    for assay in assays\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dir = cell_type_dir / split_name\n",
    "shap_dir = split_dir / \"shap\"\n",
    "analysis_dir = shap_dir / \"analysis_n303_f80.00\"\n",
    "\n",
    "assay = \"h3k27ac\"\n",
    "cell_type = \"T cell\"\n",
    "\n",
    "important_features_path = analysis_dir / assay / \"important_features.json\"\n",
    "with open(important_features_path, \"r\", encoding=\"utf8\") as f:\n",
    "    important_features = json.load(f)\n",
    "\n",
    "# important_features_selection = important_features[cell_type][\"80.0\"]\n",
    "selected_features = list(\n",
    "    set(feature_bins_dict[\"h3k27ac_T_cells\"]) - set(feature_bins_dict[\"h3k27me3_T_cells\"])\n",
    ")\n",
    "\n",
    "graph_ranks_sample_ontology(\n",
    "    rank_file=None,\n",
    "    feature_bins=selected_features,\n",
    "    output_dir=output_dir,\n",
    "    metadata_df=metadata_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_md5s = md5s_dict[f\"{cell_type}_{assay}_md5s\"]\n",
    "sample_ranks = rank_values[np.isin(rank_md5s, relevant_md5s)]\n",
    "print(f\"Number of files in subset: {sample_ranks.shape[0]}\")\n",
    "\n",
    "# get the top features for each sample, using the ranks\n",
    "top_features_n303 = [rank_bins[sample_rank][0:303] for sample_rank in sample_ranks]\n",
    "\n",
    "top_n303_frequency = Counter(\n",
    "    [feature for sublist in top_features_n303 for feature in sublist]\n",
    ")\n",
    "\n",
    "feature_most_frequently_in_top303 = top_n303_frequency.most_common(1)[0][0]\n",
    "\n",
    "print(sample_ranks[:, feature_most_frequently_in_top303])\n",
    "\n",
    "\n",
    "# cutoff = \"95\"\n",
    "# N = len(important_features[cell_type][cutoff])\n",
    "# print(f\"Top 303 features (features within the top303 in {cutoff}% of samples)): {N}\")\n",
    "# most_frequent_features_in_top303 = [feature for feature, _ in top_n303_frequency.most_common(N)]\n",
    "# for feature in most_frequent_features_in_top303:\n",
    "#     if feature not in important_features[cell_type][cutoff]:\n",
    "#         print(f\"Feature {feature} not in important_features_selection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
