{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Metadata for ChIP-Atlas datasets\n",
    "\"\"\"\n",
    "# pylint: disable=redefined-outer-name, import-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display  # pylint: disable=unused-import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "paper_dir = base_dir\n",
    "\n",
    "base_data_dir = base_dir / \"data\"\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "metadata_dir = base_data_dir / \"metadata\"\n",
    "\n",
    "predictions_dir = base_data_dir / \"training_results\" / \"predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_metadata_dir = metadata_dir / \"chip_atlas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChIP-Atlas website download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to obtain some of the metadata:\n",
    "\n",
    "```bash\n",
    "wget https://chip-atlas.dbcls.jp/data/metadata/experimentList.tab\n",
    "grep -E \"^[DESRX]{3}[0-9]{4,8}\\shg38\\s\" experimentList.tab > experimentList_hg38.tab\n",
    "grep -vE \"^[DESRX]{3}[0-9]{4,8}\\shg38\\s[ATAC,DNASE,Bisulfate,RNA]\" experimentList_hg38.tab > experimentList_hg38_chip.tab\n",
    "cut -f1,3-7,9- experimentList_hg38_chip.tab | sponge experimentList_hg38_chip.tab # Removing col 2 and 8.\n",
    "```\n",
    "\n",
    "Following columns given at the [wiki](https://github.com/inutano/chip-atlas/wiki#tables-summarizing-metadata-and-files), 'assembly' and 'Processing_logs_of_chip_ATAC_DNASE' were removed, and the next column is observed as being the title. Despite the indicated columns on the wiki, the downloaded tab file does not correspond to it, as column 'Processing logs of Bisulfite-seq' actually contaisn the title for chip experiment, when I would expect it to be empty. The varying length of each line made the handling much more bothersome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = ca_metadata_dir / \"experimentList_hg38_chip_20250306.tab\"\n",
    "new_file_name = ca_metadata_dir / (metadata_path.stem + \"_formatted.tab\")\n",
    "\n",
    "if not new_file_name.exists():\n",
    "    with open(metadata_path, \"r\", encoding=\"utf8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Merging all lines past the title\n",
    "    new_file = []\n",
    "    for line in lines:\n",
    "        elems = line.split(\"\\t\")\n",
    "        core = elems[0:7]\n",
    "        rest = elems[7:]\n",
    "\n",
    "        rest = [x.strip() for x in rest]\n",
    "        rest = [x for x in rest if x]\n",
    "\n",
    "        new_line = \"\\t\".join(core) + \"\\t\" + str(rest)\n",
    "        new_file.append(new_line)\n",
    "\n",
    "    new_file.insert(\n",
    "        0,\n",
    "        \"Experimental_ID\\tTrack_type_class\\tTrack_type\\tCell_type_class\\tCell_type\\tCell_type_description\\tTitle\\tMeta_data_submitted_by_authors\",\n",
    "    )\n",
    "\n",
    "    with open(new_file_name, \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(\"\\n\".join(new_file))\n",
    "\n",
    "ca_metadata_df = pd.read_csv(new_file_name, sep=\"\\t\", low_memory=False)\n",
    "print(ca_metadata_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal DB matching metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimal metadata created from `CA_metadata_4DB+all_pred.20240606_mod3.0.tsv`.  \n",
    "Acquired from 4 databases.  \n",
    "I mostly kepts the ids and targets from different databases.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_metadata_path = ca_metadata_dir / \"CA_minimal_metadata_20240606.tsv\"\n",
    "ca_minimal_metadata_df = pd.read_csv(minimal_metadata_path, sep=\"\\t\", low_memory=False)\n",
    "print(ca_minimal_metadata_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some GSM title were missing from the old work, so I redownloaded metadata from GEO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_minimal_metadata_df.replace(\"-\", None, inplace=True)\n",
    "print(ca_minimal_metadata_df[\"GEO_gsm-title\"].isna().sum())\n",
    "\n",
    "missing_titles = ca_minimal_metadata_df[ca_minimal_metadata_df[\"GEO_gsm-title\"].isna()][\n",
    "    \"GEO_GSM\"\n",
    "].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_GEO_file(\n",
    "    GEO: str, logdir: str | Path, amount: str = \"quick\", verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Downloads a GEO (GSM) accession file and saves it to the specified log directory.\n",
    "\n",
    "    Args:\n",
    "        GEO (str): The GEO accession number (e.g., \"GSM123456\").\n",
    "        logdir (str): Directory to save the downloaded file.\n",
    "        amount (str): Level of detail for the file. Options: 'full', 'brief', 'quick', 'data'.\n",
    "                      Default is 'full'.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved file.\n",
    "    \"\"\"\n",
    "    # Ensure GEO is uppercase\n",
    "    GEO = GEO.upper()\n",
    "\n",
    "    # Validate the accession type\n",
    "    if not GEO.startswith(\"GSM\"):\n",
    "        raise ValueError(\"Only GSM accession numbers are supported.\")\n",
    "\n",
    "    # Ensure logdir exists\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "    # Construct the URL\n",
    "    gseurl = \"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi\"\n",
    "    myurl = f\"{gseurl}?targ=self&acc={GEO}&form=text&view={amount}\"\n",
    "\n",
    "    # Define the destination file path\n",
    "    destfile = os.path.join(logdir, f\"{GEO}.soft\")\n",
    "    if os.path.exists(destfile):\n",
    "        if verbose:\n",
    "            print(f\"File already exists: {destfile}\")\n",
    "        return destfile\n",
    "\n",
    "    try:\n",
    "        # Download the file\n",
    "        response = requests.get(myurl, stream=True)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx, 5xx)\n",
    "\n",
    "        # Save the file\n",
    "        with open(destfile, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"File saved: {destfile}\")\n",
    "        return destfile\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {GEO}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = ca_metadata_dir / \"GSM_metadata\"\n",
    "logdir.mkdir(exist_ok=True)\n",
    "\n",
    "meta_paths = []\n",
    "for GEO in missing_titles:\n",
    "    filepath = download_GEO_file(GEO, logdir, amount=\"quick\", verbose=False)\n",
    "    if filepath:\n",
    "        meta_paths.append(Path(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_title_dict = {}\n",
    "for filepath in meta_paths:\n",
    "    gsm = filepath.stem\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        title_line = lines[1]\n",
    "        if not title_line.startswith(\"!Sample_title\"):\n",
    "            raise ValueError(f\"Title not found for {gsm}\")\n",
    "\n",
    "        title = title_line.split(\"=\")[1].strip()\n",
    "        missing_title_dict[gsm] = title\n",
    "\n",
    "with open(logdir / \"GSM_title.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(missing_title_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_minimal_metadata_df[\"GEO_gsm-title\"] = (\n",
    "    ca_minimal_metadata_df[\"GEO_GSM\"]\n",
    "    .map(missing_title_dict)\n",
    "    .fillna(ca_minimal_metadata_df[\"GEO_gsm-title\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_minimal_metadata_df.to_csv(\n",
    "    ca_metadata_dir / \"CA_minimal_metadata_20240606_mod.tsv\", sep=\"\\t\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancer / Sex / Age metadata categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CA_metadata_FW_20240917` contains new metadata categories (cancer/sex/age) created from analyzing more complete metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_custom_metadata_path = metadata_dir / \"chip_atlas\" / \"CA_metadata_FW_20240917.tsv\"\n",
    "ca_custom_metadata_df = pd.read_csv(ca_custom_metadata_path, sep=\"\\t\", low_memory=False)\n",
    "print(ca_custom_metadata_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = ca_minimal_metadata_df.columns[0]\n",
    "col2 = ca_metadata_df.columns[0]\n",
    "\n",
    "meta_df = ca_minimal_metadata_df.merge(\n",
    "    ca_metadata_df, how=\"left\", left_on=col1, right_on=col2\n",
    ")\n",
    "meta_df.drop(col2, axis=1, inplace=True)\n",
    "\n",
    "col2 = ca_custom_metadata_df.columns[0]\n",
    "meta_df = meta_df.merge(ca_custom_metadata_df, how=\"left\", left_on=col1, right_on=col2)\n",
    "meta_df.drop(col2, axis=1, inplace=True)\n",
    "meta_df.rename({\"Title\": \"C-A_title\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = meta_df.fillna(\"unknown\")\n",
    "meta_df = meta_df.replace(\"Unclassified\", \"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.to_csv(ca_metadata_dir / \"CA_metadata_joined_20250306.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit assay and biospecimen counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biospecimens = meta_df.copy(deep=True)\n",
    "\n",
    "# Count occurrences of each \"Cell_type\" within \"Cell_type_class\"\n",
    "group_sizes = df_biospecimens.groupby(\"Cell_type_class\")[\"Cell_type\"].count()\n",
    "\n",
    "# Sort \"Cell_type_class\" by descending count of \"Cell_type\"\n",
    "sorted_classes = group_sizes.sort_values(ascending=False).index\n",
    "\n",
    "# Apply sorted order to the original grouping\n",
    "sorted_groupby = (\n",
    "    df_biospecimens.groupby([\"Cell_type_class\", \"Cell_type\"], dropna=False)\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .set_index(\"Cell_type_class\")\n",
    "    .loc[sorted_classes]\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_groupby.columns = [\"Cell_type_class\", \"Cell_type\", \"count\"]\n",
    "\n",
    "output_dir = base_dir / \"tables\" / \"datasets_composition\"\n",
    "sorted_groupby.to_csv(output_dir / \"ChIP-Atlas_biospecimens.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays_df = (\n",
    "    meta_df.groupby(\"manual_target_consensus\", dropna=False)\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    "    .to_frame(name=\"count\")\n",
    ")\n",
    "assays_df.to_csv(output_dir / \"ChIP-Atlas_assays.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
