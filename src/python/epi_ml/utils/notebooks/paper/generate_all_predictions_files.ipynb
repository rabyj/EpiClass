{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Workbook to create supplementary prediction files destined for the paper.\\n\\nMust include all data predictions used to create paper figures.\\nIntended to create files for all 5 classifiers trained on 'assay_epiclass' and 'harmonized_sample_ontology_intermediate' categories. (10)\\nPlus six (6) other categories trained with MLP.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Workbook to create supplementary prediction files destined for the paper.\n",
    "\n",
    "Must include all data predictions used to create paper figures.\n",
    "\"\"\"\n",
    "# pylint: disable=import-error, redefined-outer-name, use-dict-literal, too-many-lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import (\n",
    "    ASSAY,\n",
    "    CELL_TYPE,\n",
    "    LIFE_STAGE,\n",
    "    SEX,\n",
    "    SplitResultsHandler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "base_data_dir = base_dir / \"data\"\n",
    "base_fig_dir = base_dir / \"figures\"\n",
    "paper_dir = base_dir\n",
    "table_dir = paper_dir / \"tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_results_handler = SplitResultsHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assay + sample ontology for all 5 model types - 100kb_all_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df_for_save(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Prepare DataFrame for saving to CSV.\"\"\"\n",
    "    df.insert(0, \"Expected class\", df.pop(\"True class\"))\n",
    "    df.set_index(\"md5sum\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_100kb = base_data_dir / \"training_results\" / \"dfreeze_v2\" / \"hg38_100kb_all_none\"\n",
    "logdir = table_dir / \"dfreeze_v2\" / \"100kb_all_none\"\n",
    "if not logdir.exists():\n",
    "    logdir.mkdir(parents=True)\n",
    "\n",
    "split_md5sums = []\n",
    "for category in [ASSAY, CELL_TYPE]:\n",
    "    all_split_dfs = split_results_handler.gather_split_results_across_methods(\n",
    "        results_dir=data_dir_100kb,\n",
    "        label_category=category,\n",
    "        only_NN=False,\n",
    "    )\n",
    "\n",
    "    # Sanity check, same shape, same input files for each method\n",
    "    for split_dict in all_split_dfs.values():\n",
    "        ref_dict = split_dict[\"NN\"]\n",
    "        ref_md5sums = sorted(ref_dict.index.values.tolist())\n",
    "        ref_shape = ref_dict.shape\n",
    "        for method, df in split_dict.items():\n",
    "            if not ref_md5sums == sorted(df.index.values.tolist()):\n",
    "                raise ValueError(\"MD5sums do not match\")\n",
    "            if ref_shape != df.shape:\n",
    "                raise ValueError(\"Shapes do not match\")\n",
    "\n",
    "    all_split_dfs_concat = split_results_handler.concatenate_split_results(all_split_dfs)\n",
    "\n",
    "    # Save to file\n",
    "    for method, df in all_split_dfs_concat.items():\n",
    "        df = prepare_df_for_save(df)\n",
    "\n",
    "        if method == \"NN\":\n",
    "            method = \"MLP\"\n",
    "\n",
    "        filename = f\"10fold_predictions_{category}_{method}.csv\"\n",
    "        df.to_csv(logdir / filename, index=True, sep=\",\", float_format=\"%.4f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other MLP results - 100kb_all_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    \"paired_end\",\n",
    "    \"harmonized_sample_cancer_high\",\n",
    "    LIFE_STAGE,\n",
    "    SEX,\n",
    "    \"harmonized_biomaterial_type\",\n",
    "    \"project\",\n",
    "]\n",
    "\n",
    "# Select 10-fold oversampling runs\n",
    "all_split_dfs = split_results_handler.general_split_metrics(\n",
    "    results_dir=data_dir_100kb,\n",
    "    merge_assays=False,\n",
    "    include_categories=categories,\n",
    "    exclude_names=[\"reg\", \"no-mixed\", \"chip\"],\n",
    "    return_type=\"split_results\",\n",
    "    verbose=False,\n",
    ")\n",
    "all_split_dfs_concat = split_results_handler.concatenate_split_results(all_split_dfs, concat_first_level=True)  # type: ignore\n",
    "\n",
    "# Save to file\n",
    "for category, df in all_split_dfs_concat.items():\n",
    "    df = prepare_df_for_save(df)\n",
    "\n",
    "    filename = f\"10fold_predictions_{category}_MLP.csv\"\n",
    "    df.to_csv(logdir / filename, index=True, sep=\",\", float_format=\"%.4f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for other feature sets (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [ASSAY, CELL_TYPE]\n",
    "include_sets = [\n",
    "    \"hg38_10mb_all_none_1mb_coord\",\n",
    "    \"hg38_100kb_random_n316_none\",\n",
    "    \"hg38_1mb_all_none\",\n",
    "    \"hg38_100kb_random_n3044_none\",\n",
    "    \"hg38_100kb_all_none\",\n",
    "    \"hg38_gene_regions_100kb_coord_n19864\",\n",
    "    \"hg38_10kb_random_n30321_none\",\n",
    "    \"hg38_regulatory_regions_n30321\",\n",
    "    \"hg38_1kb_random_n30321_none\",\n",
    "    \"hg38_cpg_topvar_200bp_10kb_coord_n30k\",\n",
    "    \"hg38_10kb_all_none\",\n",
    "    \"hg38_regulatory_regions_n303114\",\n",
    "    \"hg38_1kb_random_n303114_none\",\n",
    "    \"hg38_cpg_topvar_200bp_10kb_coord_n300k\",\n",
    "]\n",
    "exclude_names = [\"7c\", \"chip-seq-only\", \"27ct\", \"16ct\"]\n",
    "\n",
    "# Select 10-fold oversampling runs\n",
    "# expected result shape: {feature_set: {task_name: {split_name: results_dataframe}}}\n",
    "all_results: Dict[\n",
    "    str, Dict[str, Dict[str, pd.DataFrame]]\n",
    "] = split_results_handler.obtain_all_feature_set_data(\n",
    "    return_type=\"split_results\",\n",
    "    parent_folder=data_dir_100kb.parent,\n",
    "    merge_assays=False,\n",
    "    include_categories=categories,\n",
    "    include_sets=include_sets,\n",
    "    exclude_names=exclude_names,\n",
    "    verbose=False,\n",
    ")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature_set_name in all_results.keys():\n",
    "    try:\n",
    "        all_results[feature_set_name][ASSAY] = all_results[feature_set_name][\"assay_epiclass_11c\"]  # type: ignore\n",
    "        del all_results[feature_set_name][\"assay_epiclass_11c\"]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check : MD5sums and shapes should match between reference and other feature sets, for each split\n",
    "for task_name in categories:\n",
    "    # Select a reference feature set and use its splits as the baseline for comparison\n",
    "    reference_feature_set = \"hg38_100kb_all_none\"\n",
    "    reference_splits = all_results[reference_feature_set][task_name]\n",
    "\n",
    "    # Create reference MD5sums and shapes for each split in the reference feature set\n",
    "    reference_md5sums = {\n",
    "        split_name: sorted(df.index.tolist())\n",
    "        for split_name, df in reference_splits.items()\n",
    "    }\n",
    "    reference_shapes = {\n",
    "        split_name: df.shape for split_name, df in reference_splits.items()\n",
    "    }\n",
    "\n",
    "    # Iterate over each feature set and compare its splits against the reference\n",
    "    for feature_set_name, tasks_dict in all_results.items():\n",
    "        for split_name, df in tasks_dict[task_name].items():\n",
    "            if reference_md5sums[split_name] != sorted(df.index.tolist()):\n",
    "                raise ValueError(\n",
    "                    f\"MD5sums mismatch in task '{task_name}', split '{split_name}', \"\n",
    "                    f\"between reference feature set '{reference_feature_set}' and feature set '{feature_set_name}'\"\n",
    "                )\n",
    "            if reference_shapes[split_name] != df.shape:\n",
    "                raise ValueError(\n",
    "                    f\"Shape mismatch in task '{task_name}', split '{split_name}', \"\n",
    "                    f\"between reference feature set '{reference_feature_set}' and feature set '{feature_set_name}'\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = table_dir / \"dfreeze_v2\" / \"other_feature_sets\"\n",
    "logdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for feature_set_name, tasks_dict in all_results.items():\n",
    "    if feature_set_name == \"hg38_100kb_all_none\":\n",
    "        continue\n",
    "    all_split_dfs_concat = split_results_handler.concatenate_split_results(\n",
    "        tasks_dict, concat_first_level=True\n",
    "    )\n",
    "    for task_name, df in all_split_dfs_concat.items():\n",
    "        df = prepare_df_for_save(df)\n",
    "\n",
    "        filename = f\"{feature_set_name}_10fold_predictions_{task_name}.csv\"\n",
    "        df.to_csv(logdir / filename, index=True, sep=\",\", float_format=\"%.4f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
