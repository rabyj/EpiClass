{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbooks to analyze metadata.\"\"\"\n",
    "# pylint: disable=import-error, redefined-outer-name, unused-import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "import io\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import DefaultDict, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display\n",
    "\n",
    "from epi_ml.core.metadata import Metadata, UUIDMetadata\n",
    "from epi_ml.utils.general_utility import write_hdf5_paths_to_file, write_md5s_to_file\n",
    "from epi_ml.utils.modify_metadata import filter_by_pairs\n",
    "\n",
    "BIOMATERIAL_TYPE = \"harmonized_biomaterial_type\"\n",
    "CELL_TYPE = \"harmonized_sample_ontology_intermediate\"\n",
    "ASSAY = \"assay_epiclass\"\n",
    "SEX = \"harmonized_donor_sex\"\n",
    "CANCER = \"harmonized_sample_cancer_high\"\n",
    "DISEASE = \"harmonized_sample_disease_high\"\n",
    "LIFE_STAGE = \"harmonized_donor_life_stage\"\n",
    "TRACK = \"track_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAY_MERGE_DICT: Dict[str, str] = {\n",
    "    \"rna_seq\": \"rna\",\n",
    "    \"mrna_seq\": \"rna\",\n",
    "    \"wgbs-pbat\": \"wgbs\",\n",
    "    \"wgbs-standard\": \"wgbs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_cts = [\n",
    "    \"T cell\",\n",
    "    \"neutrophil\",\n",
    "    \"brain\",\n",
    "    \"monocyte\",\n",
    "    \"lymphocyte of B lineage\",\n",
    "    \"myeloid cell\",\n",
    "    \"venous blood\",\n",
    "    \"macrophage\",\n",
    "    \"mesoderm-derived structure\",\n",
    "    \"endoderm-derived structure\",\n",
    "    \"colon\",\n",
    "    \"connective tissue cell\",\n",
    "    \"hepatocyte\",\n",
    "    \"mammary gland epithelial cell\",\n",
    "    \"muscle organ\",\n",
    "    \"extraembryonic cell\",\n",
    "]\n",
    "accepted_cts = [ct.lower() for ct in accepted_cts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path().home() / \"Projects/epiclass/input/metadata\"\n",
    "path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl.json\"\n",
    "# path = base / \"dfreeze-v1.0\" / \"hg38_2023-epiatlas_dfreeze_formatted_JR.json\"\n",
    "# path = base / \"dfreeze-v1.0\" / \"hg38_2023-epiatlas_dfreeze_plus_encode_noncore_formatted_JR.json\"\n",
    "# path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    "my_metadata = Metadata(path)\n",
    "meta_df = my_metadata.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gen_info(metadata: Metadata):\n",
    "    \"\"\"Display track type, assay and cell type class counts.\"\"\"\n",
    "    metadata.display_labels(\"track_type\")\n",
    "    metadata.display_labels(ASSAY)\n",
    "    metadata.display_labels(CELL_TYPE)\n",
    "    metadata.display_labels(SEX)\n",
    "    # metadata.display_labels(CANCER)\n",
    "    # metadata.display_labels(DISEASE)\n",
    "    # metadata.display_labels(LIFE_STAGE)\n",
    "    metadata.display_labels(TRACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trios(metadata: Metadata) -> Counter:\n",
    "    \"\"\"\n",
    "    Count the occurrences of unique (track_type, assay, cell_type) trios in the metadata.\n",
    "\n",
    "    Returns:\n",
    "        Counter: A Counter object of the unique trios.\n",
    "    \"\"\"\n",
    "    trios = Counter(\n",
    "        [(dset[\"track_type\"], dset[ASSAY], dset[CELL_TYPE]) for dset in metadata.datasets]\n",
    "    )\n",
    "    return trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pairs_w_assay(metadata: Metadata, category: str) -> DefaultDict[str, Counter]:\n",
    "    \"\"\"\n",
    "    Count the occurrences of each cell type for each assay in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict(Counter): A defaultdict of Counter objects with the count of cell types per assay.\n",
    "    \"\"\"\n",
    "    pair_count = defaultdict(Counter)\n",
    "    for dset in metadata.datasets:\n",
    "        assay, other_label = dset[ASSAY], dset[category]\n",
    "        pair_count[assay].update([other_label])\n",
    "    return pair_count\n",
    "\n",
    "\n",
    "def select_cell_types(metadata: Metadata, n=70) -> DefaultDict[str, List]:\n",
    "    \"\"\"\n",
    "    Determines which cell types are needed to attain n datasets, for a given assay.\n",
    "    Starts with T cell and then selects the most common cell types.\n",
    "\n",
    "    Args:\n",
    "        metadata (Metadata): A Metadata object containing dataset metadata.\n",
    "        n (int, optional): Maximum number of cell types to select for each assay. Defaults to 70.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict(list): A defaultdict with selected cell types for each assay.\n",
    "    \"\"\"\n",
    "    cell_count = count_pairs_w_assay(metadata, CELL_TYPE)\n",
    "\n",
    "    selected_ct = defaultdict(list)\n",
    "    for assay, counter in cell_count.items():\n",
    "        selected_ct[assay].append(\"T cell\")\n",
    "        i = min(counter[\"T cell\"], n)\n",
    "        del counter[\"T cell\"]\n",
    "        while i < n and counter:\n",
    "            for cell_type, count in counter.most_common():\n",
    "                i += min(count, n - i)\n",
    "                selected_ct[assay].append(cell_type)\n",
    "                del counter[cell_type]\n",
    "                break\n",
    "        if i < n:\n",
    "            print(f\"There is not at least {n} files for {assay}. Final number={i}\")\n",
    "\n",
    "    return selected_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our metadata VS official metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata we use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl.json\"\n",
    "my_metadata = Metadata(path)\n",
    "my_meta_df = my_metadata.to_df()\n",
    "my_meta_df = my_meta_df.drop_duplicates(subset=[\"epirr_id_without_version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevants_cols = [CELL_TYPE, BIOMATERIAL_TYPE, SEX, DISEASE, LIFE_STAGE]\n",
    "my_meta_df = my_meta_df[[\"epirr_id_without_version\"] + relevants_cols]\n",
    "my_epirrs = set(my_meta_df[\"epirr_id_without_version\"].unique())\n",
    "\n",
    "my_meta_df = my_meta_df.set_index(\"epirr_id_without_version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Official metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "url_template = \"https://raw.githubusercontent.com/IHEC/epiATLAS-metadata-harmonization/refs/heads/main/openrefine/{version}/IHEC_metadata_harmonization.{version}.extended.csv\"\n",
    "for version in [\"v1.0\", \"v1.1\", \"v1.2\"]:\n",
    "    myurl = url_template.format(version=version)\n",
    "    print(f\"Downloading version {version}: {myurl}\")\n",
    "\n",
    "    try:\n",
    "        # Download the file\n",
    "        response = requests.get(myurl, stream=True)\n",
    "        response.raise_for_status()  # Raise an error for bad responses (4xx, 5xx)\n",
    "\n",
    "        # Load file as a DataFrame\n",
    "        content = response.content\n",
    "        df = pd.read_csv(io.StringIO(content.decode(\"utf-8\")))\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading {myurl}: {e}\")\n",
    "\n",
    "    dfs[version] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify dataframes to fit with our metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v, df in dfs.items():\n",
    "    df[\"epirr_id_without_version\"] = df[\"EpiRR\"].str.split(\".\").str[0]\n",
    "    df = df.set_index(\"epirr_id_without_version\")\n",
    "    df.fillna(\"unknown\", inplace=True)\n",
    "    dfs[v] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating json of differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_idxs = defaultdict(set)\n",
    "for cat in relevants_cols:\n",
    "    for version in [\"v1.0\", \"v1.1\"]:\n",
    "        meta = dfs[version]\n",
    "        meta = meta[meta.index.isin(my_epirrs)]\n",
    "\n",
    "        # sort same way\n",
    "        meta = meta.loc[my_meta_df.index]\n",
    "\n",
    "        # find idx where value is different\n",
    "        diff = meta[cat] != my_meta_df[cat]\n",
    "        diff_idxs = diff[diff].index\n",
    "\n",
    "        if not diff_idxs.empty:\n",
    "            problematic_idxs[cat].update(diff_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_changes = {col: {} for col in relevants_cols if col in problematic_idxs}\n",
    "for col in relevants_cols:\n",
    "    cat_idxs = problematic_idxs[col]\n",
    "    for idx in cat_idxs:\n",
    "        values = {\n",
    "            \"training\": my_meta_df.loc[idx, col],\n",
    "            \"v1.0-official\": dfs[\"v1.0\"].loc[idx, col],\n",
    "            \"v1.1-official\": dfs[\"v1.1\"].loc[idx, col],\n",
    "        }\n",
    "        all_changes[col][idx] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in relevants_cols:\n",
    "    if col in problematic_idxs:\n",
    "        print(f\"Changes in {col}: {len(problematic_idxs[col])}\")\n",
    "    else:\n",
    "        print(f\"No changes in {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"training_metadata_vs_official.json\"\n",
    "path = base / filename\n",
    "\n",
    "with open(path, \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(all_changes, f, indent=4, allow_nan=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: SEX v1.2 = SEX v1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_metadata_dir = (\n",
    "    Path.home() / \"Projects/epiclass/output/paper/data/metadata/official\"\n",
    ")\n",
    "\n",
    "official_metadata_dfs = {}\n",
    "for version in [\"v1.1\", \"v1.2\", \"v1.3\"]:\n",
    "    path = official_metadata_dir / f\"IHEC_metadata_harmonization.{version}.extended.csv\"\n",
    "    df = pd.read_csv(path, sep=\",\")\n",
    "    official_metadata_dfs[version] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEX = \"harmonized_donor_sex\"\n",
    "sex_mislabels_path = (\n",
    "    official_metadata_dir / \"BadQual-mislabels\" / \"official_Sex_mislabeled.csv\"\n",
    ")\n",
    "sex_mislabels_df = pd.read_csv(sex_mislabels_path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_epirrs = {}\n",
    "subset_df = sex_mislabels_df\n",
    "for version, df in official_metadata_dfs.items():\n",
    "    relevant_df = df.loc[:, [\"epirr_id_without_version\", SEX]]\n",
    "    subset_df = relevant_df.merge(\n",
    "        subset_df,\n",
    "        left_on=\"epirr_id_without_version\",\n",
    "        right_on=\"EpiRR_no-v\",\n",
    "        how=\"right\",\n",
    "        suffixes=(f\"_{version}\", \"\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = subset_df.drop(\n",
    "    columns=[col for col in subset_df.columns if col.startswith(\"epirr_id\")]\n",
    ")\n",
    "subset_df = subset_df.drop(columns=[SEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (subset_df[f\"{SEX}_v1.3\"] != subset_df[f\"{SEX}_v1.2\"]).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = official_metadata_dfs[\"v1.2\"].merge(\n",
    "    official_metadata_dfs[\"v1.3\"],\n",
    "    on=\"epirr_id_without_version\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_v1.2\", \"_v1.3\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (merged_df[f\"{SEX}_v1.3\"] != merged_df[f\"{SEX}_v1.2\"]).sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new metadata (for imputed files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl.json\"\n",
    "my_metadata = Metadata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_metadata.select_category_subsets(TRACK, [\"pval\"])\n",
    "my_metadata.select_category_subsets(\n",
    "    ASSAY, [\"h3k27ac\", \"h3k27me3\", \"h3k36me3\", \"h3k4me1\", \"h3k4me3\", \"h3k9me3\"]\n",
    ")\n",
    "\n",
    "df = pd.DataFrame.from_records(list(my_metadata.datasets), index=[\"epirr_id\"])\n",
    "\n",
    "print(df.shape, len(my_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all assay specific columns, only want epirr metadata\n",
    "df.drop(\n",
    "    columns=[\n",
    "        \"uuid\",\n",
    "        \"md5sum\",\n",
    "        \"assay_type\",\n",
    "        \"assay_epiclass\",\n",
    "        \"experiment_type\",\n",
    "        \"antibody\",\n",
    "        \"inputs\",\n",
    "        \"inputs_ctl\",\n",
    "        \"data_file_path\",\n",
    "        \"upload_date\",\n",
    "        \"paired_end\",\n",
    "        \"analyzed_as_stranded\",\n",
    "        \"status\",\n",
    "    ],\n",
    "    inplace=True,\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "problematics_columns = df.filter(like=\"read_len\").columns.to_list()\n",
    "df.drop(columns=problematics_columns, inplace=True, errors=\"ignore\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(axis=0, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, len(set(df.index)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_ids_path = (\n",
    "    Path.home()\n",
    "    / \"mounts/narval-mount\"\n",
    "    / \"rrg-ihec-share/local_ihec_data/epiatlas/hg38/bw/chip-seq_imputed\"\n",
    "    / \"all_md5sums.list\"\n",
    ")\n",
    "\n",
    "imputed_ids_df = pd.read_csv(\n",
    "    imputed_ids_path, sep=\"  \", header=None, names=[\"md5sum\", \"filename\"], engine=\"python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_ids_df.head()\n",
    "imputed_ids_df[\"epirr_id\"] = imputed_ids_df[\"filename\"].str.extract(\n",
    "    r\"impute_(.+)_H3.+.pval.bw\"\n",
    ")\n",
    "imputed_ids_df[\"assay_epiclass\"] = imputed_ids_df[\"filename\"].str.extract(\n",
    "    r\"impute_.+_(H3.+).pval.bw\"\n",
    ")\n",
    "imputed_ids_df[\"assay_epiclass\"] = imputed_ids_df[\"assay_epiclass\"].str.lower()\n",
    "imputed_ids_df[\"uuid\"] = imputed_ids_df[\"md5sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputed_ids_df.shape)\n",
    "imputed_ids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputed_ids_df[\"epirr_id\"].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_og = set(df.index)\n",
    "set_imputed = set(imputed_ids_df[\"epirr_id\"])\n",
    "\n",
    "union = set(df.index) | set(imputed_ids_df[\"epirr_id\"])\n",
    "print(len(union), len(set_og), len(set_imputed))\n",
    "print(set_imputed - set_og)\n",
    "\n",
    "for item in sorted(set_imputed - set_og):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imputed_df = df.merge(\n",
    "    imputed_ids_df, left_index=True, right_on=\"epirr_id\", how=\"right\"\n",
    ")\n",
    "print(merged_imputed_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imputed_df.fillna(\"\", inplace=True)  # necessary to not end up with \"float\" types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_imputed_df.to_csv(Path.home() / \"downloads\" / \"temp\"/ \"hg38_epiatlas_imputed_pval_chip_2024-02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dict = merged_imputed_df.to_dict(orient=\"records\")\n",
    "# meta_dict = {dset[\"md5sum\"]: dset for dset in new_dict}\n",
    "# new_metadata = Metadata.from_dict(meta_dict)\n",
    "# new_metadata.save(\n",
    "#     Path.home() / \"downloads\" / \"temp\" / \"hg38_epiatlas_imputed_pval_chip_2024-02.json\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: imputed vs obs pval datasets are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paper_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "base_metadata_dir = base_paper_dir / \"data/metadata\"\n",
    "path_metadata_observed = (\n",
    "    base_metadata_dir / \"hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    ")\n",
    "obs_metadata = Metadata(path_metadata_observed)\n",
    "\n",
    "path_obs_md5 = base_paper_dir / \"data/hdf5_list\" / \"100kb_all_none_pval_chip-seq.list\"\n",
    "with open(path_obs_md5, \"r\", encoding=\"utf8\") as f:\n",
    "    obs_md5 = f.read().splitlines()\n",
    "    obs_md5 = set(md5.split(\"/\")[-1].split(\"_\")[0] for md5 in obs_md5)\n",
    "\n",
    "path_metadata_imputed = base_metadata_dir / \"hg38_epiatlas_imputed_pval_chip_2024-02.json\"\n",
    "imp_metadata = Metadata(path_metadata_imputed)\n",
    "\n",
    "path_imputed_md5 = (\n",
    "    base_paper_dir / \"data/hdf5_list\" / \"100kb_all_none_chip-seq_imputed.list\"\n",
    ")\n",
    "with open(path_imputed_md5, \"r\", encoding=\"utf8\") as f:\n",
    "    imp_md5 = f.read().splitlines()\n",
    "    imp_md5 = set(md5.split(\"/\")[-1].split(\"_\")[0] for md5 in imp_md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for md5 in list(obs_metadata.md5s):\n",
    "    if md5 not in obs_md5:\n",
    "        del obs_metadata[md5]\n",
    "\n",
    "for md5 in list(imp_metadata.md5s):\n",
    "    if md5 not in imp_md5:\n",
    "        del imp_metadata[md5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dfs = {}\n",
    "for name, metadata in zip([\"observed\", \"imputed\"], [obs_metadata, imp_metadata]):\n",
    "    print(name)\n",
    "    metadata.display_labels(ASSAY)\n",
    "    meta_dfs[name] = metadata.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df = meta_dfs[\"observed\"]\n",
    "imp_df = meta_dfs[\"imputed\"]\n",
    "\n",
    "obs_df_cell_type = obs_df[CELL_TYPE].value_counts(dropna=False)\n",
    "relative_obs_df_cell_type = obs_df_cell_type / obs_df_cell_type.sum()\n",
    "\n",
    "imp_df_cell_type = imp_df[CELL_TYPE].value_counts(dropna=False)\n",
    "relative_imp_df_cell_type = imp_df_cell_type / imp_df_cell_type.sum()\n",
    "\n",
    "for cell_type, perc in sorted(\n",
    "    relative_obs_df_cell_type.items(), key=lambda x: x[1], reverse=True\n",
    ")[0:20]:\n",
    "    print(cell_type)\n",
    "    print(f\"obs: {obs_df_cell_type[cell_type]}, imp: {imp_df_cell_type[cell_type]}\")\n",
    "    print(\n",
    "        f\"obs: {relative_obs_df_cell_type[cell_type]:.2%}, imp: {relative_imp_df_cell_type[cell_type]:.2%}\"\n",
    "    )\n",
    "    diff = relative_obs_df_cell_type[cell_type] - relative_imp_df_cell_type[cell_type]\n",
    "    print(f\"diff: {diff:.2%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epi_ml.utils.notebooks.paper.paper_utilities import MetadataHandler\n",
    "\n",
    "paper_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "metadata_dir = paper_dir / \"data/metadata\"\n",
    "\n",
    "metadata_handler = MetadataHandler(paper_dir)\n",
    "\n",
    "metadata_v2_df = metadata_handler.load_metadata_df(\"v2\")\n",
    "metadata_v2_df.reset_index(drop=False, inplace=True)\n",
    "print(metadata_v2_df.shape)\n",
    "\n",
    "new_cell_type_path = metadata_dir / \"Martin_class_v3_041224.tsv\"\n",
    "new_cell_type_df = pd.read_csv(\n",
    "    new_cell_type_path,\n",
    "    sep=\"\\t\",\n",
    "    names=[\"epirr_id_without_version\", \"cell_type_martin\", \"cell_type_PE\"],\n",
    ")\n",
    "print(new_cell_type_df.shape)\n",
    "\n",
    "merged_metadata = metadata_v2_df.merge(\n",
    "    new_cell_type_df, on=\"epirr_id_without_version\", how=\"left\"\n",
    ")\n",
    "print(merged_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_meta = {dset[\"md5sum\"]: dset for dset in merged_metadata.to_dict(orient=\"records\")}\n",
    "new_meta_dict = Metadata.from_dict(new_meta)\n",
    "# new_meta_dict.save(\n",
    "#     metadata_dir / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl_newCT.json\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in [\"md5sum\", \"uuid\", \"epirr_id_without_version\"]:\n",
    "#     print(col, merged_metadata[col].nunique())\n",
    "\n",
    "# merged_metadata = merged_metadata.drop_duplicates(\"uuid\")\n",
    "# print(merged_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pivot_col in [\"cell_type_martin\", \"cell_grouping_PE\"]:\n",
    "#     print(pivot_col)\n",
    "#     pair_count_df = merged_metadata.groupby([pivot_col, ASSAY]).agg({\"uuid\": \"count\"}).reset_index()\n",
    "#     assay_count_df = pair_count_df[pair_count_df[\"uuid\"] >= 10].groupby(pivot_col).agg({ASSAY: \"count\"}).reset_index().sort_values(ASSAY, ascending=False)\n",
    "#     print(assay_count_df.reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
