{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbooks to analyze metadata.\"\"\"\n",
    "# pylint: disable=import-error, redefined-outer-name, unused-import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import DefaultDict, Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from epi_ml.core.metadata import Metadata, UUIDMetadata\n",
    "from epi_ml.utils.general_utility import write_hdf5_paths_to_file, write_md5s_to_file\n",
    "from epi_ml.utils.modify_metadata import filter_by_pairs\n",
    "\n",
    "BIOMATERIAL_TYPE = \"harmonized_biomaterial_type\"\n",
    "CELL_TYPE = \"harmonized_sample_ontology_intermediate\"\n",
    "ASSAY = \"assay_epiclass\"\n",
    "SEX = \"harmonized_donor_sex\"\n",
    "CANCER = \"harmonized_sample_cancer_high\"\n",
    "DISEASE = \"harmonized_sample_disease_high\"\n",
    "LIFE_STAGE = \"harmonized_donor_life_stage\"\n",
    "TRACK = \"track_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAY_MERGE_DICT: Dict[str, str] = {\n",
    "    \"rna_seq\": \"rna\",\n",
    "    \"mrna_seq\": \"rna\",\n",
    "    \"wgbs-pbat\": \"wgbs\",\n",
    "    \"wgbs-standard\": \"wgbs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path().home() / \"Projects/epiclass/input/metadata\"\n",
    "# path = base / \"hg38_2023_epiatlas_dfreeze_plus_encode_noncore_formatted_JR.json\"\n",
    "# path = base / \"hg38_2023_epiatlas_dfreeze_formatted_JR.json\"\n",
    "path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl.json\"\n",
    "# path = base / \"dfreeze-v1.0\" / \"hg38_2023-epiatlas_dfreeze_formatted_JR.json\"\n",
    "# path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    "my_metadata = Metadata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gen_info(metadata: Metadata):\n",
    "    \"\"\"Display track type, assay and cell type class counts.\"\"\"\n",
    "    metadata.display_labels(\"track_type\")\n",
    "    metadata.display_labels(ASSAY)\n",
    "    metadata.display_labels(CELL_TYPE)\n",
    "    metadata.display_labels(SEX)\n",
    "    # metadata.display_labels(CANCER)\n",
    "    # metadata.display_labels(DISEASE)\n",
    "    # metadata.display_labels(LIFE_STAGE)\n",
    "    metadata.display_labels(TRACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trios(metadata: Metadata) -> Counter:\n",
    "    \"\"\"\n",
    "    Count the occurrences of unique (track_type, assay, cell_type) trios in the metadata.\n",
    "\n",
    "    Returns:\n",
    "        Counter: A Counter object of the unique trios.\n",
    "    \"\"\"\n",
    "    trios = Counter(\n",
    "        [(dset[\"track_type\"], dset[ASSAY], dset[CELL_TYPE]) for dset in metadata.datasets]\n",
    "    )\n",
    "    return trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pairs_w_assay(metadata: Metadata, category: str) -> DefaultDict[str, Counter]:\n",
    "    \"\"\"\n",
    "    Count the occurrences of each cell type for each assay in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict(Counter): A defaultdict of Counter objects with the count of cell types per assay.\n",
    "    \"\"\"\n",
    "    pair_count = defaultdict(Counter)\n",
    "    for dset in metadata.datasets:\n",
    "        assay, other_label = dset[ASSAY], dset[category]\n",
    "        pair_count[assay].update([other_label])\n",
    "    return pair_count\n",
    "\n",
    "\n",
    "def select_cell_types(metadata: Metadata, n=70) -> DefaultDict[str, List]:\n",
    "    \"\"\"\n",
    "    Determines which cell types are needed to attain n datasets, for a given assay.\n",
    "    Starts with T cell and then selects the most common cell types.\n",
    "\n",
    "    Args:\n",
    "        metadata (Metadata): A Metadata object containing dataset metadata.\n",
    "        n (int, optional): Maximum number of cell types to select for each assay. Defaults to 70.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict(list): A defaultdict with selected cell types for each assay.\n",
    "    \"\"\"\n",
    "    cell_count = count_pairs_w_assay(metadata, CELL_TYPE)\n",
    "\n",
    "    selected_ct = defaultdict(list)\n",
    "    for assay, counter in cell_count.items():\n",
    "        selected_ct[assay].append(\"T cell\")\n",
    "        i = min(counter[\"T cell\"], n)\n",
    "        del counter[\"T cell\"]\n",
    "        while i < n and counter:\n",
    "            for cell_type, count in counter.most_common():\n",
    "                i += min(count, n - i)\n",
    "                selected_ct[assay].append(cell_type)\n",
    "                del counter[cell_type]\n",
    "                break\n",
    "        if i < n:\n",
    "            print(f\"There is not at least {n} files for {assay}. Final number={i}\")\n",
    "\n",
    "    return selected_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nb_pairs in [1,7,9]:\n",
    "#     print(f\"Number of pairs: {nb_pairs}\")\n",
    "#     meta = filter_by_pairs(\n",
    "#         copy.deepcopy(my_metadata), assay_cat=ASSAY, cat2=CELL_TYPE, nb_pairs=nb_pairs, min_per_pair=10\n",
    "#     )\n",
    "#     meta.display_labels(CELL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_gen_info(my_metadata)\n",
    "# my_metadata.get_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: SEX v1.2 = SEX v1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_metadata_dir = (\n",
    "    Path.home() / \"Projects/epiclass/output/paper/data/metadata/official\"\n",
    ")\n",
    "\n",
    "official_metadata_dfs = {}\n",
    "for version in [\"v1.1\", \"v1.2\", \"v1.3\"]:\n",
    "    path = official_metadata_dir / f\"IHEC_metadata_harmonization.{version}.extended.csv\"\n",
    "    df = pd.read_csv(path, sep=\",\")\n",
    "    official_metadata_dfs[version] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEX = \"harmonized_donor_sex\"\n",
    "sex_mislabels_path = (\n",
    "    official_metadata_dir / \"BadQual-mislabels\" / \"official_Sex_mislabeled.csv\"\n",
    ")\n",
    "sex_mislabels_df = pd.read_csv(sex_mislabels_path, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_epirrs = {}\n",
    "subset_df = sex_mislabels_df\n",
    "for version, df in official_metadata_dfs.items():\n",
    "    relevant_df = df.loc[:, [\"epirr_id_without_version\", SEX]]\n",
    "    subset_df = relevant_df.merge(\n",
    "        subset_df,\n",
    "        left_on=\"epirr_id_without_version\",\n",
    "        right_on=\"EpiRR_no-v\",\n",
    "        how=\"right\",\n",
    "        suffixes=(f\"_{version}\", \"\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = subset_df.drop(\n",
    "    columns=[col for col in subset_df.columns if col.startswith(\"epirr_id\")]\n",
    ")\n",
    "subset_df = subset_df.drop(columns=[SEX])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (subset_df[f\"{SEX}_v1.3\"] != subset_df[f\"{SEX}_v1.2\"]).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = official_metadata_dfs[\"v1.2\"].merge(\n",
    "    official_metadata_dfs[\"v1.3\"],\n",
    "    on=\"epirr_id_without_version\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_v1.2\", \"_v1.3\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (merged_df[f\"{SEX}_v1.3\"] != merged_df[f\"{SEX}_v1.2\"]).sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new metadata (for imputed files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_metadata.select_category_subsets(TRACK, [\"pval\"])\n",
    "my_metadata.select_category_subsets(\n",
    "    ASSAY, [\"h3k27ac\", \"h3k27me3\", \"h3k36me3\", \"h3k4me1\", \"h3k4me3\", \"h3k9me3\"]\n",
    ")\n",
    "\n",
    "df = pd.DataFrame.from_records(list(my_metadata.datasets), index=[\"epirr_id\"])\n",
    "\n",
    "print(df.shape, len(my_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all assay specific columns, only want epirr metadata\n",
    "df.drop(\n",
    "    columns=[\n",
    "        \"uuid\",\n",
    "        \"md5sum\",\n",
    "        \"assay_type\",\n",
    "        \"assay_epiclass\",\n",
    "        \"experiment_type\",\n",
    "        \"antibody\",\n",
    "        \"inputs\",\n",
    "        \"inputs_ctl\",\n",
    "        \"data_file_path\",\n",
    "        \"upload_date\",\n",
    "        \"paired_end\",\n",
    "        \"analyzed_as_stranded\",\n",
    "        \"status\",\n",
    "    ],\n",
    "    inplace=True,\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "problematics_columns = df.filter(like=\"read_len\").columns.to_list()\n",
    "df.drop(columns=problematics_columns, inplace=True, errors=\"ignore\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(axis=0, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, len(set(df.index)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[CELL_TYPE].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_ids_path = (\n",
    "    Path.home()\n",
    "    / \"mounts/narval-mount\"\n",
    "    / \"scratch/local_ihec_data/epiatlas/hg38/bw/chip-seq_imputed/all_md5sums.list\"\n",
    ")\n",
    "\n",
    "imputed_ids_df = pd.read_csv(\n",
    "    imputed_ids_path, sep=\"  \", header=None, names=[\"md5sum\", \"filename\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_ids_df.head()\n",
    "imputed_ids_df[\"epirr_id\"] = imputed_ids_df[\"filename\"].str.extract(\n",
    "    r\"impute_(.+)_H3.+.pval.bw\"\n",
    ")\n",
    "imputed_ids_df[\"assay_epiclass\"] = imputed_ids_df[\"filename\"].str.extract(\n",
    "    r\"impute_.+_(H3.+).pval.bw\"\n",
    ")\n",
    "imputed_ids_df[\"assay_epiclass\"] = imputed_ids_df[\"assay_epiclass\"].str.lower()\n",
    "imputed_ids_df[\"uuid\"] = imputed_ids_df[\"md5sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputed_ids_df.shape)\n",
    "imputed_ids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputed_ids_df[\"epirr_id\"].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_og = set(df.index)\n",
    "set_imputed = set(imputed_ids_df[\"epirr_id\"])\n",
    "\n",
    "union = set(df.index) | set(imputed_ids_df[\"epirr_id\"])\n",
    "print(len(union), len(set_og), len(set_imputed))\n",
    "print(set_imputed - set_og)\n",
    "\n",
    "for item in sorted(set_imputed - set_og):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imputed_df = df.merge(\n",
    "    imputed_ids_df, left_index=True, right_on=\"epirr_id\", how=\"right\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_imputed_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_imputed_df[CELL_TYPE].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imputed_df.fillna(\"\", inplace=True)  # necessary to not end up with \"float\" types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_imputed_df.to_csv(Path.home() / \"downloads\" / \"temp\"/ \"hg38_epiatlas_imputed_pval_chip_2024-02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dict = merged_imputed_df.to_dict(orient=\"records\")\n",
    "# meta_dict = {dset[\"md5sum\"]: dset for dset in new_dict}\n",
    "# new_metadata = Metadata.from_dict(meta_dict)\n",
    "# new_metadata.save(\n",
    "#     Path.home() / \"downloads\" / \"temp\" / \"hg38_epiatlas_imputed_pval_chip_2024-02.json\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epi_ml.utils.notebooks.paper.paper_utilities import MetadataHandler\n",
    "\n",
    "paper_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "metadata_dir = paper_dir / \"data/metadata\"\n",
    "\n",
    "metadata_handler = MetadataHandler(paper_dir)\n",
    "\n",
    "metadata_v2_df = metadata_handler.load_metadata_df(\"v2\")\n",
    "metadata_v2_df.reset_index(drop=False, inplace=True)\n",
    "print(metadata_v2_df.shape)\n",
    "\n",
    "new_cell_type_path = metadata_dir / \"Martin_class_v3_041224.tsv\"\n",
    "new_cell_type_df = pd.read_csv(\n",
    "    new_cell_type_path,\n",
    "    sep=\"\\t\",\n",
    "    names=[\"epirr_id_without_version\", \"cell_type_martin\", \"cell_type_PE\"],\n",
    ")\n",
    "print(new_cell_type_df.shape)\n",
    "\n",
    "merged_metadata = metadata_v2_df.merge(\n",
    "    new_cell_type_df, on=\"epirr_id_without_version\", how=\"left\"\n",
    ")\n",
    "print(merged_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_meta = {dset[\"md5sum\"]: dset for dset in merged_metadata.to_dict(orient=\"records\")}\n",
    "new_meta_dict = Metadata.from_dict(new_meta)\n",
    "new_meta_dict.save(\n",
    "    metadata_dir / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl_newCT.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in [\"md5sum\", \"uuid\", \"epirr_id_without_version\"]:\n",
    "#     print(col, merged_metadata[col].nunique())\n",
    "\n",
    "# merged_metadata = merged_metadata.drop_duplicates(\"uuid\")\n",
    "# print(merged_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pivot_col in [\"cell_type_martin\", \"cell_grouping_PE\"]:\n",
    "#     print(pivot_col)\n",
    "#     pair_count_df = merged_metadata.groupby([pivot_col, ASSAY]).agg({\"uuid\": \"count\"}).reset_index()\n",
    "#     assay_count_df = pair_count_df[pair_count_df[\"uuid\"] >= 10].groupby(pivot_col).agg({ASSAY: \"count\"}).reset_index().sort_values(ASSAY, ascending=False)\n",
    "#     print(assay_count_df.reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-epilap-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
