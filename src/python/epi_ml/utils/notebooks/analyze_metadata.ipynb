{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbooks to analyze metadata.\"\"\"\n",
    "# pylint: disable=import-error, redefined-outer-name, unused-import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import DefaultDict, Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from epi_ml.core.metadata import Metadata, UUIDMetadata\n",
    "from epi_ml.utils.general_utility import write_hdf5_paths_to_file, write_md5s_to_file\n",
    "from epi_ml.utils.modify_metadata import filter_by_pairs\n",
    "\n",
    "BIOMATERIAL_TYPE = \"harmonized_biomaterial_type\"\n",
    "CELL_TYPE = \"harmonized_sample_ontology_intermediate\"\n",
    "ASSAY = \"assay_epiclass\"\n",
    "SEX = \"harmonized_donor_sex\"\n",
    "CANCER = \"harmonized_sample_cancer_high\"\n",
    "DISEASE = \"harmonized_sample_disease_high\"\n",
    "LIFE_STAGE = \"harmonized_donor_life_stage\"\n",
    "TRACK = \"track_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAY_MERGE_DICT: Dict[str, str] = {\n",
    "    \"rna_seq\": \"rna\",\n",
    "    \"mrna_seq\": \"rna\",\n",
    "    \"wgbs-pbat\": \"wgbs\",\n",
    "    \"wgbs-standard\": \"wgbs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path().home() / \"Projects/epiclass/input/metadata\"\n",
    "# path = base / \"hg38_2023_epiatlas_dfreeze_plus_encode_noncore_formatted_JR.json\"\n",
    "# path = base / \"hg38_2023_epiatlas_dfreeze_formatted_JR.json\"\n",
    "path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl.json\"\n",
    "# path = base / \"dfreeze-v1.0\" / \"hg38_2023-epiatlas_dfreeze_formatted_JR.json\"\n",
    "# path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    "my_metadata = Metadata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gen_info(metadata: Metadata):\n",
    "    \"\"\"Display track type, assay and cell type class counts.\"\"\"\n",
    "    metadata.display_labels(\"track_type\")\n",
    "    metadata.display_labels(ASSAY)\n",
    "    metadata.display_labels(CELL_TYPE)\n",
    "    metadata.display_labels(SEX)\n",
    "    # metadata.display_labels(CANCER)\n",
    "    # metadata.display_labels(DISEASE)\n",
    "    # metadata.display_labels(LIFE_STAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trios(metadata: Metadata) -> Counter:\n",
    "    \"\"\"\n",
    "    Count the occurrences of unique (track_type, assay, cell_type) trios in the metadata.\n",
    "\n",
    "    Returns:\n",
    "        Counter: A Counter object of the unique trios.\n",
    "    \"\"\"\n",
    "    trios = Counter(\n",
    "        [(dset[\"track_type\"], dset[ASSAY], dset[CELL_TYPE]) for dset in metadata.datasets]\n",
    "    )\n",
    "    return trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pairs_w_assay(metadata: Metadata, category: str) -> DefaultDict[str, Counter]:\n",
    "    \"\"\"\n",
    "    Count the occurrences of each cell type for each assay in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict(Counter): A defaultdict of Counter objects with the count of cell types per assay.\n",
    "    \"\"\"\n",
    "    pair_count = defaultdict(Counter)\n",
    "    for dset in metadata.datasets:\n",
    "        assay, other_label = dset[ASSAY], dset[category]\n",
    "        pair_count[assay].update([other_label])\n",
    "    return pair_count\n",
    "\n",
    "\n",
    "def select_cell_types(metadata: Metadata, n=70) -> DefaultDict[str, List]:\n",
    "    \"\"\"\n",
    "    Determines which cell types are needed to attain n datasets, for a given assay.\n",
    "    Starts with T cell and then selects the most common cell types.\n",
    "\n",
    "    Args:\n",
    "        metadata (Metadata): A Metadata object containing dataset metadata.\n",
    "        n (int, optional): Maximum number of cell types to select for each assay. Defaults to 70.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict(list): A defaultdict with selected cell types for each assay.\n",
    "    \"\"\"\n",
    "    cell_count = count_pairs_w_assay(metadata, CELL_TYPE)\n",
    "\n",
    "    selected_ct = defaultdict(list)\n",
    "    for assay, counter in cell_count.items():\n",
    "        selected_ct[assay].append(\"T cell\")\n",
    "        i = min(counter[\"T cell\"], n)\n",
    "        del counter[\"T cell\"]\n",
    "        while i < n and counter:\n",
    "            for cell_type, count in counter.most_common():\n",
    "                i += min(count, n - i)\n",
    "                selected_ct[assay].append(cell_type)\n",
    "                del counter[cell_type]\n",
    "                break\n",
    "        if i < n:\n",
    "            print(f\"There is not at least {n} files for {assay}. Final number={i}\")\n",
    "\n",
    "    return selected_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_gen_info(my_metadata)\n",
    "# my_metadata.get_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_metadata.remove_missing_labels(CELL_TYPE)\n",
    "my_metadata.select_category_subsets(ASSAY, [\"rna_seq\"])\n",
    "my_metadata.display_labels(CELL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_metadata.remove_missing_labels(CELL_TYPE)\n",
    "# my_metadata.convert_classes(ASSAY, ASSAY_MERGE_DICT)\n",
    "# for md5 in list(my_metadata.md5s):\n",
    "#     assay = my_metadata[md5][ASSAY]\n",
    "#     ct = my_metadata[md5][CELL_TYPE]\n",
    "#     new_label = f\"{assay}_{ct}\"\n",
    "#     my_metadata[md5][f\"{ASSAY}_{CELL_TYPE}\"] = new_label\n",
    "\n",
    "# my_metadata.display_labels(f\"{ASSAY}_{CELL_TYPE}\")\n",
    "# my_metadata.save(base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl_w_merged_assay-ct.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_metadata = filter_by_pairs(my_metadata, assay_cat=ASSAY, cat2=CELL_TYPE, nb_pairs=9, min_per_pair=10)\n",
    "# my_metadata.display_labels(CELL_TYPE)\n",
    "# my_metadata.display_labels(ASSAY)\n",
    "# my_metadata.display_labels(f\"{ASSAY}_{CELL_TYPE}\")\n",
    "\n",
    "# filepath = Path.home() / \"downloads\" / \"100kb_all_none_16ct_pair9.list\"\n",
    "# write_hdf5_paths_to_file(my_metadata.md5s, parent=\"\", suffix=\"100kb_all_none_value\", filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for track_type in [\"pval\", \"raw\"]:\n",
    "#     meta = copy.deepcopy(my_metadata)\n",
    "#     meta.select_category_subsets(TRACK, [track_type])\n",
    "#     meta.display_labels(ASSAY)\n",
    "#     write_hdf5_paths_to_file(\n",
    "#         md5s=meta.md5s,\n",
    "#         parent=\"/lustre07/scratch/rabyj/local_ihec_data/epiatlas/hg38/hdf5\",\n",
    "#         suffix=\"100kb_all_none_value\",\n",
    "#         filepath=Path.home() / \"downloads/temp\" / f\"100kb_all_none_{track_type}_chip-seq.list\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_meta = copy.deepcopy(my_metadata)\n",
    "# my_meta.select_category_subsets(TRACK, [\"raw\", \"ctl_raw\"])\n",
    "# my_meta.display_labels(ASSAY)\n",
    "# write_hdf5_paths_to_file(\n",
    "#     md5s=my_meta.md5s,\n",
    "#     parent=\"/lustre07/scratch/rabyj/local_ihec_data/epiatlas/hg38/hdf5\",\n",
    "#     suffix=\"100kb_all_none_value\",\n",
    "#     filepath=Path.home() / \"downloads/temp\" / \"100kb_all_none_core7_raw.list\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # my_metadata.display_labels(\"project\")\n",
    "\n",
    "# my_metadata.select_category_subsets(ASSAY, [\"input\"])\n",
    "# my_metadata.select_category_subsets(CELL_TYPE, [\"T cell\", \"lymphocyte of B lineage\", \"neutrophil\", \"muscle organ\"])\n",
    "# my_metadata.display_labels(CELL_TYPE)\n",
    "# write_md5s_to_file(\n",
    "#     md5s=my_metadata.md5s,\n",
    "#     logdir=Path.home() / \"downloads/temp\",\n",
    "#     name=\"input_4ct\",\n",
    "# )\n",
    "# write_hdf5_paths_to_file(\n",
    "#     md5s=my_metadata.md5s,\n",
    "#     parent=\"\",\n",
    "#     suffix=\"100kb_all_none\",\n",
    "#     filepath=Path.home() / \"downloads/temp\" / \"100kb_all_none_input_4ct.list\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new metadata (for imputed files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_metadata.select_category_subsets(TRACK, [\"pval\"])\n",
    "my_metadata.select_category_subsets(\n",
    "    ASSAY, [\"h3k27ac\", \"h3k27me3\", \"h3k36me3\", \"h3k4me1\", \"h3k4me3\", \"h3k9me3\"]\n",
    ")\n",
    "\n",
    "df = pd.DataFrame.from_records(list(my_metadata.datasets), index=[\"epirr_id\"])\n",
    "\n",
    "print(df.shape, len(my_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all assay specific columns, only want epirr metadata\n",
    "df.drop(\n",
    "    columns=[\n",
    "        \"uuid\",\n",
    "        \"md5sum\",\n",
    "        \"assay_type\",\n",
    "        \"assay_epiclass\",\n",
    "        \"experiment_type\",\n",
    "        \"antibody\",\n",
    "        \"inputs\",\n",
    "        \"inputs_ctl\",\n",
    "        \"data_file_path\",\n",
    "        \"upload_date\",\n",
    "        \"paired_end\",\n",
    "        \"analyzed_as_stranded\",\n",
    "        \"status\",\n",
    "    ],\n",
    "    inplace=True,\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "problematics_columns = df.filter(like=\"read_len\").columns.to_list()\n",
    "df.drop(columns=problematics_columns, inplace=True, errors=\"ignore\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(axis=0, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, len(set(df.index)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[CELL_TYPE].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_ids_path = (\n",
    "    Path.home()\n",
    "    / \"mounts/narval-mount\"\n",
    "    / \"scratch/local_ihec_data/epiatlas/hg38/bw/chip-seq_imputed/all_md5sums.list\"\n",
    ")\n",
    "\n",
    "imputed_ids_df = pd.read_csv(\n",
    "    imputed_ids_path, sep=\"  \", header=None, names=[\"md5sum\", \"filename\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_ids_df.head()\n",
    "imputed_ids_df[\"epirr_id\"] = imputed_ids_df[\"filename\"].str.extract(\n",
    "    r\"impute_(.+)_H3.+.pval.bw\"\n",
    ")\n",
    "imputed_ids_df[\"assay_epiclass\"] = imputed_ids_df[\"filename\"].str.extract(\n",
    "    r\"impute_.+_(H3.+).pval.bw\"\n",
    ")\n",
    "imputed_ids_df[\"assay_epiclass\"] = imputed_ids_df[\"assay_epiclass\"].str.lower()\n",
    "imputed_ids_df[\"uuid\"] = imputed_ids_df[\"md5sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputed_ids_df.shape)\n",
    "imputed_ids_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputed_ids_df[\"epirr_id\"].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_og = set(df.index)\n",
    "set_imputed = set(imputed_ids_df[\"epirr_id\"])\n",
    "\n",
    "union = set(df.index) | set(imputed_ids_df[\"epirr_id\"])\n",
    "print(len(union), len(set_og), len(set_imputed))\n",
    "print(set_imputed - set_og)\n",
    "\n",
    "for item in sorted(set_imputed - set_og):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imputed_df = df.merge(\n",
    "    imputed_ids_df, left_index=True, right_on=\"epirr_id\", how=\"right\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_imputed_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_imputed_df[CELL_TYPE].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imputed_df.fillna(\"\", inplace=True)  # necessary to not end up with \"float\" types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_imputed_df.to_csv(Path.home() / \"downloads\" / \"temp\"/ \"hg38_epiatlas_imputed_pval_chip_2024-02.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dict = merged_imputed_df.to_dict(orient=\"records\")\n",
    "# meta_dict = {dset[\"md5sum\"]: dset for dset in new_dict}\n",
    "# new_metadata = Metadata.from_dict(meta_dict)\n",
    "# new_metadata.save(\n",
    "#     Path.home() / \"downloads\" / \"temp\" / \"hg38_epiatlas_imputed_pval_chip_2024-02.json\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_v2_df = metadata_handler.load_metadata_df(\"v2\")\n",
    "# metadata_v2_df.reset_index(drop=False, inplace=True)\n",
    "# print(metadata_v2_df.shape)\n",
    "\n",
    "# new_cell_type_path = metadata_dir / \"Martin_class_v3_041224.tsv\"\n",
    "# new_cell_type_df = pd.read_csv(new_cell_type_path, sep=\"\\t\", names=[\"epirr_id_without_version\", \"cell_type_martin\", \"cell_grouping_PE\"])\n",
    "# print(new_cell_type_df.shape)\n",
    "\n",
    "# merged_metadata = metadata_v2_df.merge(new_cell_type_df, on=\"epirr_id_without_version\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_meta = {dset[\"md5sum\"]:dset for dset in merged_metadata.to_dict(orient=\"records\")}\n",
    "# new_meta_dict = Metadata.from_dict(new_meta)\n",
    "# new_meta_dict.save(metadata_dir / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl_newCT.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in [\"md5sum\", \"uuid\", \"epirr_id_without_version\"]:\n",
    "#     print(col, merged_metadata[col].nunique())\n",
    "\n",
    "# merged_metadata = merged_metadata.drop_duplicates(\"uuid\")\n",
    "# print(merged_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pivot_col in [\"cell_type_martin\", \"cell_grouping_PE\"]:\n",
    "#     print(pivot_col)\n",
    "#     pair_count_df = merged_metadata.groupby([pivot_col, ASSAY]).agg({\"uuid\": \"count\"}).reset_index()\n",
    "#     assay_count_df = pair_count_df[pair_count_df[\"uuid\"] >= 10].groupby(pivot_col).agg({ASSAY: \"count\"}).reset_index().sort_values(ASSAY, ascending=False)\n",
    "#     print(assay_count_df.reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-epilap-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
