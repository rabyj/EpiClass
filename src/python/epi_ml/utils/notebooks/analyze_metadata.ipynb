{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Workbooks to analyze metadata.\"\"\"\n",
    "\n",
    "# pylint: disable=import-error, redefined-outer-name, unused-import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import DefaultDict, Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from epi_ml.core.metadata import Metadata, UUIDMetadata\n",
    "from epi_ml.utils.general_utility import write_hdf5_paths_to_file, write_md5s_to_file\n",
    "from epi_ml.utils.modify_metadata import filter_by_pairs\n",
    "from epi_ml.utils.notebooks.paper.paper_utilities import (\n",
    "    ASSAY,\n",
    "    ASSAY_ORDER,\n",
    "    BIOMATERIAL_TYPE,\n",
    "    CANCER,\n",
    "    CELL_TYPE,\n",
    "    DISEASE,\n",
    "    EPIATLAS_16_CT,\n",
    "    LIFE_STAGE,\n",
    "    SEX,\n",
    "    TRACK,\n",
    "    MetadataHandler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE7_ASSAYS = ASSAY_ORDER[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAY_MERGE_DICT: Dict[str, str] = {\n",
    "    \"rna_seq\": \"rna\",\n",
    "    \"mrna_seq\": \"rna\",\n",
    "    \"wgbs-pbat\": \"wgbs\",\n",
    "    \"wgbs-standard\": \"wgbs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "paper_meta_dir = paper_dir / \"data\" / \"metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path().home() / \"Projects/epiclass/input/metadata\"\n",
    "path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl.json\"\n",
    "# path = base / \"dfreeze-v1.0\" / \"hg38_2023-epiatlas_dfreeze_formatted_JR.json\"\n",
    "# path = base / \"dfreeze-v1.0\" / \"hg38_2023-epiatlas_dfreeze_plus_encode_noncore_formatted_JR.json\"\n",
    "# path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    "my_metadata = Metadata(path)\n",
    "meta_df = my_metadata.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gen_info(metadata: Metadata):\n",
    "    \"\"\"Display track type, assay and cell type class counts.\"\"\"\n",
    "    metadata.display_labels(\"track_type\")\n",
    "    metadata.display_labels(ASSAY)\n",
    "    metadata.display_labels(CELL_TYPE)\n",
    "    metadata.display_labels(SEX)\n",
    "    # metadata.display_labels(CANCER)\n",
    "    # metadata.display_labels(DISEASE)\n",
    "    # metadata.display_labels(LIFE_STAGE)\n",
    "    metadata.display_labels(TRACK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trios(metadata: Metadata) -> Counter:\n",
    "    \"\"\"\n",
    "    Count the occurrences of unique (track_type, assay, cell_type) trios in the metadata.\n",
    "\n",
    "    Returns:\n",
    "        Counter: A Counter object of the unique trios.\n",
    "    \"\"\"\n",
    "    trios = Counter(\n",
    "        [(dset[\"track_type\"], dset[ASSAY], dset[CELL_TYPE]) for dset in metadata.datasets]\n",
    "    )\n",
    "    return trios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pairs_w_assay(metadata: Metadata, category: str) -> DefaultDict[str, Counter]:\n",
    "    \"\"\"\n",
    "    Count the occurrences of each cell type for each assay in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict(Counter): A defaultdict of Counter objects with the count of cell types per assay.\n",
    "    \"\"\"\n",
    "    pair_count = defaultdict(Counter)\n",
    "    for dset in metadata.datasets:\n",
    "        assay, other_label = dset[ASSAY], dset[category]\n",
    "        pair_count[assay].update([other_label])\n",
    "    return pair_count\n",
    "\n",
    "\n",
    "def select_cell_types(metadata: Metadata, n=70) -> DefaultDict[str, List]:\n",
    "    \"\"\"\n",
    "    Determines which cell types are needed to attain n datasets, for a given assay.\n",
    "    Starts with T cell and then selects the most common cell types.\n",
    "\n",
    "    Args:\n",
    "        metadata (Metadata): A Metadata object containing dataset metadata.\n",
    "        n (int, optional): Maximum number of cell types to select for each assay. Defaults to 70.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict(list): A defaultdict with selected cell types for each assay.\n",
    "    \"\"\"\n",
    "    cell_count = count_pairs_w_assay(metadata, CELL_TYPE)\n",
    "\n",
    "    selected_ct = defaultdict(list)\n",
    "    for assay, counter in cell_count.items():\n",
    "        selected_ct[assay].append(\"T cell\")\n",
    "        i = min(counter[\"T cell\"], n)\n",
    "        del counter[\"T cell\"]\n",
    "        while i < n and counter:\n",
    "            for cell_type, count in counter.most_common():\n",
    "                i += min(count, n - i)\n",
    "                selected_ct[assay].append(cell_type)\n",
    "                del counter[cell_type]\n",
    "                break\n",
    "        if i < n:\n",
    "            print(f\"There is not at least {n} files for {assay}. Final number={i}\")\n",
    "\n",
    "    return selected_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_metadata.select_category_subsets(ASSAY, CORE7_ASSAYS)\n",
    "# logdir = Path.home() / \"scratch/pca\"\n",
    "# write_md5s_to_file(\n",
    "#     md5s=my_metadata.md5s,\n",
    "#     logdir=logdir,\n",
    "#     name=\"epiatlas_chip\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_metadata.select_category_subsets(BIOMATERIAL_TYPE, [\"cell line\"])\n",
    "# df = my_metadata.to_df()\n",
    "# print(df[\"epirr_id_without_version\"].unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new metadata (for imputed files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_dir = Path.home() / \"Projects/epiclass/output/paper\"\n",
    "paper_meta_dir = paper_dir / \"data\" / \"metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = paper_meta_dir / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl.json\"\n",
    "my_metadata = Metadata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_metadata.select_category_subsets(TRACK, [\"pval\"])\n",
    "my_metadata.select_category_subsets(\n",
    "    ASSAY, [\"h3k27ac\", \"h3k27me3\", \"h3k36me3\", \"h3k4me1\", \"h3k4me3\", \"h3k9me3\"]\n",
    ")\n",
    "\n",
    "df = pd.DataFrame.from_records(list(my_metadata.datasets), index=[\"epirr_id\"])\n",
    "\n",
    "print(df.shape, len(my_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all assay specific columns, only want epirr metadata\n",
    "df.drop(\n",
    "    columns=[\n",
    "        \"uuid\",\n",
    "        \"md5sum\",\n",
    "        \"assay_type\",\n",
    "        \"assay_epiclass\",\n",
    "        \"experiment_type\",\n",
    "        \"antibody\",\n",
    "        \"inputs\",\n",
    "        \"inputs_ctl\",\n",
    "        \"data_file_path\",\n",
    "        \"upload_date\",\n",
    "        \"paired_end\",\n",
    "        \"analyzed_as_stranded\",\n",
    "        \"status\",\n",
    "    ],\n",
    "    inplace=True,\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "problematics_columns = df.filter(like=\"read_len\").columns.to_list()\n",
    "df.drop(columns=problematics_columns, inplace=True, errors=\"ignore\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(axis=0, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, len(set(df.index)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_ids_path = paper_meta_dir / \"all_imputed_files_md5.list\"\n",
    "\n",
    "imputed_ids_df = pd.read_csv(\n",
    "    imputed_ids_path, sep=\"  \", header=None, names=[\"md5sum\", \"filename\"], engine=\"python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_ids_df.head()\n",
    "imputed_ids_df[\"epirr_id\"] = imputed_ids_df[\"filename\"].str.extract(\n",
    "    r\"impute_(.+)_H3.+.pval.bw\"\n",
    ")\n",
    "imputed_ids_df[\"assay_epiclass\"] = imputed_ids_df[\"filename\"].str.extract(\n",
    "    r\"impute_.+_(H3.+).pval.bw\"\n",
    ")\n",
    "imputed_ids_df[\"assay_epiclass\"] = imputed_ids_df[\"assay_epiclass\"].str.lower()\n",
    "imputed_ids_df[\"uuid\"] = imputed_ids_df[\"md5sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputed_ids_df.shape)\n",
    "display(imputed_ids_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imputed_ids_df[\"epirr_id\"].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_og = set(df.index)\n",
    "set_imputed = set(imputed_ids_df[\"epirr_id\"])\n",
    "\n",
    "union = set(df.index) | set(imputed_ids_df[\"epirr_id\"])\n",
    "print(len(union), len(set_og), len(set_imputed))\n",
    "print(set_imputed - set_og)\n",
    "\n",
    "for item in sorted(set_imputed - set_og):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imputed_df = df.merge(\n",
    "    imputed_ids_df, left_index=True, right_on=\"epirr_id\", how=\"right\"\n",
    ")\n",
    "print(merged_imputed_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_imputed_df.fillna(\"\", inplace=True)  # necessary to not end up with \"float\" types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = merged_imputed_df.to_dict(orient=\"records\")\n",
    "meta_dict = {dset[\"md5sum\"]: dset for dset in new_dict}\n",
    "new_metadata = Metadata.from_dict(meta_dict)\n",
    "new_metadata.save(paper_meta_dir / \"hg38_epiatlas_imputed_pval_chip_2024-02.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check: imputed vs obs pval datasets are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_data_dir = paper_dir / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_metadata_observed = (\n",
    "    paper_meta_dir / \"hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    ")\n",
    "obs_metadata = Metadata(path_metadata_observed)\n",
    "\n",
    "path_obs_md5 = paper_data_dir / \"hdf5_list\" / \"100kb_all_none_pval_chip-seq.list\"\n",
    "with open(path_obs_md5, \"r\", encoding=\"utf8\") as f:\n",
    "    obs_md5 = f.read().splitlines()\n",
    "    obs_md5 = set(md5.split(\"/\")[-1].split(\"_\")[0] for md5 in obs_md5)\n",
    "\n",
    "path_metadata_imputed = paper_meta_dir / \"hg38_epiatlas_imputed_pval_chip_2024-02.json\"\n",
    "imp_metadata = Metadata(path_metadata_imputed)\n",
    "\n",
    "path_imputed_md5 = paper_data_dir / \"hdf5_list\" / \"100kb_all_none_chip-seq_imputed.list\"\n",
    "with open(path_imputed_md5, \"r\", encoding=\"utf8\") as f:\n",
    "    imp_md5 = f.read().splitlines()\n",
    "    imp_md5 = set(md5.split(\"/\")[-1].split(\"_\")[0] for md5 in imp_md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for md5 in list(obs_metadata.md5s):\n",
    "    if md5 not in obs_md5:\n",
    "        del obs_metadata[md5]\n",
    "\n",
    "for md5 in list(imp_metadata.md5s):\n",
    "    if md5 not in imp_md5:\n",
    "        del imp_metadata[md5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dfs = {}\n",
    "for name, metadata in zip([\"observed\", \"imputed\"], [obs_metadata, imp_metadata]):\n",
    "    print(name)\n",
    "    metadata.display_labels(ASSAY)\n",
    "    meta_dfs[name] = metadata.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df = meta_dfs[\"observed\"]\n",
    "imp_df = meta_dfs[\"imputed\"]\n",
    "\n",
    "obs_df_cell_type = obs_df[CELL_TYPE].value_counts(dropna=False)\n",
    "relative_obs_df_cell_type = obs_df_cell_type / obs_df_cell_type.sum()\n",
    "\n",
    "imp_df_cell_type = imp_df[CELL_TYPE].value_counts(dropna=False)\n",
    "relative_imp_df_cell_type = imp_df_cell_type / imp_df_cell_type.sum()\n",
    "\n",
    "for cell_type, perc in sorted(\n",
    "    relative_obs_df_cell_type.items(), key=lambda x: x[1], reverse=True\n",
    ")[0:20]:\n",
    "    print(cell_type)\n",
    "    print(f\"obs: {obs_df_cell_type[cell_type]}, imp: {imp_df_cell_type[cell_type]}\")\n",
    "    print(\n",
    "        f\"obs: {relative_obs_df_cell_type[cell_type]:.2%}, imp: {relative_imp_df_cell_type[cell_type]:.2%}\"\n",
    "    )\n",
    "    diff = relative_obs_df_cell_type[cell_type] - relative_imp_df_cell_type[cell_type]\n",
    "    print(f\"diff: {diff:.2%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_handler = MetadataHandler(paper_dir)\n",
    "\n",
    "metadata_v2_df = metadata_handler.load_metadata_df(\"v2\")\n",
    "metadata_v2_df.reset_index(drop=False, inplace=True)\n",
    "print(metadata_v2_df.shape)\n",
    "\n",
    "new_cell_type_path = paper_meta_dir / \"Martin_class_v3_041224.tsv\"\n",
    "new_cell_type_df = pd.read_csv(\n",
    "    new_cell_type_path,\n",
    "    sep=\"\\t\",\n",
    "    names=[\"epirr_id_without_version\", \"cell_type_martin\", \"cell_type_PE\"],\n",
    ")\n",
    "print(new_cell_type_df.shape)\n",
    "\n",
    "merged_metadata = metadata_v2_df.merge(\n",
    "    new_cell_type_df, on=\"epirr_id_without_version\", how=\"left\"\n",
    ")\n",
    "print(merged_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_meta = {dset[\"md5sum\"]: dset for dset in merged_metadata.to_dict(orient=\"records\")}\n",
    "new_meta_dict = Metadata.from_dict(new_meta)\n",
    "new_meta_dict.save(\n",
    "    paper_meta_dir / \"hg38_2023-epiatlas-dfreeze-pospurge-nodup_filterCtl_newCT.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in [\"md5sum\", \"uuid\", \"epirr_id_without_version\"]:\n",
    "#     print(col, merged_metadata[col].nunique())\n",
    "\n",
    "# merged_metadata = merged_metadata.drop_duplicates(\"uuid\")\n",
    "# print(merged_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pivot_col in [\"cell_type_martin\", \"cell_grouping_PE\"]:\n",
    "#     print(pivot_col)\n",
    "#     pair_count_df = merged_metadata.groupby([pivot_col, ASSAY]).agg({\"uuid\": \"count\"}).reset_index()\n",
    "#     assay_count_df = pair_count_df[pair_count_df[\"uuid\"] >= 10].groupby(pivot_col).agg({ASSAY: \"count\"}).reset_index().sort_values(ASSAY, ascending=False)\n",
    "#     print(assay_count_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge pre purge predictions with official BadQual metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_path = (\n",
    "    paper_dir\n",
    "    / \"data/training_results/pre-purge_n21606/10fold\"\n",
    "    / \"full-10fold-validation_prediction_augmented-all.csv\"\n",
    ")\n",
    "preds_df = pd.read_csv(preds_path, sep=\",\", low_memory=False)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = \"assay_epiclass_1l_3000n_11c_10fold-oversampling\"\n",
    "cols = [\"uuid\", ASSAY, \"track_type\", \"Predicted class\", \"Max pred\"]\n",
    "preds_df[cols].head()\n",
    "preds_df = preds_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_qual_path = (\n",
    "    paper_meta_dir\n",
    "    / \"epiatlas\"\n",
    "    / \"official\"\n",
    "    / \"BadQual-mislabels\"\n",
    "    / \"official_BadQual.csv\"\n",
    ")\n",
    "bad_qual_df = pd.read_csv(bad_qual_path)\n",
    "display(bad_qual_df.head())\n",
    "\n",
    "bad_uuid = set(bad_qual_df[\"uuid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(bad_qual_df, preds_df, how=\"right\", on=[\"uuid\"])\n",
    "\n",
    "for df in [bad_qual_df, preds_df, merged_df]:\n",
    "    print(df.shape)\n",
    "\n",
    "merged_df = merged_df[merged_df[\"uuid\"].isin(bad_uuid)]\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "to_pivot = merged_df[[\"uuid\", \"track_type\", \"Max pred\", \"Predicted class\"]]\n",
    "\n",
    "# Pivot longer to wider format using two value columns\n",
    "wide_df = to_pivot.pivot(\n",
    "    index=\"uuid\", columns=\"track_type\", values=[\"Max pred\", \"Predicted class\"]\n",
    ")\n",
    "\n",
    "# Flatten MultiIndex columns\n",
    "wide_df.columns = [\n",
    "    f\"{val.lower().replace(' ', '_')}_{track}\" for val, track in wide_df.columns\n",
    "]\n",
    "\n",
    "# Reset index so uuid becomes a column again\n",
    "wide_df = wide_df.reset_index()\n",
    "\n",
    "print(wide_df.shape)  # Should be roughly (134, 7-9)\n",
    "display(wide_df.head())\n",
    "\n",
    "# remerge with bad_qual_df\n",
    "merged_df = pd.merge(bad_qual_df, wide_df, how=\"left\", on=[\"uuid\"])\n",
    "print(merged_df.shape)\n",
    "display(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "new_path = bad_qual_path.parent / \"official_BadQual_augmented.csv\"\n",
    "merged_df.to_csv(new_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
