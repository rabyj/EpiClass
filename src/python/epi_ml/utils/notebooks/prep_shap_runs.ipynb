{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"See markdown\"\"\"\n",
    "# pylint: disable=line-too-long, redefined-outer-name, import-error, duplicate-code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare background and evaluation data for SHAP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from epi_ml.core.metadata import Metadata\n",
    "from epi_ml.utils.general_utility import write_hdf5_paths_to_file\n",
    "\n",
    "BIOMATERIAL_TYPE = \"harmonized_biomaterial_type\"\n",
    "CELL_TYPE = \"harmonized_sample_ontology_intermediate\"\n",
    "ASSAY = \"assay_epiclass\"\n",
    "SEX = \"harmonized_donor_sex\"\n",
    "CANCER = \"harmonized_sample_cancer_high\"\n",
    "DISEASE = \"harmonized_sample_disease_high\"\n",
    "LIFE_STAGE = \"harmonized_donor_life_stage\"\n",
    "TRACK = \"track_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gen_info(metadata: Metadata, extra_categories: List[str] | None = None):\n",
    "    \"\"\"Display track type, assay and cell type class counts.\"\"\"\n",
    "    metadata.display_labels(\"track_type\")\n",
    "    metadata.display_labels(ASSAY)\n",
    "    metadata.display_labels(CELL_TYPE)\n",
    "    if extra_categories:\n",
    "        for category in extra_categories:\n",
    "            metadata.display_labels(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_datasets(metadata: Metadata, n=5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Select a random subset of n datasets for each unique (track_type, assay, cell_type) trio.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of sampled md5sums of the selected datasets.\n",
    "    \"\"\"\n",
    "    trio_files = defaultdict(list)\n",
    "    for md5sum, dset in metadata.items:\n",
    "        trio = (dset[\"track_type\"], dset[ASSAY], dset[CELL_TYPE])\n",
    "        trio_files[trio].append(md5sum)\n",
    "    print(len(trio_files))\n",
    "\n",
    "    sampled_md5s = list(\n",
    "        itertools.chain.from_iterable(\n",
    "            [random.sample(md5_list, n) for md5_list in trio_files.values()]\n",
    "        )\n",
    "    )\n",
    "    return sampled_md5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path().home() / \"Projects/epilap/input/metadata\"\n",
    "path = base / \"dfreeze-v2\" / \"hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    "base_metadata = Metadata(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = (\n",
    "    Path.home()\n",
    "    / \"mounts/narval-mount/project-rabyj/epilap/output/logs/epiatlas-dfreeze-v2.1/hg38_100kb_all_none\"\n",
    ")\n",
    "model_path = (\n",
    "    model_path / \"harmonized_donor_sex_1l_3000n/w-mixed/10fold-oversample/split0/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_md5_path = list(model_path.glob(\"split0_training_*.md5\"))[0]\n",
    "valid_md5_path = list(model_path.glob(\"split0_validation_*.md5\"))[0]\n",
    "training_mapping_path = model_path / \"training_mapping.tsv\"\n",
    "\n",
    "with open(training_md5_path, \"r\", encoding=\"utf8\") as f:\n",
    "    training_md5 = set(f.read().splitlines())\n",
    "with open(valid_md5_path, \"r\", encoding=\"utf8\") as f:\n",
    "    valid_md5 = set(f.read().splitlines())\n",
    "with open(training_mapping_path, \"r\", encoding=\"utf8\") as f:\n",
    "    training_mapping = dict(line.split(\"\\t\") for line in f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metadata = copy.deepcopy(base_metadata)\n",
    "for md5 in list(training_metadata.md5s):\n",
    "    if md5 not in training_md5:\n",
    "        del training_metadata[md5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metadata = copy.deepcopy(base_metadata)\n",
    "for md5 in list(valid_metadata.md5s):\n",
    "    if md5 not in valid_md5:\n",
    "        del valid_metadata[md5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trios_md5_dict = defaultdict(list)\n",
    "for dset in training_metadata.datasets:\n",
    "    trios_md5_dict[(dset[ASSAY], dset[CELL_TYPE], dset[TRACK])].append(dset[\"md5sum\"])\n",
    "\n",
    "print(f\"{len(trios_md5_dict)} entries/trios\")\n",
    "\n",
    "training_label_counter = training_metadata.label_counter(category, verbose=False)\n",
    "total_training = sum(training_label_counter.values())\n",
    "\n",
    "best_background = None\n",
    "best_diff = float(\"inf\")\n",
    "best_n_per_trio = None\n",
    "for n_per_trio in [2]:\n",
    "    meta = copy.deepcopy(training_metadata)\n",
    "    background_md5s = set()\n",
    "    for trio, md5s in trios_md5_dict.items():\n",
    "        background_md5s.update(md5s[0:n_per_trio])\n",
    "\n",
    "    # Remove md5s not in the background from meta\n",
    "    for md5 in list(meta.md5s):\n",
    "        if md5 not in background_md5s:\n",
    "            del meta[md5]\n",
    "\n",
    "    print(f\"\\nn_per_trio: {n_per_trio}\")\n",
    "    label_counter = meta.label_counter(category, verbose=False)\n",
    "    total_background = sum(label_counter.values())\n",
    "    sum_diff = defaultdict(float)\n",
    "\n",
    "    for label in training_label_counter:\n",
    "        ratio_training = training_label_counter[label] / total_training\n",
    "        ratio_background = label_counter[label] / total_background\n",
    "        diff = abs(ratio_training - ratio_background)\n",
    "        sum_diff[n_per_trio] += diff\n",
    "        print(\n",
    "            f\"{label}: train:{ratio_training:.3f}, sample:{ratio_background:.3f}, diff={diff:.3f}\"\n",
    "        )\n",
    "\n",
    "    if sum_diff[n_per_trio] < best_diff:\n",
    "        best_diff = sum_diff[n_per_trio]\n",
    "        best_background = meta\n",
    "        best_n_per_trio = n_per_trio\n",
    "    print(f\"sum_diff: {sum_diff[n_per_trio]:.3f}\")\n",
    "\n",
    "print(f\"\\nbest_diff: {best_diff:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{best_n_per_trio}pertrio\"\n",
    "shap_dir = model_path / \"shap\"\n",
    "shap_dir.mkdir(exist_ok=True)\n",
    "\n",
    "write_hdf5_paths_to_file(\n",
    "    md5s=sorted(best_background.md5s),\n",
    "    parent=\".\",\n",
    "    suffix=\"100kb_all_none\",\n",
    "    filepath=shap_dir / f\"shap_background_{name}.list\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_gen_info(valid_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_metadata.select_category_subsets(ASSAY, [\"rna_seq\", \"mrna_seq\"])\n",
    "# valid_metadata.select_category_subsets(CELL_TYPE, [\"T cell\", \"lymphocyte of B lineage\", \"muscle organ\", \"monocyte\", \"neutrophil\", \"myeloid cell\"])\n",
    "# valid_metadata.remove_small_classes(min_class_size=10, label_category=CELL_TYPE, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_gen_info(valid_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"all_files_split0_validation\"\n",
    "write_hdf5_paths_to_file(\n",
    "    md5s=sorted(valid_metadata.md5s),\n",
    "    parent=\".\",\n",
    "    suffix=\"100kb_all_none\",\n",
    "    filepath=shap_dir / f\"shap_eval_{name}.list\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
