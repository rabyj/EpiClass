{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Explore metadata distribution of correct/wrong predictions\"\"\"\n",
    "# pylint: disable=line-too-long, redefined-outer-name, import-error, pointless-statement, use-dict-literal, expression-not-assigned, unused-import, too-many-lines, unreachable\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAY = \"assay_epiclass\"\n",
    "TRACK = \"track_type\"\n",
    "\n",
    "BIOMATERIAL_TYPE = \"harmonized_biomaterial_type\"\n",
    "CANCER = \"harmonized_sample_cancer_high\"\n",
    "CELL_TYPE = \"harmonized_sample_ontology_intermediate\"\n",
    "DISEASE = \"harmonized_sample_disease_high\"\n",
    "LIFE_STAGE = \"harmonized_donor_life_stage\"\n",
    "SEX = \"harmonized_donor_sex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = (\n",
    "    Path.home() / \"downloads\" / \"temp\" / \"merged_pred_results_all_2.1_chrY_zscores.csv\"\n",
    ")\n",
    "results_df = pd.read_csv(results_path, index_col=\"md5sum\", header=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_target = SEX\n",
    "\n",
    "print([column for column in results_df.columns if SEX in column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_name = \"harmonized_donor_sex_1l_3000n_w-mixed_10fold-oversample\"\n",
    "\n",
    "classifier_preds_colname = f\"Predicted class {classifier_name}\"\n",
    "classifer_correct_colname = f\"True class {classifier_name}\"\n",
    "classifer_same_colname = f\"Same? {classifier_name}\"\n",
    "\n",
    "classifier_df = results_df[results_df[classifier_preds_colname].notnull()]\n",
    "print(results_df.shape, classifier_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(classifier_df[classifier_preds_colname].value_counts())\n",
    "display(classifier_df[classifer_correct_colname].value_counts())\n",
    "display(classifier_df[classifer_same_colname].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_cols = [\n",
    "    ASSAY,\n",
    "    TRACK,\n",
    "    CELL_TYPE,\n",
    "    BIOMATERIAL_TYPE,\n",
    "] + [analysis_target]\n",
    "\n",
    "global_metadata_distribution = classifier_df.groupby(by=groupby_cols).size()\n",
    "\n",
    "# pylint: disable=singleton-comparison\n",
    "error_metadata_distribution = (\n",
    "    classifier_df[classifier_df[classifer_same_colname] == True]\n",
    "    .groupby(by=groupby_cols)\n",
    "    .size()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_metadata_distribution.sum(), error_metadata_distribution.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_count_df = []\n",
    "for labels, global_count in global_metadata_distribution.items():\n",
    "    error_count = error_metadata_distribution.get(labels, default=0)  # type: ignore\n",
    "    error_rate = error_count / global_count  # type: ignore\n",
    "    error_count_df.append(list(labels) + [error_rate, error_count, global_count])  # type: ignore\n",
    "\n",
    "error_count_df = pd.DataFrame(\n",
    "    error_count_df, columns=groupby_cols + [\"error rate\", \"n error\", \"n total\"]\n",
    ")\n",
    "assert error_count_df[\"n total\"].sum() == global_metadata_distribution.sum()\n",
    "\n",
    "error_count_df.to_csv(\n",
    "    results_path.parent / f\"{classifier_name}_error_rate.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    data_frame=error_count_df,\n",
    "    x=\"n total\",\n",
    "    y=\"error rate\",\n",
    "    hover_data=error_count_df.columns.values[0:5],\n",
    "    color=TRACK,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
