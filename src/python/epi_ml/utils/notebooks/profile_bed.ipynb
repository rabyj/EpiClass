{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Perform gene ontology analysis on bed files.\"\"\"\n",
    "# pylint: disable=import-error,unused-import,redefined-outer-name\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import gffpandas.gffpandas as gffpd\n",
    "import pandas as pd\n",
    "from gprofiler import GProfiler\n",
    "\n",
    "from epi_ml.utils.general_utility import get_valid_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.home() / \"Projects/epilap\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of the gff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gff():\n",
    "    \"\"\"Filter gff to only keep genes.\"\"\"\n",
    "    gff_path = base_path / \"input\" / \"gff\" / \"Homo_sapiens.GRCh38.109.chr.gff3\"\n",
    "    gff_df = gffpd.read_gff3(gff_path)\n",
    "    gff_df_source: pd.DataFrame = gff_df.df  # type: ignore\n",
    "\n",
    "    accepted_types = [\n",
    "        source\n",
    "        for source in gff_df_source[\"type\"].unique().tolist()\n",
    "        if \"gene\" in source and \"segment\" not in source\n",
    "    ]\n",
    "\n",
    "    gff_df = gff_df.filter_feature_of_type(accepted_types)\n",
    "    gff_df_source[\"seq_id\"] = \"chr\" + gff_df_source[\"seq_id\"].astype(str)\n",
    "\n",
    "    gff_df.to_gff3(gff_path.parent / \"Homo_sapiens.GRCh38.109.chr.filtered.gff3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also had to modify ##sequence-region header to add 'chr'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using bedtools intersect\n",
    "\n",
    "Use biggest file as B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bed_base_dir = (\n",
    "#     base_path\n",
    "#     / \"output/logs/epiatlas-dfreeze-v2.1/hg38_100kb_all_none/shap/harmonized_sample_ontology_intermediate_1l_3000n/10fold/split0/shap/rna_only/frequent_features/feature_frequency_method\"\n",
    "# )\n",
    "# if not bed_base_dir.exists():\n",
    "#     raise ValueError(f\"{bed_base_dir} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEDTOOLS_PATH = Path.home() / \"downloads\" / \"installations\" / \"bedtools\"\n",
    "GFF_PATH = base_path / \"input\" / \"gff\" / \"Homo_sapiens.GRCh38.109.chr.filtered.gff3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_one_bed(input_bed_path: Path, output_filename: Path) -> None:\n",
    "    \"\"\"Bed to GO. Does nothing if output_filename already exists.\"\"\"\n",
    "    # don't redo work\n",
    "    if output_filename.is_file():\n",
    "        print(f\"{output_filename} already exists.\")\n",
    "        return\n",
    "\n",
    "    cmd = [\n",
    "        str(BEDTOOLS_PATH),\n",
    "        \"intersect\",\n",
    "        \"-a\",\n",
    "        str(input_bed_path),\n",
    "        \"-b\",\n",
    "        str(GFF_PATH),\n",
    "        \"-wo\",\n",
    "        \"-F\",\n",
    "        \"0.5\",\n",
    "    ]\n",
    "    output = subprocess.check_output(cmd).decode()\n",
    "\n",
    "    print(f\"Writing to {output_filename}\")\n",
    "    with open(output_filename, \"w\", encoding=\"utf8\") as out:\n",
    "        out.writelines(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bed_folder = Path.home() / \"scratch/epiclass/join_important_features/global_info\"\n",
    "# for bed_file in bed_folder.glob(\"*.bed\"):\n",
    "#     if os.stat(str(bed_file)).st_size == 0:\n",
    "#         os.remove(str(bed_file))\n",
    "#         continue\n",
    "#     output_name = Path(bed_file.stem + \"_intersect_gff.tsv\")\n",
    "#     output_filename = bed_folder / output_name\n",
    "#     intersect_one_bed(bed_file, output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using gProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GProfiler(return_dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_folder = (\n",
    "    Path.home()\n",
    "    / \"scratch/epiclass/join_important_features/harmonized_sample_ontology_intermediate_1l_3000n/10fold-oversampling/global_shap_analysis/select_beds_top303/\"\n",
    ")\n",
    "\n",
    "if not bed_folder.exists():\n",
    "    raise ValueError(f\"{bed_folder} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for intersect_file in bed_folder.glob(\"*_intersect_gff.tsv\"):\n",
    "    # Don't redo work\n",
    "    new_file = bed_folder / f\"{intersect_file.stem}_gprofiler.tsv\"\n",
    "    # if new_file.is_file():\n",
    "    #     continue\n",
    "\n",
    "    try:\n",
    "        intersect_df = pd.read_csv(intersect_file, sep=\"\\t\", header=None)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "    genes = intersect_df[11].str.extract(r\"ID=gene:(\\w+);\").drop_duplicates()\n",
    "    genes_list = sorted(genes[0].values)\n",
    "\n",
    "    gene_list_path = bed_folder / f\"{intersect_file.stem}_genes.list\"\n",
    "    with open(gene_list_path, \"w\", encoding=\"utf8\") as out:\n",
    "        out.write(\"\\n\".join(genes_list))\n",
    "\n",
    "    # print(f\"Writing GO results to {new_file}\")\n",
    "    # go_profile = gp.profile(query=genes_list)\n",
    "    # go_profile.to_csv(new_file, sep=\"\\t\", index=False)  # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
