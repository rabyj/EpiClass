{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from epi_ml.core.metadata import Metadata\n",
    "from epi_ml.utils.general_utility import get_valid_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSAY = \"assay_epiclass\"\n",
    "SEX = \"harmonized_donor_sex\"\n",
    "TRACK = \"track_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epilap_project = Path.home() / \"Projects/epilap\"\n",
    "\n",
    "metadata = (\n",
    "    epilap_project\n",
    "    / \"input\"\n",
    "    / \"metadata\"\n",
    "    / \"dfreeze-v2\"\n",
    "    / \"hg38_2023-epiatlas-dfreeze_v2.1_w_encode_noncore_2.json\"\n",
    ")\n",
    "\n",
    "logs = epilap_project / \"output/logs/epiatlas-dfreeze-v2.1\"\n",
    "chrY_coverage_file = logs / \"chrY_coverage_results\" / \"chrXY_coverage_all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = Metadata(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chrY = pd.read_csv(chrY_coverage_file, index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['chrY', 'chrX', 'chrY/chrX'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_chrY.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge metadata and chrY coverage info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.DataFrame.from_records(list(meta.datasets)).set_index(\"md5sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h3k27ac          4689\n",
       "non-core         3599\n",
       "h3k4me1          2889\n",
       "h3k4me3          2397\n",
       "rna_seq          2309\n",
       "h3k36me3         2085\n",
       "h3k27me3         2025\n",
       "h3k9me3          1926\n",
       "wgbs-standard     884\n",
       "input             777\n",
       "mrna_seq          681\n",
       "CTCF              468\n",
       "wgbs-pbat         260\n",
       "Name: assay_epiclass, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df[ASSAY].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-core tracks\n",
    "# meta_df = meta_df[~ meta_df[ASSAY].str.contains(\"non-core|CTCF\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df_chrY.merge(meta_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24989, 169) (21789, 3) (20922, 172)\n"
     ]
    }
   ],
   "source": [
    "print(meta_df.shape, df_chrY.shape, merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "not right shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/local/USHERBROOKE/rabj2301/Projects/sources/epi_ml/src/python/epi_ml/utils/notebooks/chrY_zscore.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/local/USHERBROOKE/rabj2301/Projects/sources/epi_ml/src/python/epi_ml/utils/notebooks/chrY_zscore.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Check the merge\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/local/USHERBROOKE/rabj2301/Projects/sources/epi_ml/src/python/epi_ml/utils/notebooks/chrY_zscore.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39massert\u001b[39;00m (merged_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m meta_df\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m (df_chrY\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m meta_df\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m merged_df\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]), \u001b[39m\"\u001b[39m\u001b[39mnot right shape\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: not right shape"
     ]
    }
   ],
   "source": [
    "# Check the merge\n",
    "assert (merged_df.shape[0] == meta_df.shape[0]) and (\n",
    "    df_chrY.shape[1] + meta_df.shape[1] == merged_df.shape[1]\n",
    "), \"not right shape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in set(meta_df.index.values) - set(df_chrY.index.values):\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute chrY zscore coverage by assay and sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">chrY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assay_epiclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h3k27ac</th>\n",
       "      <td>0.102679</td>\n",
       "      <td>0.144223</td>\n",
       "      <td>4689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3k27me3</th>\n",
       "      <td>0.103248</td>\n",
       "      <td>0.208041</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3k36me3</th>\n",
       "      <td>0.091796</td>\n",
       "      <td>0.165159</td>\n",
       "      <td>2085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3k4me1</th>\n",
       "      <td>0.081342</td>\n",
       "      <td>0.149748</td>\n",
       "      <td>2889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3k4me3</th>\n",
       "      <td>0.084939</td>\n",
       "      <td>0.115496</td>\n",
       "      <td>2397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3k9me3</th>\n",
       "      <td>0.166447</td>\n",
       "      <td>0.307748</td>\n",
       "      <td>1926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input</th>\n",
       "      <td>0.208890</td>\n",
       "      <td>0.314801</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrna_seq</th>\n",
       "      <td>0.049679</td>\n",
       "      <td>0.076258</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rna_seq</th>\n",
       "      <td>0.042931</td>\n",
       "      <td>0.047574</td>\n",
       "      <td>2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wgbs-pbat</th>\n",
       "      <td>7.444794</td>\n",
       "      <td>6.063828</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wgbs-standard</th>\n",
       "      <td>4.475153</td>\n",
       "      <td>4.275084</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    chrY                \n",
       "                    mean       std count\n",
       "assay_epiclass                          \n",
       "h3k27ac         0.102679  0.144223  4689\n",
       "h3k27me3        0.103248  0.208041  2025\n",
       "h3k36me3        0.091796  0.165159  2085\n",
       "h3k4me1         0.081342  0.149748  2889\n",
       "h3k4me3         0.084939  0.115496  2397\n",
       "h3k9me3         0.166447  0.307748  1926\n",
       "input           0.208890  0.314801   777\n",
       "mrna_seq        0.049679  0.076258   681\n",
       "rna_seq         0.042931  0.047574  2309\n",
       "wgbs-pbat       7.444794  6.063828   260\n",
       "wgbs-standard   4.475153  4.275084   884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# groupby_columns = [ASSAY, SEX, TRACK]\n",
    "# groupby_columns = [ASSAY, SEX]\n",
    "groupby_columns = [ASSAY]\n",
    "\n",
    "chrY_dists = merged_df.groupby(groupby_columns).agg({\"chrY\": [\"mean\", \"std\", \"count\"]})\n",
    "display(chrY_dists)\n",
    "# display(chrY_dists.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_name = \"assay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrY_dists.to_csv(logs / \"chrY_coverage_results\" / f\"chrY_coverage_distributions_{partial_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_name = f\"expected_{partial_name}_chrY_z-score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for row in chrY_dists.iterrows():\n",
    "    index, vals = row\n",
    "    # assay, sex, track = index # type: ignore\n",
    "    # assay, sex = index # type: ignore\n",
    "    assay = index  # type: ignore\n",
    "\n",
    "    mean = vals[\"chrY\"][\"mean\"]\n",
    "    std = vals[\"chrY\"][\"std\"]\n",
    "    count = vals[\"chrY\"][\"count\"]\n",
    "\n",
    "    # partial_df = merged_df[(merged_df[ASSAY] == assay) & (merged_df[SEX] == sex) & (merged_df[TRACK] == track)]\n",
    "    # partial_df = merged_df[(merged_df[ASSAY] == assay) & (merged_df[SEX] == sex)]\n",
    "    partial_df = merged_df[(merged_df[ASSAY] == assay)]\n",
    "    partial_df = partial_df[[\"chrY\"]].copy()\n",
    "\n",
    "    partial_df.loc[:, score_name] = (partial_df[\"chrY\"] - mean) / std\n",
    "    partial_df.loc[:, f\"count_{score_name}\"] = count\n",
    "\n",
    "    new_data.append(partial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_zscores_df = pd.concat(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df_chrY.merge(\n",
    "    all_zscores_df, how=\"left\", left_index=True, right_index=True, suffixes=(\"\", \"_DROP\")\n",
    ").sort_index()\n",
    "final_df = final_df.drop(columns=[\"chrY_DROP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_csv(logs / \"chrY_coverage_results\" / f\"chrY_coverage_zscores_{partial_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map predictions to chrY z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_pred_dir = Path.home() / \"downloads\" / \"temp\"\n",
    "sex_pred_file = (\n",
    "    sex_pred_dir / \"sex3_oversample_full-10fold-validation_prediction_augmented-all.csv\"\n",
    ")\n",
    "\n",
    "full_chrY_df = pd.read_csv(\n",
    "    logs / \"chrY_coverage_results\" / f\"chrY_coverage_zscores.csv\", index_col=0, header=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18299, 87)\n"
     ]
    }
   ],
   "source": [
    "pred_df = pd.read_csv(sex_pred_file, index_col=0, header=0)\n",
    "print(pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18299, 96)\n"
     ]
    }
   ],
   "source": [
    "merged_pred_df = pred_df.merge(\n",
    "    full_chrY_df, how=\"inner\", left_index=True, right_index=True, suffixes=(\"\", \"_DROP\")\n",
    ").sort_index()\n",
    "merged_pred_df = merged_pred_df.drop(\n",
    "    columns=[column for column in pred_df.columns if column.endswith(\"_DROP\")]\n",
    ")\n",
    "print(merged_pred_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "UserWarning",
     "evalue": "stop here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUserWarning\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/local/USHERBROOKE/rabj2301/Projects/sources/epi_ml/src/python/epi_ml/utils/notebooks/chrY_zscore.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/local/USHERBROOKE/rabj2301/Projects/sources/epi_ml/src/python/epi_ml/utils/notebooks/chrY_zscore.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mUserWarning\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mstop here\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mUserWarning\u001b[0m: stop here"
     ]
    }
   ],
   "source": [
    "raise UserWarning(\"stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chrY z-scores confusion matrix for sex3 preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS_DICT = {\"female\": \"red\", \"male\": \"blue\", \"mixed\": \"purple\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_pred_df.to_csv(sex_pred_dir / \"sex3_oversample_full-10fold-validation_prediction_augmented-all_chrY_zscores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([col for col in merged_pred_df.columns if \"z-score\" in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_pred_df = merged_pred_df[\n",
    "#     ~merged_pred_df[ASSAY].str.contains(pat=\"wgb\", case=False)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### graphs per assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_label = \"expected_assay_chrY_z-score\"\n",
    "count_label = f\"count_{coverage_label}\"\n",
    "\n",
    "classes = merged_pred_df[\"True class\"].unique()\n",
    "assays = merged_pred_df[ASSAY].unique()\n",
    "\n",
    "matrix_logdir = chrY_coverage_file = (\n",
    "    logs\n",
    "    / \"chrY_coverage_results\"\n",
    "    / \"10fold_valid\"\n",
    "    / \"z-score\"\n",
    "    / \"per_assay\"\n",
    "    / \"w-unknown\"\n",
    "    / \"per_assay_graph\"\n",
    ")\n",
    "\n",
    "for assay_label in assays:\n",
    "    assay_df = merged_pred_df[merged_pred_df[ASSAY] == assay_label]\n",
    "\n",
    "    # confusion matrix for chrY z-score\n",
    "    for threshold in [0, 0.7, 0.9]:\n",
    "        row = 1\n",
    "        col = 1\n",
    "        fig = make_subplots(\n",
    "            rows=3,\n",
    "            cols=3,\n",
    "            shared_yaxes=True,\n",
    "            x_title=\"Predicted class (nb of predictions)\",\n",
    "            y_title=\"z-score vs expected assay\",\n",
    "            row_titles=list(classes),\n",
    "            column_titles=list(classes),\n",
    "            vertical_spacing=0.08,\n",
    "            horizontal_spacing=0.01,\n",
    "        )\n",
    "        threshold_df = assay_df[assay_df[\"Max pred\"] >= threshold]\n",
    "\n",
    "        for label in classes:\n",
    "            df_label = threshold_df[threshold_df[\"True class\"] == label]\n",
    "\n",
    "            # Iterate over each target and add a violin plot for it\n",
    "            for target in classes:\n",
    "                sub_df = df_label[df_label[\"Predicted class\"] == target]\n",
    "\n",
    "                if sub_df.shape[0] == 0:\n",
    "                    y_values = [\n",
    "                        threshold_df[coverage_label].mean()\n",
    "                    ]  # Minimal synthetic data\n",
    "                    sample_count = 0\n",
    "                    hovertext = [\"PLACEHOLDER - NO DATA\"]\n",
    "                else:\n",
    "                    y_values = sub_df[coverage_label]\n",
    "                    hovertext = [\n",
    "                        f\"{md5sum, assay}:(z-score={z_score:.3f} (n={int(count)}), pred={pred:.3f})\"\n",
    "                        for md5sum, pred, z_score, count, assay in zip(\n",
    "                            sub_df.index,\n",
    "                            sub_df[\"Max pred\"],\n",
    "                            sub_df[coverage_label],\n",
    "                            sub_df[count_label],\n",
    "                            sub_df[ASSAY],\n",
    "                        )\n",
    "                    ]\n",
    "\n",
    "                fig.add_trace(\n",
    "                    go.Violin(\n",
    "                        y=y_values,\n",
    "                        name=f\"{target} ({sub_df.shape[0]})\",\n",
    "                        box_visible=True,\n",
    "                        meanline_visible=True,\n",
    "                        points=\"all\",\n",
    "                        text=hovertext,\n",
    "                        line_color=COLORS_DICT[target],\n",
    "                        hovertemplate=\"%{text}\",\n",
    "                    ),\n",
    "                    row=row,\n",
    "                    col=col,\n",
    "                )\n",
    "\n",
    "                # Move to the next subplot position\n",
    "                col += 1\n",
    "                if col > 3:\n",
    "                    col = 1\n",
    "                    row += 1\n",
    "\n",
    "        # Update global layout and traces\n",
    "        fig.update_traces(marker=dict(size=1))\n",
    "        fig.update_yaxes(\n",
    "            range=[\n",
    "                min(assay_df[coverage_label]) - 0.01,\n",
    "                max(assay_df[coverage_label]) + 0.01,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Directly using annotations param does not work with make_subplots\n",
    "        existing_annotations = fig.layout.annotations\n",
    "        new_annotation = dict(\n",
    "            x=1.01,  # Position on the x-axis\n",
    "            y=0.5,  # Position on the y-axis\n",
    "            showarrow=False,  # Do not show arrow\n",
    "            text=\"Reference class\",  # The text you want to display\n",
    "            xref=\"paper\",  # 'x' coordinate is set in relative coordinates\n",
    "            yref=\"paper\",  # 'y' coordinate is set in relative coordinates\n",
    "            xanchor=\"left\",  # Text starts from the left of the x-coordinate\n",
    "            yanchor=\"middle\",  # Middle aligned vertically\n",
    "            font=dict(size=16),\n",
    "            textangle=90,\n",
    "        )\n",
    "        updated_annotations = list(existing_annotations) + [new_annotation]\n",
    "\n",
    "        title = f\"z-score(mean chrY coverage per file):{assay_label} (pred>{threshold})\"\n",
    "\n",
    "        fig.update_layout(\n",
    "            title_text=f\"{title} (n={threshold_df.shape[0]})\",\n",
    "            showlegend=False,\n",
    "            annotations=updated_annotations,\n",
    "        )\n",
    "\n",
    "        # fig.show()\n",
    "\n",
    "        title = get_valid_filename(title).replace(\"_br_\", \"_\")\n",
    "        html_file = matrix_logdir / f\"{title}.html\"\n",
    "        png_file = matrix_logdir / f\"{title}.png\"\n",
    "        if not png_file.exists():\n",
    "            fig.write_image(png_file, scale=2)\n",
    "        if not html_file.exists():\n",
    "            fig.write_html(html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs for all assays mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_label = \"expected_assay_chrY_z-score\"\n",
    "count_label = f\"count_{coverage_label}\"\n",
    "\n",
    "classes = merged_pred_df[\"True class\"].unique()\n",
    "\n",
    "matrix_logdir = chrY_coverage_file = (\n",
    "    logs\n",
    "    / \"chrY_coverage_results\"\n",
    "    / \"10fold_valid\"\n",
    "    / \"z-score\"\n",
    "    / \"per_assay\"\n",
    "    / \"w-unknown\"\n",
    ")\n",
    "\n",
    "\n",
    "# confusion matrix for chrY z-score\n",
    "for threshold in [0, 0.7, 0.9]:\n",
    "    row = 1\n",
    "    col = 1\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=3,\n",
    "        shared_yaxes=True,\n",
    "        x_title=\"Predicted class (nb of predictions)\",\n",
    "        y_title=\"z-score for expected assay\",\n",
    "        row_titles=list(classes),\n",
    "        column_titles=list(classes),\n",
    "        vertical_spacing=0.08,\n",
    "        horizontal_spacing=0.01,\n",
    "    )\n",
    "    threshold_df = merged_pred_df[merged_pred_df[\"Max pred\"] >= threshold]\n",
    "\n",
    "    title = (\n",
    "        f\"z-score(mean chrY coverage per file) - (pred>{threshold})<br>w fc/pval, no wgbs\"\n",
    "    )\n",
    "\n",
    "    filename = get_valid_filename(title).replace(\"_br_\", \"_\")\n",
    "    html_file = matrix_logdir / f\"{filename}.html\"\n",
    "    png_file = matrix_logdir / f\"{filename}.png\"\n",
    "    if png_file.exists() or html_file.exists():\n",
    "        continue\n",
    "\n",
    "    for label in classes:\n",
    "        df_label = threshold_df[threshold_df[\"True class\"] == label]\n",
    "\n",
    "        # Iterate over each target and add a violin plot for it\n",
    "        for target in classes:\n",
    "            sub_df = df_label[df_label[\"Predicted class\"] == target]\n",
    "\n",
    "            if sub_df.shape[0] == 0:\n",
    "                y_values = [threshold_df[coverage_label].mean()]  # Minimal synthetic data\n",
    "                sample_count = 0\n",
    "                hovertext = [\"PLACEHOLDER - NO DATA\"]\n",
    "            else:\n",
    "                y_values = sub_df[coverage_label]\n",
    "                hovertext = [\n",
    "                    f\"{md5sum, assay}:(z-score={z_score:.3f} (n={int(count)}), pred={pred:.3f})\"\n",
    "                    for md5sum, pred, z_score, count, assay in zip(\n",
    "                        sub_df.index,\n",
    "                        sub_df[\"Max pred\"],\n",
    "                        sub_df[coverage_label],\n",
    "                        sub_df[count_label],\n",
    "                        sub_df[ASSAY],\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Violin(\n",
    "                    y=y_values,\n",
    "                    name=f\"{target} ({sub_df.shape[0]})\",\n",
    "                    box_visible=True,\n",
    "                    meanline_visible=True,\n",
    "                    points=\"all\",\n",
    "                    text=hovertext,\n",
    "                    line_color=COLORS_DICT[target],\n",
    "                    hovertemplate=\"%{text}\",\n",
    "                ),\n",
    "                row=row,\n",
    "                col=col,\n",
    "            )\n",
    "\n",
    "            # Move to the next subplot position\n",
    "            col += 1\n",
    "            if col > 3:\n",
    "                col = 1\n",
    "                row += 1\n",
    "\n",
    "    # Update global layout and traces\n",
    "    fig.update_traces(marker=dict(size=1))\n",
    "    fig.update_yaxes(\n",
    "        range=[\n",
    "            min(merged_pred_df[coverage_label]) - 0.01,\n",
    "            max(merged_pred_df[coverage_label]) + 0.01,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Directly using annotations param does not work with make_subplots\n",
    "    existing_annotations = fig.layout.annotations  # type: ignore\n",
    "    new_annotation = dict(\n",
    "        x=1.01,  # Position on the x-axis\n",
    "        y=0.5,  # Position on the y-axis\n",
    "        showarrow=False,  # Do not show arrow\n",
    "        text=\"Reference class\",  # The text you want to display\n",
    "        xref=\"paper\",  # 'x' coordinate is set in relative coordinates\n",
    "        yref=\"paper\",  # 'y' coordinate is set in relative coordinates\n",
    "        xanchor=\"left\",  # Text starts from the left of the x-coordinate\n",
    "        yanchor=\"middle\",  # Middle aligned vertically\n",
    "        font=dict(size=16),\n",
    "        textangle=90,\n",
    "    )\n",
    "    updated_annotations = list(existing_annotations) + [new_annotation]\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f\"{title} (n={threshold_df.shape[0]})\",\n",
    "        showlegend=False,\n",
    "        annotations=updated_annotations,\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig.write_image(png_file, scale=2)\n",
    "    fig.write_html(html_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with global results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_336231/4197668515.py:4: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,141,142,143,144,145,146,147,148,149,151,160,161,162,164,186,187,188,190,199,200,201,203,212,213,214,216,225,226,227,229,238,239,240,242,251,252,253,255,264,265,266,268,277,278,279,281,290,291,292,294,303,304,305,307,316,317,318,320,331,342,343,344,346,355,356,357,359) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  target_df = pd.read_csv(target_file, index_col=0, header=0)\n"
     ]
    }
   ],
   "source": [
    "target_file_dir = logs / \"merged_results\"\n",
    "target_file = target_file_dir / \"merged_pred_results_all_2.1_chrY.csv\"\n",
    "\n",
    "target_df = pd.read_csv(target_file, index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_target_df = target_df.merge(\n",
    "    full_chrY_df, how=\"left\", left_index=True, right_index=True, suffixes=(\"\", \"_DROP\")\n",
    ").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_cols = []\n",
    "for column in updated_target_df.columns:\n",
    "    if column.endswith(\"_DROP\"):\n",
    "        same_cols.append(column[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in same_cols:\n",
    "    assert np.isclose(\n",
    "        0, (updated_target_df[column] - updated_target_df[f\"{column}_DROP\"]).sum()\n",
    "    ), f\"{column} not equal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_target_df = updated_target_df.drop(\n",
    "    columns=[column for column in updated_target_df.columns if column.endswith(\"_DROP\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_target_df.to_csv(target_file_dir / \"merged_pred_results_all_2.1_chrY_zscores.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epiclass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
