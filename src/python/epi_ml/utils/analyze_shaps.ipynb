{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Initial analysis of shap values behavior.\"\"\"\n",
    "# pylint: disable=redefined-outer-name, expression-not-assigned, import-error, not-callable, pointless-statement, no-value-for-parameter, undefined-variable, unused-argument\n",
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from IPython.display import display\n",
    "from scipy.special import softmax\n",
    "\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "from epi_ml.core import metadata\n",
    "\n",
    "# from epi_ml.core.data import UnknownData\n",
    "# from epi_ml.core.hdf5_loader import Hdf5Loader\n",
    "# from epi_ml.core.model_pytorch import LightningDenseClassifier\n",
    "# from epi_ml.core.shap_values import SHAP_Analyzer, SHAP_Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chr1',\n",
       " 'chr10',\n",
       " 'chr11',\n",
       " 'chr12',\n",
       " 'chr13',\n",
       " 'chr14',\n",
       " 'chr15',\n",
       " 'chr16',\n",
       " 'chr17',\n",
       " 'chr18',\n",
       " 'chr19',\n",
       " 'chr2',\n",
       " 'chr20',\n",
       " 'chr21',\n",
       " 'chr22',\n",
       " 'chr3',\n",
       " 'chr4',\n",
       " 'chr5',\n",
       " 'chr6',\n",
       " 'chr7',\n",
       " 'chr8',\n",
       " 'chr9',\n",
       " 'chrX']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_chroms(chrom_file):\n",
    "    \"\"\"Return sorted chromosome names list.\"\"\"\n",
    "    with open(chrom_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        chroms = []\n",
    "        for line in file:\n",
    "            line = line.rstrip()\n",
    "            if line:\n",
    "                chroms.append(line.split()[0])\n",
    "    chroms.sort()\n",
    "    return chroms\n",
    "\n",
    "\n",
    "load_chroms(\n",
    "    \"/home/local/USHERBROOKE/rabj2301/Projects/epilap/input/chromsizes/hg38.noy.chrom.sizes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "home = Path(\"/home/local/USHERBROOKE/rabj2301/Projects\")\n",
    "input_dir = home / \"epilap/input\"\n",
    "metadata_path = (\n",
    "    input_dir\n",
    "    / \"metadata/hg38_2023_epiatlas_dfreeze_plus_encode_noncore_formatted_JR.json\"\n",
    ")\n",
    "\n",
    "output = home / \"epilap/output\"\n",
    "# logdir = output / \"logs/hg38_2022-epiatlas/shap\"\n",
    "# model_dir = output / \"models/split0\"\n",
    "\n",
    "logdir = output / \"models/SHAP/harmonized_donor_sex_1l_3000n-no_validation-binary\"\n",
    "model_dir = logdir\n",
    "\n",
    "my_meta = metadata.Metadata(metadata_path)\n",
    "meta_copy = copy.deepcopy(my_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_path = (\n",
    "    logdir / \"shap_explain_harmonized_donor_sex_evaluation_2023-05-05_00-10-11.npz\"\n",
    ")\n",
    "background_info_path = (\n",
    "    logdir\n",
    "    / \"shap_explain_harmonized_donor_sex_explainer_background_2023-05-04_22-48-55.npz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_shap_samples(shap_dict, n: int) -> Dict[str, List[np.ndarray]]:\n",
    "    \"\"\"Return a subset of shap values and their ids.\"\"\"\n",
    "    selected_shap_samples = {\"shap\": [], \"ids\": []}\n",
    "    total_samples = len(shap_dict[\"ids\"])\n",
    "    selected_indices = np.random.choice(total_samples, n, replace=False)\n",
    "\n",
    "    for class_shap_values in shap_dict[\"shap\"]:\n",
    "        selected_shap_samples[\"shap\"].append(class_shap_values[selected_indices, :])\n",
    "\n",
    "    selected_shap_samples[\"ids\"] = [shap_dict[\"ids\"][idx] for idx in selected_indices]\n",
    "\n",
    "    return selected_shap_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evaluation_md5s', 'shap_values', 'classes']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(shap_values_path, \"rb\") as f:\n",
    "    shap_values_archive = np.load(f)\n",
    "    dict(shap_values_archive.items())\n",
    "\n",
    "list(shap_values_archive.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background_md5s', 'background_expectation', 'classes']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(background_info_path, \"rb\") as f:\n",
    "    explainer_background = np.load(f)\n",
    "    explainer_background = dict(explainer_background.items())\n",
    "\n",
    "list(explainer_background.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb classes: 2\n",
      "nb samples: 770\n",
      "dim 1 shap value matrix: (770, 30321)\n",
      "[['0' 'female']\n",
      " ['1' 'male']]\n"
     ]
    }
   ],
   "source": [
    "eval_md5s = shap_values_archive[\"evaluation_md5s\"]\n",
    "shap_matrices = shap_values_archive[\"shap_values\"]\n",
    "\n",
    "print(f\"nb classes: {len(shap_matrices)}\")\n",
    "print(f\"nb samples: {len(eval_md5s)}\")\n",
    "print(f\"dim 1 shap value matrix: {shap_matrices[0].shape}\")\n",
    "print(shap_values_archive[\"classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for md5 in list(my_meta.md5s):\n",
    "    if md5 not in set(eval_md5s):\n",
    "        del my_meta[md5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label breakdown for assay_epiclass\n",
      "0 labels missing and ignored from count\n",
      "input: 70\n",
      "h3k27ac: 70\n",
      "h3k27me3: 70\n",
      "h3k36me3: 70\n",
      "h3k4me1: 70\n",
      "h3k4me3: 70\n",
      "h3k9me3: 70\n",
      "wgbs-standard: 70\n",
      "rna_seq: 70\n",
      "mrna_seq: 70\n",
      "wgbs-pbat: 70\n",
      "For a total of 770 examples\n",
      "\n",
      "\n",
      "Label breakdown for harmonized_donor_sex\n",
      "0 labels missing and ignored from count\n",
      "female: 393\n",
      "male: 293\n",
      "unknown: 74\n",
      "mixed: 10\n",
      "For a total of 770 examples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_meta.display_labels(\"assay_epiclass\")\n",
    "my_meta.display_labels(\"harmonized_donor_sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values_dict_new = select_shap_samples(shap_values_dict, 2)\n",
    "# md5sums = shap_values_dict_new[\"ids\"]\n",
    "# /lustre06/project/6007017/rabyj/epilap/input/hdf5_list/hg38_2023-01-epiatlas-freeze/shap_assay_background.list\n",
    "# /lustre06/project/6007017/rabyj/epilap/input/hdf5_list/hg38_2023-01-epiatlas-freeze/shap_assay_explain.list\n",
    "# my_meta[md5sums[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(shap_values_dict['ids']).to_csv(logdir / \"shap_sample_md5sums.list\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hdf5_loader = Hdf5Loader(\n",
    "#     chrom_file=input_dir / \"chromsizes/hg38.noy.chrom.sizes\", normalization=True\n",
    "# )\n",
    "# hdf5_loader.load_hdf5s(input_dir / \"hdf5_list/100kb_all_none.list\", md5s=md5sums)\n",
    "# print(len(hdf5_loader.signals))\n",
    "# dset = UnknownData(\n",
    "#     md5sums, [hdf5_loader.signals[md5] for md5 in md5sums], y=None, y_str=None\n",
    "# )\n",
    "# model = LightningDenseClassifier.restore_model(model_dir)\n",
    "# model.mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_meta.remove_category_subsets(\"track_type\", [\"raw\", \"fc\", \"Unique_raw\"])\n",
    "# # len(my_meta)\n",
    "# my_meta.remove_small_classes(10, \"assay\")\n",
    "# my_meta.display_labels(\"assay\")\n",
    "# my_meta.display_labels(\"track_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_impact(shap_values_matrices):\n",
    "    \"\"\"Return average absolute shap values.\"\"\"\n",
    "    shap_abs = np.zeros(shap_values_matrices[0].shape)\n",
    "    for matrix in shap_values_matrices:\n",
    "        shap_abs += np.absolute(matrix)\n",
    "    shap_abs /= len(shap_values_matrices)\n",
    "    return shap_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_most_important_features(sample_shaps, n):\n",
    "    \"\"\"Return features with highest absolute shap values.\"\"\"\n",
    "    return np.flip(np.argsort(np.absolute(sample_shaps)))[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(avg_impact):\n",
    "    \"\"\"Print a box plot\"\"\"\n",
    "    px.box(y=avg_impact.sum(axis=0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_md5s(\n",
    "    md5s: List[str], metadata: metadata.Metadata, category_label: str, labels: List[str]\n",
    ") -> List[int]:\n",
    "    \"\"\"Subsample md5s based on metadata filtering provided, for a given category and filtering labels.\n",
    "\n",
    "    Args:\n",
    "            md5s (list): A list of MD5 hashes.\n",
    "            metadata (Metadata): A metadata object containing the data to be filtered.\n",
    "            category_label (str): The category label to be used for filtering the metadata.\n",
    "            labels (list): A list of labels to be used for selecting category subsets in the metadata.\n",
    "\n",
    "    Returns:\n",
    "            list: A list of indices corresponding to the selected md5s.\n",
    "    \"\"\"\n",
    "    meta = copy.deepcopy(metadata)\n",
    "    meta.select_category_subsets(category_label, labels)\n",
    "    chosen_idxs = []\n",
    "    for i, md5 in enumerate(md5s):\n",
    "        if md5 in meta:\n",
    "            chosen_idxs.append(i)\n",
    "    return chosen_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_meta.select_category_subsets(\"assay_epiclass\", [\"h3k27ac\"])\n",
    "# meta_copy.select_category_subsets(\"assay_epiclass\", [\"h3k27me3\"])\n",
    "# chosen_idxs_h3k27me3 = []\n",
    "# for i, md5 in enumerate(eval_md5s):\n",
    "#     if md5 in meta_copy:\n",
    "#         chosen_idxs_h3k27me3.append(i)\n",
    "\n",
    "# first_class_shap = shap_matrices[0]\n",
    "# first_class_shap = first_class_shap[chosen_idxs,:]\n",
    "# h3k27me3_class_shap = shap_matrices[0][chosen_idxs_h3k27me3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "(41, 30321)\n"
     ]
    }
   ],
   "source": [
    "chosen_idxs = subsample_md5s(eval_md5s, my_meta, \"harmonized_donor_sex\", [\"female\"])\n",
    "print(len(chosen_idxs))\n",
    "\n",
    "first_class_shap = shap_matrices[0]\n",
    "selected_first_class_shap = first_class_shap[chosen_idxs, :]\n",
    "print(selected_first_class_shap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_500_features = []\n",
    "# for sample in selected_first_class_shap:\n",
    "#     top_500_features.append(n_most_important_features(sample, 500))\n",
    "\n",
    "# top_500_features_all = []\n",
    "# for sample in first_class_shap:\n",
    "#     top_500_features_all.append(n_most_important_features(sample, 500))\n",
    "\n",
    "top_100_features = []\n",
    "for sample in selected_first_class_shap:\n",
    "    top_100_features.append(n_most_important_features(sample, 100))\n",
    "\n",
    "top_100_features_all = []\n",
    "for sample in first_class_shap:\n",
    "    top_100_features_all.append(n_most_important_features(sample, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_in_centile(\n",
    "    pairwise_intersections: List[List[int]], centile_list: List[int]\n",
    ") -> Dict[int, List[int]]:\n",
    "    \"\"\"\n",
    "    Get a list of features in the specified frequency centile from multiple feature lists.\n",
    "\n",
    "    This function takes a list of feature lists and a centile value. It calculates the occurrence frequency\n",
    "    of each feature and returns the list of features in the specified frequency centile.\n",
    "\n",
    "    Args:\n",
    "        feature_lists (List[List[int]]): A list of feature lists, where each inner list contains feature indices.\n",
    "        centile_list (List[int]: The centile values for which the features will be returned.\n",
    "\n",
    "    Returns:\n",
    "        Dict[int:List[int]]: A dict containing the list of features in each specified frequency centile.\n",
    "    \"\"\"\n",
    "    # Compute the features in the specified centiles\n",
    "    intersection_counter = Counter()\n",
    "    for feature_set in pairwise_intersections:\n",
    "        intersection_counter.update(feature_set)\n",
    "    sorted_features = sorted(\n",
    "        intersection_counter.items(), key=lambda x: x[1], reverse=True\n",
    "    )\n",
    "\n",
    "    centile_features_dict = {}\n",
    "    for centile in centile_list:\n",
    "        num_features = len(sorted_features)\n",
    "        centile_start = int(np.percentile(range(num_features), centile))\n",
    "        centile_end = int(np.percentile(range(num_features), centile + 1))\n",
    "        centile_features = [\n",
    "            feature for feature, _ in sorted_features[centile_start:centile_end]\n",
    "        ]\n",
    "\n",
    "        centile_features_dict[centile] = centile_features\n",
    "\n",
    "    return centile_features_dict\n",
    "\n",
    "\n",
    "def feature_overlap_stats(\n",
    "    feature_lists: List[List[int]], centile_list: list[int]\n",
    ") -> Tuple[float, float, Set[int], Set[int], Dict[int, List[int]]]:\n",
    "    \"\"\"\n",
    "    Calculate the statistics of feature overlap between multiple feature lists.\n",
    "\n",
    "    This function takes a list of feature lists and calculates the median and average\n",
    "    pairwise overlaps between them. It also computes the union and intersection of all features\n",
    "    in the given feature lists.\n",
    "\n",
    "    Args:\n",
    "        feature_lists (List[List[int]]): A list of feature lists, where each inner list contains feature indices.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, Set[int], Set[int]]: A tuple containing the median overlap, average overlap,\n",
    "                                                 intersection of all features, and union of all features.\n",
    "    \"\"\"\n",
    "    # Compute the overlap between two feature lists\n",
    "    all_pairwise_overlaps = [\n",
    "        set(sample1) & set(sample2)\n",
    "        for sample1, sample2 in itertools.combinations(feature_lists, 2)\n",
    "    ]\n",
    "    all_pairwise_overlaps_len = [len(x) for x in all_pairwise_overlaps]\n",
    "\n",
    "    # Compute the median and average overlap\n",
    "    median_overlap = np.median(all_pairwise_overlaps_len)\n",
    "    average_overlap = np.mean(all_pairwise_overlaps_len)\n",
    "\n",
    "    centile_dict = {}\n",
    "\n",
    "    # Union and intersection of all features\n",
    "    all_features_union: Set[int] = set()\n",
    "    all_features_intersection: Set[int] = set(feature_lists[0])\n",
    "    for feature_set in feature_lists:\n",
    "        all_features_union.update(feature_set)\n",
    "        all_features_intersection &= set(feature_set)\n",
    "\n",
    "    return median_overlap, average_overlap, all_features_intersection, all_features_union, centile_dict  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 samples stats:\n",
      "Median overlap: 66.5\n",
      "Average overlap: 65.75\n",
      "Intersection of all features: 12 features\n",
      "Union of all features: 314 features\n",
      "\n",
      "28917\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    median_overlap,\n",
    "    average_overlap,\n",
    "    features_intersection,\n",
    "    features_union,\n",
    "    _,\n",
    ") = feature_overlap_stats(top_100_features, [])\n",
    "print(f\"{len(chosen_idxs)} samples stats:\")\n",
    "print(\"Median overlap:\", median_overlap)\n",
    "print(f\"Average overlap: {average_overlap:.2f}\")\n",
    "print(f\"Intersection of all features: {len(features_intersection)} features\")\n",
    "print(f\"Union of all features: {len(features_union)} features\\n\")\n",
    "print(list(features_intersection)[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    median_overlap,\n",
    "    average_overlap,\n",
    "    features_intersection,\n",
    "    features_union,\n",
    "    _,\n",
    ") = feature_overlap_stats(top_100_features_all, [])\n",
    "print(\"All 770 samples stats:\")\n",
    "print(\"Median overlap:\", median_overlap)\n",
    "print(f\"Average overlap: {average_overlap:.2f}\")\n",
    "print(f\"Intersection of all features: {len(features_intersection)} features\")\n",
    "print(f\"Union of all features: {len(features_union)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393 samples stats:\n",
      "Median overlap: 127.0\n",
      "Average overlap: 151.05992626058057\n",
      "Intersection of all features: 0 features\n",
      "Union of all features: 6733 features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    median_overlap,\n",
    "    average_overlap,\n",
    "    features_intersection,\n",
    "    features_union,\n",
    "    _,\n",
    ") = feature_overlap_stats(top_500_features, [])\n",
    "print(f\"{len(chosen_idxs)} samples stats:\")\n",
    "print(\"Median overlap:\", median_overlap)\n",
    "print(f\"Average overlap: {average_overlap:.2f}\")\n",
    "print(f\"Intersection of all features: {len(features_intersection)} features\")\n",
    "print(f\"Union of all features: {len(features_union)} features\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 770 samples stats:\n",
      "Median overlap: 130.0\n",
      "Average overlap: 150.47419992231437\n",
      "Intersection of all features: 0 features\n",
      "Union of all features: 7729 features\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    median_overlap,\n",
    "    average_overlap,\n",
    "    features_intersection,\n",
    "    features_union,\n",
    "    _,\n",
    ") = feature_overlap_stats(top_500_features_all, [])\n",
    "print(\"All 770 samples stats:\")\n",
    "print(\"Median overlap:\", median_overlap)\n",
    "print(f\"Average overlap: {average_overlap:.2f}\")\n",
    "print(f\"Intersection of all features: {len(features_intersection)} features\")\n",
    "print(f\"Union of all features: {len(features_union)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected contribution of 12 feature if uniform importance:0.03958%\n",
      "Average expected contribution of 1 feature if uniform importance:0.00330%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.041562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.042539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.042792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.043162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.044316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "count  41.000000\n",
       "mean    0.042809\n",
       "std     0.000596\n",
       "min     0.041562\n",
       "25%     0.042539\n",
       "50%     0.042792\n",
       "75%     0.043162\n",
       "max     0.044316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.003739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.003423</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.003429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.003672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.003736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.003805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.003932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2          3          4          5   \\\n",
       "count  41.000000  41.000000  41.000000  41.000000  41.000000  41.000000   \n",
       "mean    0.003523   0.004291   0.002748   0.002680   0.003651   0.003895   \n",
       "std     0.000047   0.000219   0.000255   0.000144   0.000075   0.000218   \n",
       "min     0.003423   0.003811   0.001918   0.002352   0.003509   0.003459   \n",
       "25%     0.003498   0.004144   0.002634   0.002577   0.003594   0.003754   \n",
       "50%     0.003516   0.004268   0.002766   0.002691   0.003654   0.003874   \n",
       "75%     0.003539   0.004463   0.002955   0.002786   0.003694   0.004054   \n",
       "max     0.003617   0.004729   0.003048   0.002915   0.003846   0.004517   \n",
       "\n",
       "              6          7          8          9          10         11  \n",
       "count  41.000000  41.000000  41.000000  41.000000  41.000000  41.000000  \n",
       "mean    0.002838   0.003501   0.004723   0.003699   0.003522   0.003739  \n",
       "std     0.000149   0.000047   0.000627   0.000153   0.000055   0.000105  \n",
       "min     0.002450   0.003418   0.003799   0.003419   0.003405   0.003429  \n",
       "25%     0.002746   0.003475   0.004371   0.003602   0.003483   0.003672  \n",
       "50%     0.002868   0.003492   0.004546   0.003682   0.003512   0.003736  \n",
       "75%     0.002936   0.003532   0.004812   0.003792   0.003564   0.003805  \n",
       "max     0.003050   0.003595   0.006573   0.004163   0.003629   0.003932  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sample\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30321.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.003298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.003004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.003298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.003674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  30321.000000\n",
       "mean       0.003298\n",
       "std        0.000013\n",
       "min        0.003004\n",
       "25%        0.003294\n",
       "50%        0.003298\n",
       "75%        0.003302\n",
       "max        0.003674"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(first_class_shap[0,:])\n",
    "N = len(features_intersection)\n",
    "print(\n",
    "    f\"Average expected contribution of {N} feature if uniform importance:{N/30321*100:.5f}%\"\n",
    ")\n",
    "print(\n",
    "    f\"Average expected contribution of 1 feature if uniform importance:{1/30321*100:.5f}%\"\n",
    ")\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        softmax(selected_first_class_shap, axis=1)[:, list(features_intersection)].sum(\n",
    "            axis=1\n",
    "        )\n",
    "        * 100\n",
    "    ).describe()\n",
    ")\n",
    "display(\n",
    "    pd.DataFrame(\n",
    "        softmax(selected_first_class_shap, axis=1)[:, list(features_intersection)] * 100\n",
    "    ).describe()\n",
    ")\n",
    "\n",
    "# display(pd.DataFrame(softmax(np.absolute(first_class_shap), axis=1)[5,:]*100).describe())\n",
    "# display(pd.DataFrame(first_class_shap[0,:]).describe())\n",
    "# display(pd.DataFrame(softmax(first_class_shap[0,:]*100)).describe())\n",
    "# sum(softmax(first_class_shap[0,:]))\n",
    "\n",
    "print(\"One sample\")\n",
    "probs_1sample = pd.DataFrame(softmax(first_class_shap, axis=1)[0, :] * 100)\n",
    "display(probs_1sample.describe())\n",
    "# print(np.percentile(probs_1sample, 90))\n",
    "# print(np.percentile(probs_1sample, 95))\n",
    "# print(np.percentile(probs_1sample, 99))\n",
    "# display(pd.DataFrame(selected_first_class_shap[0,:]).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.box(first_class_shap.copy())\n",
    "# px.box(softmax(np.absolute(first_class_shap)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
