<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>python.tests.core.epiatlas_treatment_test API documentation</title>
<meta name="description" content="EpiAtlas data treatment testing module." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>python.tests.core.epiatlas_treatment_test</code></h1>
</header>
<section id="section-intro">
<p>EpiAtlas data treatment testing module.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;EpiAtlas data treatment testing module.&#34;&#34;&#34;
from __future__ import annotations

import copy
from collections import Counter
from typing import List

import numpy as np
import pytest
from sklearn.model_selection import StratifiedKFold

from src.python.core.epiatlas_treatment import (
    ACCEPTED_TRACKS,
    EpiAtlasDataset,
    EpiAtlasFoldFactory,
)
from src.python.core.metadata import Metadata
from src.python.tests.fixtures.epilap_test_data import EpiAtlasTreatmentTestData


class TestEpiAtlasFoldFactory:
    &#34;&#34;&#34;Test class EpiAtlasFoldFactory.

    Preconditions: Exact same input labels list. (raw_dset.train.encoded_labels)
    &#34;&#34;&#34;

    @pytest.fixture(scope=&#34;class&#34;, autouse=True)
    def test_data(self) -&gt; EpiAtlasFoldFactory:
        &#34;&#34;&#34;Mock test EpiAtlasFoldFactory.&#34;&#34;&#34;
        return EpiAtlasTreatmentTestData.default_test_data()

    def test_yield_split_size(self, test_data: EpiAtlasFoldFactory):
        &#34;&#34;&#34;Test that splits contain the correct number of training and validation samples.&#34;&#34;&#34;
        total_data = test_data.epiatlas_dataset.create_total_data(oversampling=False)
        assert total_data.num_examples == len(set(total_data.ids))

        leader_size = test_data.epiatlas_dataset.raw_dataset.train.num_examples
        other_size = len(test_data.epiatlas_dataset._other_tracks)
        assert total_data.num_examples == leader_size + other_size

        for dset in test_data.yield_split():
            train_unique_size = len(set(dset.train.ids))
            valid_unique_size = len(set(dset.validation.ids))
            assert total_data.num_examples == train_unique_size + valid_unique_size

    def test_yield_subsample_validation_1(self, test_data: EpiAtlasFoldFactory):
        &#34;&#34;&#34;Test correct subsampling. Subsplit should partition initial validation split.&#34;&#34;&#34;
        ea_handler = test_data

        # Is it coherent with initial split?
        # initial usual train/valid split
        for split_n in range(ea_handler.k):
            total_dataset = list(ea_handler.yield_split())[split_n]
            total_ids = set(total_dataset.validation.ids)

            # focus down on further splits of validation test
            for _ in range(2):
                for sub_dataset in ea_handler.yield_subsample_validation(
                    chosen_split=split_n, nb_split=2
                ):
                    train = sub_dataset.train.ids
                    valid = sub_dataset.validation.ids

                    ids = set(list(train) + list(valid))
                    assert ids == total_ids

    def test_yield_subsample_validation_2(self, test_data: EpiAtlasFoldFactory):
        &#34;&#34;&#34;Test correct subsampling. Repeated calls should lead to same outcome&#34;&#34;&#34;
        dset1 = next(test_data.yield_subsample_validation(chosen_split=0, nb_split=2))
        dset2 = next(test_data.yield_subsample_validation(chosen_split=0, nb_split=2))
        assert list(dset1.validation.ids) == list(dset2.validation.ids)

    def test_yield_subsample_validation_outofrange(self, test_data: EpiAtlasFoldFactory):
        &#34;&#34;&#34;Test correct subsampling range.&#34;&#34;&#34;
        chosen_split = test_data.k  # one off error

        err_msg = f&#34;{chosen_split}.*{test_data.k}&#34;
        with pytest.raises(IndexError, match=err_msg):
            next(
                test_data.yield_subsample_validation(
                    chosen_split=chosen_split, nb_split=2
                )
            )

    def test_yield_subsample_validation_toomanysplits(
        self, test_data: EpiAtlasFoldFactory
    ):
        &#34;&#34;&#34;Test that you cannot ask for too many splits.&#34;&#34;&#34;
        nb_split = 10
        with pytest.raises(ValueError):
            next(test_data.yield_subsample_validation(chosen_split=0, nb_split=nb_split))


class TestEpiAtlasDataset:
    &#34;&#34;&#34;Test class EpiAtlasDataset&#34;&#34;&#34;

    @pytest.fixture(scope=&#34;class&#34;)
    def test_metadata(self) -&gt; Metadata:
        &#34;&#34;&#34;Mock test EpiAtlasFoldFactory.&#34;&#34;&#34;
        meta_path = (
            EpiAtlasTreatmentTestData.default_test_data().epiatlas_dataset.datasource.metadata_file
        )
        return Metadata(meta_path)

    @pytest.fixture(scope=&#34;class&#34;)
    def test_datasource(self):
        return EpiAtlasTreatmentTestData.default_test_data().epiatlas_dataset.datasource

    @staticmethod
    def modified_metadata(test_metadata, del_tracks: List[str]) -&gt; Metadata:
        meta = copy.deepcopy(test_metadata)
        for del_track in del_tracks:
            for md5, dset in list(meta.items):
                if dset[&#34;track_type&#34;] == del_track:
                    del meta[md5]
        return meta

    @pytest.mark.parametrize(&#34;del_track,&#34;, [&#34;pval&#34;, &#34;fc&#34;, &#34;Unique_minusRaw&#34;])
    def test_epiatlas_prepare_split(self, test_metadata: Metadata, del_track):
        &#34;&#34;&#34;Verify that having missing non-leading tracks does not cause an error.&#34;&#34;&#34;
        meta = self.modified_metadata(test_metadata, [del_track])
        EpiAtlasDataset.epiatlas_prepare_split(meta)

    @pytest.mark.parametrize(&#34;del_track,&#34;, [&#34;pval&#34;, &#34;fc&#34;, &#34;Unique_minusRaw&#34;])
    def test_yield_missing_tracks(self, test_datasource, test_metadata, del_track: str):
        &#34;&#34;&#34;Make sure splitter can handle missing non-leading tracks.&#34;&#34;&#34;
        meta = self.modified_metadata(test_metadata, [del_track])
        ea_handler = EpiAtlasFoldFactory.from_datasource(
            test_datasource,
            label_category=&#34;biomaterial_type&#34;,
            min_class_size=2,
            n_fold=3,
            metadata=meta,
        )
        for _ in ea_handler.yield_split():
            pass

    def test_yield_only_lead(self, test_datasource, test_metadata):
        &#34;&#34;&#34;Make sure splitter can handle missing non-leading tracks.&#34;&#34;&#34;
        meta = TestEpiAtlasDataset.modified_metadata(test_metadata, [&#34;fc&#34;, &#34;pval&#34;])
        labels_count = meta.label_counter(&#34;track_type&#34;)

        total_size = sum(labels_count[track_type] for track_type in ACCEPTED_TRACKS)
        total_raw_count = labels_count[&#34;raw&#34;]

        ea_handler = EpiAtlasFoldFactory.from_datasource(
            test_datasource,
            label_category=&#34;biomaterial_type&#34;,
            min_class_size=2,
            n_fold=3,
            metadata=meta,
        )
        lead_tracks = ea_handler.epiatlas_dataset.raw_dataset.train.num_examples
        other_tracks = len(ea_handler.epiatlas_dataset._other_tracks)

        assert total_size == lead_tracks + other_tracks

        valid_raw_sum = 0
        for dset in ea_handler.yield_split():
            train_unique_size = len(set(dset.train.ids))
            valid_unique_size = len(set(dset.validation.ids))
            assert dset.test.num_examples == 0

            assert total_size == train_unique_size + valid_unique_size

            track_type_counter = Counter(
                [meta[md5][&#34;track_type&#34;] for md5 in dset.validation.ids]
            )
            valid_raw_sum += track_type_counter[&#34;raw&#34;]

        assert valid_raw_sum == total_raw_count


def test_StratifiedKFold_sanity():
    &#34;&#34;&#34;Test that StratifiedKFold yields same datasets every time.

    Preconditions: Exact same input labels list. (raw_dset.train.encoded_labels)
    &#34;&#34;&#34;
    skf1 = StratifiedKFold(n_splits=5, shuffle=False)
    skf2 = StratifiedKFold(n_splits=5, shuffle=False)
    n_classes = 10
    num_examples = 150
    labels = np.random.choice(n_classes, size=num_examples)

    run_1 = list(
        skf1.split(
            np.zeros((num_examples, n_classes)),
            list(labels),
        )
    )
    run_2 = list(
        skf2.split(
            np.zeros((num_examples, n_classes)),
            list(labels),
        )
    )

    for elem1, elem2 in zip(run_1, run_2):
        train1, valid1 = elem1
        train2, valid2 = elem2
        assert np.array_equal(train1, train2)
        assert np.array_equal(valid1, valid2)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="python.tests.core.epiatlas_treatment_test.test_StratifiedKFold_sanity"><code class="name flex">
<span>def <span class="ident">test_StratifiedKFold_sanity</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Test that StratifiedKFold yields same datasets every time.</p>
<p>Preconditions: Exact same input labels list. (raw_dset.train.encoded_labels)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_StratifiedKFold_sanity():
    &#34;&#34;&#34;Test that StratifiedKFold yields same datasets every time.

    Preconditions: Exact same input labels list. (raw_dset.train.encoded_labels)
    &#34;&#34;&#34;
    skf1 = StratifiedKFold(n_splits=5, shuffle=False)
    skf2 = StratifiedKFold(n_splits=5, shuffle=False)
    n_classes = 10
    num_examples = 150
    labels = np.random.choice(n_classes, size=num_examples)

    run_1 = list(
        skf1.split(
            np.zeros((num_examples, n_classes)),
            list(labels),
        )
    )
    run_2 = list(
        skf2.split(
            np.zeros((num_examples, n_classes)),
            list(labels),
        )
    )

    for elem1, elem2 in zip(run_1, run_2):
        train1, valid1 = elem1
        train2, valid2 = elem2
        assert np.array_equal(train1, train2)
        assert np.array_equal(valid1, valid2)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset"><code class="flex name class">
<span>class <span class="ident">TestEpiAtlasDataset</span></span>
</code></dt>
<dd>
<div class="desc"><p>Test class EpiAtlasDataset</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TestEpiAtlasDataset:
    &#34;&#34;&#34;Test class EpiAtlasDataset&#34;&#34;&#34;

    @pytest.fixture(scope=&#34;class&#34;)
    def test_metadata(self) -&gt; Metadata:
        &#34;&#34;&#34;Mock test EpiAtlasFoldFactory.&#34;&#34;&#34;
        meta_path = (
            EpiAtlasTreatmentTestData.default_test_data().epiatlas_dataset.datasource.metadata_file
        )
        return Metadata(meta_path)

    @pytest.fixture(scope=&#34;class&#34;)
    def test_datasource(self):
        return EpiAtlasTreatmentTestData.default_test_data().epiatlas_dataset.datasource

    @staticmethod
    def modified_metadata(test_metadata, del_tracks: List[str]) -&gt; Metadata:
        meta = copy.deepcopy(test_metadata)
        for del_track in del_tracks:
            for md5, dset in list(meta.items):
                if dset[&#34;track_type&#34;] == del_track:
                    del meta[md5]
        return meta

    @pytest.mark.parametrize(&#34;del_track,&#34;, [&#34;pval&#34;, &#34;fc&#34;, &#34;Unique_minusRaw&#34;])
    def test_epiatlas_prepare_split(self, test_metadata: Metadata, del_track):
        &#34;&#34;&#34;Verify that having missing non-leading tracks does not cause an error.&#34;&#34;&#34;
        meta = self.modified_metadata(test_metadata, [del_track])
        EpiAtlasDataset.epiatlas_prepare_split(meta)

    @pytest.mark.parametrize(&#34;del_track,&#34;, [&#34;pval&#34;, &#34;fc&#34;, &#34;Unique_minusRaw&#34;])
    def test_yield_missing_tracks(self, test_datasource, test_metadata, del_track: str):
        &#34;&#34;&#34;Make sure splitter can handle missing non-leading tracks.&#34;&#34;&#34;
        meta = self.modified_metadata(test_metadata, [del_track])
        ea_handler = EpiAtlasFoldFactory.from_datasource(
            test_datasource,
            label_category=&#34;biomaterial_type&#34;,
            min_class_size=2,
            n_fold=3,
            metadata=meta,
        )
        for _ in ea_handler.yield_split():
            pass

    def test_yield_only_lead(self, test_datasource, test_metadata):
        &#34;&#34;&#34;Make sure splitter can handle missing non-leading tracks.&#34;&#34;&#34;
        meta = TestEpiAtlasDataset.modified_metadata(test_metadata, [&#34;fc&#34;, &#34;pval&#34;])
        labels_count = meta.label_counter(&#34;track_type&#34;)

        total_size = sum(labels_count[track_type] for track_type in ACCEPTED_TRACKS)
        total_raw_count = labels_count[&#34;raw&#34;]

        ea_handler = EpiAtlasFoldFactory.from_datasource(
            test_datasource,
            label_category=&#34;biomaterial_type&#34;,
            min_class_size=2,
            n_fold=3,
            metadata=meta,
        )
        lead_tracks = ea_handler.epiatlas_dataset.raw_dataset.train.num_examples
        other_tracks = len(ea_handler.epiatlas_dataset._other_tracks)

        assert total_size == lead_tracks + other_tracks

        valid_raw_sum = 0
        for dset in ea_handler.yield_split():
            train_unique_size = len(set(dset.train.ids))
            valid_unique_size = len(set(dset.validation.ids))
            assert dset.test.num_examples == 0

            assert total_size == train_unique_size + valid_unique_size

            track_type_counter = Counter(
                [meta[md5][&#34;track_type&#34;] for md5 in dset.validation.ids]
            )
            valid_raw_sum += track_type_counter[&#34;raw&#34;]

        assert valid_raw_sum == total_raw_count</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.modified_metadata"><code class="name flex">
<span>def <span class="ident">modified_metadata</span></span>(<span>test_metadata, del_tracks: List[str]) ‑> src.python.core.metadata.Metadata</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def modified_metadata(test_metadata, del_tracks: List[str]) -&gt; Metadata:
    meta = copy.deepcopy(test_metadata)
    for del_track in del_tracks:
        for md5, dset in list(meta.items):
            if dset[&#34;track_type&#34;] == del_track:
                del meta[md5]
    return meta</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_datasource"><code class="name flex">
<span>def <span class="ident">test_datasource</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture(scope=&#34;class&#34;)
def test_datasource(self):
    return EpiAtlasTreatmentTestData.default_test_data().epiatlas_dataset.datasource</code></pre>
</details>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_epiatlas_prepare_split"><code class="name flex">
<span>def <span class="ident">test_epiatlas_prepare_split</span></span>(<span>self, test_metadata: Metadata, del_track)</span>
</code></dt>
<dd>
<div class="desc"><p>Verify that having missing non-leading tracks does not cause an error.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.parametrize(&#34;del_track,&#34;, [&#34;pval&#34;, &#34;fc&#34;, &#34;Unique_minusRaw&#34;])
def test_epiatlas_prepare_split(self, test_metadata: Metadata, del_track):
    &#34;&#34;&#34;Verify that having missing non-leading tracks does not cause an error.&#34;&#34;&#34;
    meta = self.modified_metadata(test_metadata, [del_track])
    EpiAtlasDataset.epiatlas_prepare_split(meta)</code></pre>
</details>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_metadata"><code class="name flex">
<span>def <span class="ident">test_metadata</span></span>(<span>self) ‑> src.python.core.metadata.Metadata</span>
</code></dt>
<dd>
<div class="desc"><p>Mock test EpiAtlasFoldFactory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture(scope=&#34;class&#34;)
def test_metadata(self) -&gt; Metadata:
    &#34;&#34;&#34;Mock test EpiAtlasFoldFactory.&#34;&#34;&#34;
    meta_path = (
        EpiAtlasTreatmentTestData.default_test_data().epiatlas_dataset.datasource.metadata_file
    )
    return Metadata(meta_path)</code></pre>
</details>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_yield_missing_tracks"><code class="name flex">
<span>def <span class="ident">test_yield_missing_tracks</span></span>(<span>self, test_datasource, test_metadata, del_track: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Make sure splitter can handle missing non-leading tracks.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.mark.parametrize(&#34;del_track,&#34;, [&#34;pval&#34;, &#34;fc&#34;, &#34;Unique_minusRaw&#34;])
def test_yield_missing_tracks(self, test_datasource, test_metadata, del_track: str):
    &#34;&#34;&#34;Make sure splitter can handle missing non-leading tracks.&#34;&#34;&#34;
    meta = self.modified_metadata(test_metadata, [del_track])
    ea_handler = EpiAtlasFoldFactory.from_datasource(
        test_datasource,
        label_category=&#34;biomaterial_type&#34;,
        min_class_size=2,
        n_fold=3,
        metadata=meta,
    )
    for _ in ea_handler.yield_split():
        pass</code></pre>
</details>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_yield_only_lead"><code class="name flex">
<span>def <span class="ident">test_yield_only_lead</span></span>(<span>self, test_datasource, test_metadata)</span>
</code></dt>
<dd>
<div class="desc"><p>Make sure splitter can handle missing non-leading tracks.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_yield_only_lead(self, test_datasource, test_metadata):
    &#34;&#34;&#34;Make sure splitter can handle missing non-leading tracks.&#34;&#34;&#34;
    meta = TestEpiAtlasDataset.modified_metadata(test_metadata, [&#34;fc&#34;, &#34;pval&#34;])
    labels_count = meta.label_counter(&#34;track_type&#34;)

    total_size = sum(labels_count[track_type] for track_type in ACCEPTED_TRACKS)
    total_raw_count = labels_count[&#34;raw&#34;]

    ea_handler = EpiAtlasFoldFactory.from_datasource(
        test_datasource,
        label_category=&#34;biomaterial_type&#34;,
        min_class_size=2,
        n_fold=3,
        metadata=meta,
    )
    lead_tracks = ea_handler.epiatlas_dataset.raw_dataset.train.num_examples
    other_tracks = len(ea_handler.epiatlas_dataset._other_tracks)

    assert total_size == lead_tracks + other_tracks

    valid_raw_sum = 0
    for dset in ea_handler.yield_split():
        train_unique_size = len(set(dset.train.ids))
        valid_unique_size = len(set(dset.validation.ids))
        assert dset.test.num_examples == 0

        assert total_size == train_unique_size + valid_unique_size

        track_type_counter = Counter(
            [meta[md5][&#34;track_type&#34;] for md5 in dset.validation.ids]
        )
        valid_raw_sum += track_type_counter[&#34;raw&#34;]

    assert valid_raw_sum == total_raw_count</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory"><code class="flex name class">
<span>class <span class="ident">TestEpiAtlasFoldFactory</span></span>
</code></dt>
<dd>
<div class="desc"><p>Test class EpiAtlasFoldFactory.</p>
<p>Preconditions: Exact same input labels list. (raw_dset.train.encoded_labels)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TestEpiAtlasFoldFactory:
    &#34;&#34;&#34;Test class EpiAtlasFoldFactory.

    Preconditions: Exact same input labels list. (raw_dset.train.encoded_labels)
    &#34;&#34;&#34;

    @pytest.fixture(scope=&#34;class&#34;, autouse=True)
    def test_data(self) -&gt; EpiAtlasFoldFactory:
        &#34;&#34;&#34;Mock test EpiAtlasFoldFactory.&#34;&#34;&#34;
        return EpiAtlasTreatmentTestData.default_test_data()

    def test_yield_split_size(self, test_data: EpiAtlasFoldFactory):
        &#34;&#34;&#34;Test that splits contain the correct number of training and validation samples.&#34;&#34;&#34;
        total_data = test_data.epiatlas_dataset.create_total_data(oversampling=False)
        assert total_data.num_examples == len(set(total_data.ids))

        leader_size = test_data.epiatlas_dataset.raw_dataset.train.num_examples
        other_size = len(test_data.epiatlas_dataset._other_tracks)
        assert total_data.num_examples == leader_size + other_size

        for dset in test_data.yield_split():
            train_unique_size = len(set(dset.train.ids))
            valid_unique_size = len(set(dset.validation.ids))
            assert total_data.num_examples == train_unique_size + valid_unique_size

    def test_yield_subsample_validation_1(self, test_data: EpiAtlasFoldFactory):
        &#34;&#34;&#34;Test correct subsampling. Subsplit should partition initial validation split.&#34;&#34;&#34;
        ea_handler = test_data

        # Is it coherent with initial split?
        # initial usual train/valid split
        for split_n in range(ea_handler.k):
            total_dataset = list(ea_handler.yield_split())[split_n]
            total_ids = set(total_dataset.validation.ids)

            # focus down on further splits of validation test
            for _ in range(2):
                for sub_dataset in ea_handler.yield_subsample_validation(
                    chosen_split=split_n, nb_split=2
                ):
                    train = sub_dataset.train.ids
                    valid = sub_dataset.validation.ids

                    ids = set(list(train) + list(valid))
                    assert ids == total_ids

    def test_yield_subsample_validation_2(self, test_data: EpiAtlasFoldFactory):
        &#34;&#34;&#34;Test correct subsampling. Repeated calls should lead to same outcome&#34;&#34;&#34;
        dset1 = next(test_data.yield_subsample_validation(chosen_split=0, nb_split=2))
        dset2 = next(test_data.yield_subsample_validation(chosen_split=0, nb_split=2))
        assert list(dset1.validation.ids) == list(dset2.validation.ids)

    def test_yield_subsample_validation_outofrange(self, test_data: EpiAtlasFoldFactory):
        &#34;&#34;&#34;Test correct subsampling range.&#34;&#34;&#34;
        chosen_split = test_data.k  # one off error

        err_msg = f&#34;{chosen_split}.*{test_data.k}&#34;
        with pytest.raises(IndexError, match=err_msg):
            next(
                test_data.yield_subsample_validation(
                    chosen_split=chosen_split, nb_split=2
                )
            )

    def test_yield_subsample_validation_toomanysplits(
        self, test_data: EpiAtlasFoldFactory
    ):
        &#34;&#34;&#34;Test that you cannot ask for too many splits.&#34;&#34;&#34;
        nb_split = 10
        with pytest.raises(ValueError):
            next(test_data.yield_subsample_validation(chosen_split=0, nb_split=nb_split))</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_data"><code class="name flex">
<span>def <span class="ident">test_data</span></span>(<span>self) ‑> src.python.core.epiatlas_treatment.EpiAtlasFoldFactory</span>
</code></dt>
<dd>
<div class="desc"><p>Mock test EpiAtlasFoldFactory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@pytest.fixture(scope=&#34;class&#34;, autouse=True)
def test_data(self) -&gt; EpiAtlasFoldFactory:
    &#34;&#34;&#34;Mock test EpiAtlasFoldFactory.&#34;&#34;&#34;
    return EpiAtlasTreatmentTestData.default_test_data()</code></pre>
</details>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_split_size"><code class="name flex">
<span>def <span class="ident">test_yield_split_size</span></span>(<span>self, test_data: EpiAtlasFoldFactory)</span>
</code></dt>
<dd>
<div class="desc"><p>Test that splits contain the correct number of training and validation samples.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_yield_split_size(self, test_data: EpiAtlasFoldFactory):
    &#34;&#34;&#34;Test that splits contain the correct number of training and validation samples.&#34;&#34;&#34;
    total_data = test_data.epiatlas_dataset.create_total_data(oversampling=False)
    assert total_data.num_examples == len(set(total_data.ids))

    leader_size = test_data.epiatlas_dataset.raw_dataset.train.num_examples
    other_size = len(test_data.epiatlas_dataset._other_tracks)
    assert total_data.num_examples == leader_size + other_size

    for dset in test_data.yield_split():
        train_unique_size = len(set(dset.train.ids))
        valid_unique_size = len(set(dset.validation.ids))
        assert total_data.num_examples == train_unique_size + valid_unique_size</code></pre>
</details>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_1"><code class="name flex">
<span>def <span class="ident">test_yield_subsample_validation_1</span></span>(<span>self, test_data: EpiAtlasFoldFactory)</span>
</code></dt>
<dd>
<div class="desc"><p>Test correct subsampling. Subsplit should partition initial validation split.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_yield_subsample_validation_1(self, test_data: EpiAtlasFoldFactory):
    &#34;&#34;&#34;Test correct subsampling. Subsplit should partition initial validation split.&#34;&#34;&#34;
    ea_handler = test_data

    # Is it coherent with initial split?
    # initial usual train/valid split
    for split_n in range(ea_handler.k):
        total_dataset = list(ea_handler.yield_split())[split_n]
        total_ids = set(total_dataset.validation.ids)

        # focus down on further splits of validation test
        for _ in range(2):
            for sub_dataset in ea_handler.yield_subsample_validation(
                chosen_split=split_n, nb_split=2
            ):
                train = sub_dataset.train.ids
                valid = sub_dataset.validation.ids

                ids = set(list(train) + list(valid))
                assert ids == total_ids</code></pre>
</details>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_2"><code class="name flex">
<span>def <span class="ident">test_yield_subsample_validation_2</span></span>(<span>self, test_data: EpiAtlasFoldFactory)</span>
</code></dt>
<dd>
<div class="desc"><p>Test correct subsampling. Repeated calls should lead to same outcome</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_yield_subsample_validation_2(self, test_data: EpiAtlasFoldFactory):
    &#34;&#34;&#34;Test correct subsampling. Repeated calls should lead to same outcome&#34;&#34;&#34;
    dset1 = next(test_data.yield_subsample_validation(chosen_split=0, nb_split=2))
    dset2 = next(test_data.yield_subsample_validation(chosen_split=0, nb_split=2))
    assert list(dset1.validation.ids) == list(dset2.validation.ids)</code></pre>
</details>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_outofrange"><code class="name flex">
<span>def <span class="ident">test_yield_subsample_validation_outofrange</span></span>(<span>self, test_data: EpiAtlasFoldFactory)</span>
</code></dt>
<dd>
<div class="desc"><p>Test correct subsampling range.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_yield_subsample_validation_outofrange(self, test_data: EpiAtlasFoldFactory):
    &#34;&#34;&#34;Test correct subsampling range.&#34;&#34;&#34;
    chosen_split = test_data.k  # one off error

    err_msg = f&#34;{chosen_split}.*{test_data.k}&#34;
    with pytest.raises(IndexError, match=err_msg):
        next(
            test_data.yield_subsample_validation(
                chosen_split=chosen_split, nb_split=2
            )
        )</code></pre>
</details>
</dd>
<dt id="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_toomanysplits"><code class="name flex">
<span>def <span class="ident">test_yield_subsample_validation_toomanysplits</span></span>(<span>self, test_data: EpiAtlasFoldFactory)</span>
</code></dt>
<dd>
<div class="desc"><p>Test that you cannot ask for too many splits.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_yield_subsample_validation_toomanysplits(
    self, test_data: EpiAtlasFoldFactory
):
    &#34;&#34;&#34;Test that you cannot ask for too many splits.&#34;&#34;&#34;
    nb_split = 10
    with pytest.raises(ValueError):
        next(test_data.yield_subsample_validation(chosen_split=0, nb_split=nb_split))</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="python.tests.core" href="index.html">python.tests.core</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="python.tests.core.epiatlas_treatment_test.test_StratifiedKFold_sanity" href="#python.tests.core.epiatlas_treatment_test.test_StratifiedKFold_sanity">test_StratifiedKFold_sanity</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset">TestEpiAtlasDataset</a></code></h4>
<ul class="">
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.modified_metadata" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.modified_metadata">modified_metadata</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_datasource" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_datasource">test_datasource</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_epiatlas_prepare_split" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_epiatlas_prepare_split">test_epiatlas_prepare_split</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_metadata" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_metadata">test_metadata</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_yield_missing_tracks" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_yield_missing_tracks">test_yield_missing_tracks</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_yield_only_lead" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasDataset.test_yield_only_lead">test_yield_only_lead</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory">TestEpiAtlasFoldFactory</a></code></h4>
<ul class="">
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_data" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_data">test_data</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_split_size" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_split_size">test_yield_split_size</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_1" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_1">test_yield_subsample_validation_1</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_2" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_2">test_yield_subsample_validation_2</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_outofrange" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_outofrange">test_yield_subsample_validation_outofrange</a></code></li>
<li><code><a title="python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_toomanysplits" href="#python.tests.core.epiatlas_treatment_test.TestEpiAtlasFoldFactory.test_yield_subsample_validation_toomanysplits">test_yield_subsample_validation_toomanysplits</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>